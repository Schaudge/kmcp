{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"KMCP: accurate metagenomic profiling of both prokaryotic and viral organisms by pseudo-mapping What can we do? 1. Accurate metagenomic profiling KMCP adopts a novol metagenomic profiling strategy, by splitting reference genomes into 10 fragments and mappings reads to these fragments via fast k-mer matching. KMCP performs well on both prokaryotic and viral organisms, with higher sensitivity and specificity than other k-mer-based tools (check the benchmark ). 2. Fast sequence search against large scales of genomic datasets KMCP can be used for fast sequence search against large scales of genomic dataset as BIGSI and COBS do. We reimplemented and modified the Compact Bit-Sliced Signature index (COBS) algorithm, bringing a smaller index size and much faster searching speed ( 4x-10x faster than COBS ) (check the tutorial and benchmark ). 3. Fast genome similarity estimation KMCP can be used for fast similarity estimation of assemblies/genomes against known reference genomes. Genome sketching is a method of utilizing small and approximate summaries of genomic data for fast searching and comparison. Mash and Sourmash provide fast genome distance estimation using MinHash (Mash) or FracMinHash (Scaled MinHash) (Sourmash). KMCP utilizes multiple k-mer sketches ( Minimizer , FracMinHash (previously named Scaled MinHash ) and Closed Syncmers ) for genome similarity estimation. KMCP is 4x-7x faster than Mash/Sourmash (check the tutorial and benchmark ). Features Easy to install Statically linked executable binaries for multiple platforms (Linux/Windows/macOS, amd64). No dependencies, no configurations. Easy to use Supporting shell autocompletion . Detailed usage and tutorials . Building database is easy and fast ~25 min for 47894 genomes from GTDB-r202 on a sever with 40 CPU threads and solid disk drive. Fast searching speed The index structure is modified from COBS, while KMCP is 4x-10x faster . Automatically scales to exploit all available CPU cores. Searching time is linearly related to the number of reference genomes. Scalable searching . Searching results against multiple databases can be fast merged . This brings many benefits: There's no need to re-built the database with newly added reference genomes . HPC cluster could linearly accelerate searching with each computation node hosting a database built with a part of reference genomes. Computers with limited main memory would also support searching by building small databases. Accurate taxonomic profiling Some k-mer based taxonomic profilers suffers from high false positive rates, while KMCP adopts multiple strategies to improve specificity and keeps high sensitivity at the same time . Except for archaea and bacteria, KMCP performed well on virus/phages . KMCP also provides confident infectious pathogen detection . Preset six modes for multiple scenarios . Supports CAMI and MetaPhlAn profiling format . Documents Installation Databases Tutorials Taxonomic profiling Sequence and genome searching Usage Benchmarks FAQs Installation Download executable binaries , or install using conda: conda install -c bioconda kmcp SIMD extensions including AVX512 , AVX2 , SSE2 are sequentially detected and used in two packages for better searching performance. pand , for accelerating searching on databases constructed with multiple hash functions. pospop , for batch counting matched k-mers in bloom filters. Commands subcommand function compute Generate k-mers (sketches) from FASTA/Q sequences index Construct database from k-mer files search Search sequences against a database merge Merge search results from multiple databases profile Generate taxonomic profile from search results utils filter Filter search results and find species/assembly-specific queries utils merge-regions Merge species/assembly-specific regions utils unik-info Print information of .unik file utils index-info Print information of index file Quickstart # compute k-mers kmcp compute -k 21 --split-number 10 --split-overlap 100 \\ --in-dir genomes/ --out-dir genomes-k21-n10 # index k-mers kmcp index --in-dir genomes-k21-n10/ --out-dir genomes.kmcp # delete temporary files # rm -rf genomes-k21-n10/ # search kmcp search --db-dir genomes.kmcp/ test.fa.gz --out-file search.tsv.gz # profile and binning kmcp profile search.tsv.gz \\ --taxid-map taxid.map \\ --taxdump taxdump/ \\ --out-prefix search.tsv.gz.k.profile \\ --metaphlan-report search.tsv.gz.m.profile \\ --cami-report search.tsv.gz.c.profile \\ --binning-result search.tsv.gz.binning.gz Support Please open an issue to report bugs, propose new functions or ask for help. License MIT License Acknowledgments Zhi-Luo Deng (Helmholtz Centre for Infection Research, Germany) gave a lot of valuable advice on metagenomic profiling and benchmarking. Robert Clausecker (Zuse Institute Berlin, Germany) wrote the high-performance vectorized positional popcount package ( pospop ) during my development of KMCP , which greatly accelerated the bit-matrix searching.","title":"Home"},{"location":"#kmcp-accurate-metagenomic-profiling-of-both-prokaryotic-and-viral-organisms-by-pseudo-mapping","text":"","title":"KMCP: accurate metagenomic profiling of both prokaryotic and viral organisms by pseudo-mapping"},{"location":"#what-can-we-do","text":"","title":"What can we do?"},{"location":"#1-accurate-metagenomic-profiling","text":"KMCP adopts a novol metagenomic profiling strategy, by splitting reference genomes into 10 fragments and mappings reads to these fragments via fast k-mer matching. KMCP performs well on both prokaryotic and viral organisms, with higher sensitivity and specificity than other k-mer-based tools (check the benchmark ).","title":"1. Accurate metagenomic profiling"},{"location":"#2-fast-sequence-search-against-large-scales-of-genomic-datasets","text":"KMCP can be used for fast sequence search against large scales of genomic dataset as BIGSI and COBS do. We reimplemented and modified the Compact Bit-Sliced Signature index (COBS) algorithm, bringing a smaller index size and much faster searching speed ( 4x-10x faster than COBS ) (check the tutorial and benchmark ).","title":"2. Fast sequence search against large scales of genomic datasets"},{"location":"#3-fast-genome-similarity-estimation","text":"KMCP can be used for fast similarity estimation of assemblies/genomes against known reference genomes. Genome sketching is a method of utilizing small and approximate summaries of genomic data for fast searching and comparison. Mash and Sourmash provide fast genome distance estimation using MinHash (Mash) or FracMinHash (Scaled MinHash) (Sourmash). KMCP utilizes multiple k-mer sketches ( Minimizer , FracMinHash (previously named Scaled MinHash ) and Closed Syncmers ) for genome similarity estimation. KMCP is 4x-7x faster than Mash/Sourmash (check the tutorial and benchmark ).","title":"3. Fast genome similarity estimation"},{"location":"#features","text":"Easy to install Statically linked executable binaries for multiple platforms (Linux/Windows/macOS, amd64). No dependencies, no configurations. Easy to use Supporting shell autocompletion . Detailed usage and tutorials . Building database is easy and fast ~25 min for 47894 genomes from GTDB-r202 on a sever with 40 CPU threads and solid disk drive. Fast searching speed The index structure is modified from COBS, while KMCP is 4x-10x faster . Automatically scales to exploit all available CPU cores. Searching time is linearly related to the number of reference genomes. Scalable searching . Searching results against multiple databases can be fast merged . This brings many benefits: There's no need to re-built the database with newly added reference genomes . HPC cluster could linearly accelerate searching with each computation node hosting a database built with a part of reference genomes. Computers with limited main memory would also support searching by building small databases. Accurate taxonomic profiling Some k-mer based taxonomic profilers suffers from high false positive rates, while KMCP adopts multiple strategies to improve specificity and keeps high sensitivity at the same time . Except for archaea and bacteria, KMCP performed well on virus/phages . KMCP also provides confident infectious pathogen detection . Preset six modes for multiple scenarios . Supports CAMI and MetaPhlAn profiling format .","title":"Features"},{"location":"#documents","text":"Installation Databases Tutorials Taxonomic profiling Sequence and genome searching Usage Benchmarks FAQs","title":"Documents"},{"location":"#installation","text":"Download executable binaries , or install using conda: conda install -c bioconda kmcp SIMD extensions including AVX512 , AVX2 , SSE2 are sequentially detected and used in two packages for better searching performance. pand , for accelerating searching on databases constructed with multiple hash functions. pospop , for batch counting matched k-mers in bloom filters.","title":"Installation"},{"location":"#commands","text":"subcommand function compute Generate k-mers (sketches) from FASTA/Q sequences index Construct database from k-mer files search Search sequences against a database merge Merge search results from multiple databases profile Generate taxonomic profile from search results utils filter Filter search results and find species/assembly-specific queries utils merge-regions Merge species/assembly-specific regions utils unik-info Print information of .unik file utils index-info Print information of index file","title":"Commands"},{"location":"#quickstart","text":"# compute k-mers kmcp compute -k 21 --split-number 10 --split-overlap 100 \\ --in-dir genomes/ --out-dir genomes-k21-n10 # index k-mers kmcp index --in-dir genomes-k21-n10/ --out-dir genomes.kmcp # delete temporary files # rm -rf genomes-k21-n10/ # search kmcp search --db-dir genomes.kmcp/ test.fa.gz --out-file search.tsv.gz # profile and binning kmcp profile search.tsv.gz \\ --taxid-map taxid.map \\ --taxdump taxdump/ \\ --out-prefix search.tsv.gz.k.profile \\ --metaphlan-report search.tsv.gz.m.profile \\ --cami-report search.tsv.gz.c.profile \\ --binning-result search.tsv.gz.binning.gz","title":"Quickstart"},{"location":"#support","text":"Please open an issue to report bugs, propose new functions or ask for help.","title":"Support"},{"location":"#license","text":"MIT License","title":"License"},{"location":"#acknowledgments","text":"Zhi-Luo Deng (Helmholtz Centre for Infection Research, Germany) gave a lot of valuable advice on metagenomic profiling and benchmarking. Robert Clausecker (Zuse Institute Berlin, Germany) wrote the high-performance vectorized positional popcount package ( pospop ) during my development of KMCP , which greatly accelerated the bit-matrix searching.","title":"Acknowledgments"},{"location":"database/","text":"Database Prebuilt databases All prebuilt database are available at: OneDrive for global users. CowTransfer for Chinese users, a command-line tool is recommended. Hardware requirements Prebuilt databases were built for computers with >= 32 CPU cores in consideration of better parallelization, and computers should have at least 64 GB. By default, kmcp search loads the whole database into main memory (via mmap ) for fast searching. Optionally, the flag --low-mem can be set to avoid loading the whole database, while it's much slower, >10X slower on SSD and should be much slower on HDD disks. To reduce memory requirements on computers without enough memory, users can divide the reference genomes into several parts and build smaller databases for all parts, so that the biggest database can be loaded into RAM . This can also accelerate searching on a computer cluster , where every node searches a part of the database. After performing database searching, search results on all small databases can be merged with kmcp merge for downstream analysis. A). Databases for metagenomic profiling These databases are created following steps below . Users can also build custom databases , it's simple and fast. DB source #species #assemblies parameters archive file size Bacteria and Archaea GTDB r202 43252 47894 k=21, frags=10 gtdb.kmcp.tar.gz (50.16 GB, md5 ) 58.02 GB Bacteria and Archaea HumGut 23604 30691 k=21, frags=10 humgut.kmcp.tar.gz (18.70 GB, md5 ) 21.52 GB Fungi Refseq r208 161 403 k=21, frags=10 refseq-fungi.kmcp.tar.gz (3.67 GB, md5 ) 4.18 GB Viruses GenBank 246 19584 27936 k=21, frags=5 genbank-viral.kmcp.tar.gz (1.15 GB, md5 ) 3.75 GB Viruses Refseq r208 7189 11618 k=21, frags=5 refseq-viral.kmcp.tar.gz (967 MB, md5 ) 2.00 GB Human CHM13 1 1 k=21, frags=1024 human-chm13.kmcp.tar.gz (818 MB, md5 ) 946 MB Taxonomy data : Taxonomy dump file: taxdump.tar.gz (2021-12-06, md5 ) Taxonomy data for HumGut : Taxonomy dump file: taxdump-humgut.tar.gz ( md5 ) Taxid mapping file: taxid-humgut.map ( md5 ) Name mapping file: name-humgut.map ( md5 ) B). Databases for genome similarity estimation Check the tutorial . FracMinHash (Scaled MinHash): kingdoms source parameters file size Bacteria and Archaea GTDB r202 k=31, scale=1000 gtdb.minhash.kmcp.tar.gz (710 MB, md5 ) 1.52 GB Fungi Refseq r208 k=31, scale=1000 refseq-fungi.minhash.kmcp.tar.gz (49 MB, md5 ) 98 MB Viruses Genbank 246 k=31, scale=10 genbank-viral.minhash.kmcp.tar.gz (580 MB, md5 ) 1.19 GB Viruses Refseq r208 k=31, scale=10 refseq-viral.minhash.kmcp.tar.gz (205 MB, md5 ) 555 MB Closed Syncmers: kingdoms source parameters file size Bacteria and Archaea GTDB r202 k=31, s=15, scale=60 gtdb.syncmer.kmcp.tar.gz (1.03 GB, md5 ) 2.28 GB Fungi Refseq r208 k=31, s=15, scale=60 refseq-fungi.syncmer.kmcp.tar.gz (73 MB, md5 ) 145 MB Viruses Genbank 246 k=31, s=10 genbank-viral.syncmer.kmcp.tar.gz (473 MB, md5 ) 1.06 GB Viruses Refseq r208 k=31, s=21 refseq-viral.syncmer.kmcp.tar.gz (162 MB, md5 ) 441 MB C). Databases of plasmid source # assembly type parameters file size Refseq r208 37318 All k-mers k=21 refseq-plasmid.kmcp.tar.gz (5.29 GB, md5 ) 7.80 GB Refseq r208 37318 FracMinHash K=31, scale=10 refseq-plasmid.minhash.kmcp.tar.gz (1.01 GB, md5 ) 2.00 GB Refseq r208 37318 Closed Syncmer K=31, s=21 refseq-plasmid.syncmer.kmcp.tar.gz (806 MB, md5 ) 1.54 GB Building databases GTDB Tools: brename for batching renaming files. rush for executing jobs in parallel. seqkit for FASTA file processing. kmcp for metagenomic profiling. Files: gtdb_genomes_reps_r202.tar.gz ar122_metadata_r202.tar.gz bac120_metadata_r202.tar.gz Uncompressing and renaming: # uncompress mkdir -p gtdb tar -zxvf gtdb_genomes_reps_r202.tar.gz -O gtdb # rename brename -R -p '^(\\w{3}_\\d{9}\\.\\d+).+' -r '$1.fna.gz' gtdb Mapping file: tar -zxvf ar122_metadata_r202.tar.gz bac120_metadata_r202.tar.gz # assembly accesion -> full head find gtdb/ -name \"*.fna.gz\" \\ | rush -k 'echo -ne \"{%@(.+).fna}\\t$(seqkit head -n 1 {} | seqkit seq -n)\\n\" ' \\ > name.map # assembly accesion -> taxid (cat ar122_metadata_r202.tsv; sed 1d bac120_metadata_r202.tsv) \\ | csvtk cut -t -f accession,ncbi_taxid \\ | csvtk replace -t -p '^.._' \\ | csvtk grep -t -P <(cut -f 1 name.map) \\ | csvtk del-header \\ > taxid.map # stats (optional) # number of species/strains cat taxid.map \\ | taxonkit lineage -i 2 -r -n -L \\ | csvtk freq -Ht -f 4 -nr \\ | csvtk pretty -H -t \\ | tee taxid.map.stats species 43566 strain 4108 subspecies 111 forma specialis 58 no rank 26 isolate 24 serotype 1 # number of unique species/strains cat taxid.map \\ | csvtk uniq -Ht -f 2 \\ | taxonkit lineage -i 2 -r -n -L \\ | csvtk freq -Ht -f 4 -nr \\ | csvtk pretty -H -t \\ | tee taxid.map.uniq.stats species 24739 strain 4101 subspecies 89 forma specialis 58 no rank 26 isolate 24 serotype 1 Building database (all k-mers, for profiling on short-reads): input=gtdb # compute k-mers # sequence containing \"plasmid\" in name are ignored, # reference genomes are splitted into 10 fragments with 100bp overlap # k = 21 kmcp compute -I $input -O gtdb-r202-k21-n10 -k 21 -n 10 -l 100 -B plasmid \\ --log gtdb-r202-k21-n10.log -j 32 --force # build database # number of index files: 32, for server with >= 32 CPU cores # bloom filter parameter: # number of hash function: 1 # false positive rate: 0.3 kmcp index -j 32 -I gtdb-r202-k21-n10 -O gtdb.kmcp -n 1 -f 0.3 \\ --log gtdb.kmcp.log # cp taxid and name mapping file to database directory cp taxid.map name.map gtdb.kmcp/ Building database (k-mer sketches, for profiling on long-reads): # ------------------------------------------------------------------------------------- # Closed Syncmers with s=16 input=gtdb # compute k-mers # sequence containing \"plasmid\" in name are ignored, # reference genomes are splitted into 10 fragments with 100bp overlap # k = 21 # s = 16 # Closed Syncmers kmcp compute -I $input -O gtdb-r202-k21-n10-S16 -k 21 -S 16 -n 10 -l 100 -B plasmid \\ --log gtdb-r202-k21-n10-S16.log -j 32 --force # build database # number of index files: 32, for server with >= 32 CPU cores # bloom filter parameter: # number of hash function: 1 # false positive rate: 0.2 kmcp index -j 32 -I gtdb-r202-k21-n10-S16 -O gtdb.sync16.kmcp -n 1 -f 0.2 \\ --log gtdb.sync16.kmcp.log # cp taxid and name mapping file to database directory cp taxid.map name.map gtdb.sync16.kmcp/ # ------------------------------------------------------------------------------------- # FracMinhash/Scaled MinHash with d=5 input=gtdb # compute k-mers # sequence containing \"plasmid\" in name are ignored, # reference genomes are splitted into 10 fragments with 100bp overlap # k = 21 # D = 5 # FracMinhash kmcp compute -I $input -O gtdb-r202-k21-n10-D5 -k 21 -D 5 -n 10 -l 100 -B plasmid \\ --log gtdb-r202-k21-n10-D5.log -j 32 --force # build database # number of index files: 32, for server with >= 32 CPU cores # bloom filter parameter: # number of hash function: 1 # false positive rate: 0.2 kmcp index -j 32 -I gtdb-r202-k21-n10-D5 -O gtdb.minh5.kmcp -n 1 -f 0.2 \\ --log gtdb.minh5.kmcp.log # cp taxid and name mapping file to database directory cp taxid.map name.map gtdb.minh5.kmcp/ # ------------------------------------------------------------------------------------- # Minimizer with W=5 input=gtdb # compute k-mers # sequence containing \"plasmid\" in name are ignored, # reference genomes are splitted into 10 fragments with 100bp overlap # k = 21 # W = 5 # Minimizer kmcp compute -I $input -O gtdb-r202-k21-n10-W5 -k 21 -W 5 -n 10 -l 100 -B plasmid \\ --log gtdb-r202-k21-n10-W5.log -j 32 --force # build database # number of index files: 32, for server with >= 32 CPU cores # bloom filter parameter: # number of hash function: 1 # false positive rate: 0.2 kmcp index -j 32 -I gtdb-r202-k21-n10-W5 -O gtdb.mini5.kmcp -n 1 -f 0.2 \\ --log gtdb.mini5.kmcp.log # cp taxid and name mapping file to database directory cp taxid.map name.map gtdb.mini5.kmcp/ Building small databases (all k-mers, for profiling with a computer cluster): input=gtdb find $input -name \"*.fna.gz\" > $input.files.txt # number of databases n=16 # split into $n chunks split -n l/$n $chunksize -d $input.files.txt $input.n$n- # create database for every chunks for f in $input.n$n-*; do echo $f # compute k-mers # sequence containing \"plasmid\" in name are ignored, # reference genomes are splitted into 10 fragments with 100bp overlap # k = 21 kmcp compute -i $f -O $f-k21-n10 -k 21 -n 10 -l 100 -B plasmid \\ --log $f-k21-n10.log -j 24 --force # build database # number of index files: 24, for server with >= 24 CPU cores # bloom filter parameter: # number of hash function: 1 # false positive rate: 0.3 kmcp index -j 24 -I $f-k21-n10 -O $f.kmcp -n 1 -f 0.3 \\ --log $f.kmcp.log # cp taxid and name mapping file to database directory cp taxid.map name.map $f.kmcp/ done RefSeq viral or fungi Tools genome_updater for downloading genomes from NCBI. Downloading viral and fungi sequences: # name=fungi name=viral # -k for dry-run # -i for fix time genome_updater.sh \\ -d \"refseq\"\\ -g $name \\ -c \"all\" \\ -l \"all\" \\ -f \"genomic.fna.gz\" \\ -o \"refseq-$name\" \\ -t 12 \\ -m -a -p # cd to 2021-09-30_19-35-19 # taxdump mkdir -p taxdump tar -zxvf taxdump.tar.gz -C taxdump # assembly accesion -> taxid cut -f 1,6 assembly_summary.txt > taxid.map # assembly accesion -> name cut -f 1,8 assembly_summary.txt > name.map # stats (optional) cat taxid.map \\ | csvtk freq -Ht -f 2 -nr \\ | taxonkit lineage -r -n -L --data-dir taxdump/ \\ | taxonkit reformat -I 1 -f '{k}\\t{p}\\t{c}\\t{o}\\t{f}\\t{g}\\t{s}' --data-dir taxdump/ \\ | csvtk add-header -t -n 'taxid,count,name,rank,superkindom,phylum,class,order,family,genus,species' \\ > taxid.map.stats.tsv seqkit stats -T -j 12 --infile-list <(find files -name \"*.fna.gz\") > files.stats.tsv # ------------------------------------------------------ # create another directory linking to genome files input=files.renamed mkdir -p $input # create soft links cd $input find ../files -name \"*.fna.gz\" \\ | rush 'ln -s {}' cd .. # rename brename -R -p '^(\\w{3}_\\d{9}\\.\\d+).+' -r '$1.fna.gz' $input Building database (all k-mers, for profiling on short-reads): # ----------------------------------------------------------------- # for viral, only splitting into 5 fragments name=viral input=files.renamed # ------------- # all kmers kmcp compute -I $input -O refseq-$name-k21-n5 \\ -k 21 --seq-name-filter plasmid \\ --split-number 5 --split-overlap 100 \\ --log refseq-$name-k21-n5.log -j 32 --force # viral genomes are small: # using small false positive rate: 0.001 # using more hash functions: 3 kmcp index -I refseq-$name-k21-n5/ -O refseq-viral.kmcp \\ -j 32 -f 0.001 -n 3 -x 100K \\ --log refseq-viral.kmcp.log --force # cp taxid and name mapping file to database directory cp taxid.map name.map refseq-viral.kmcp/ # ----------------------------------------------------------------- # for fungi name=fungi input=files.renamed # ------------- # all kmers kmcp compute -I $input -O refseq-$name-k21-n10 \\ -k 21 --seq-name-filter plasmid \\ --split-number 10 --split-overlap 100 \\ --log refseq-$name-k21-n10.log -j 32 --force kmcp index -I refseq-$name-k21-n10/ -O refseq-fungi.kmcp \\ -j 32 -f 0.3 -n 1 \\ --log refseq-fungi.kmcp.log --force # cp taxid and name mapping file to database directory cp taxid.map name.map refseq-fungi.kmcp/ Building database (k-mer sketches, for profiling on long-reads): # ----------------------------------------------------------------- # for viral, only splitting into 5 fragments name=viral input=files.renamed # --------------------------------------------- # here we compute Closed Syncmers with s=16 kmcp compute -I $input -O refseq-$name-k21-n5-S16 \\ -k 21 -S 16 --seq-name-filter plasmid \\ --split-number 5 --split-overlap 100 \\ --log refseq-$name-k21-n5-S16.log -j 32 --force # viral genomes are small: # using small false positive rate: 0.001 # using more hash functions: 3 kmcp index -I refseq-$name-k21-n5-S16/ -O refseq-viral.sync16.kmcp \\ -j 32 -f 0.001 -n 3 -x 100K \\ --log refseq-viral.sync16.kmcp.log --force # cp taxid and name mapping file to database directory cp taxid.map name.map refseq-viral.sync16.kmcp/ # --------------------------------------------- # here we compute FracMinHash with D=5 kmcp compute -I $input -O refseq-$name-k21-n5-D5 \\ -k 21 -D 5 --seq-name-filter plasmid \\ --split-number 5 --split-overlap 100 \\ --log refseq-$name-k21-n5-D5.log -j 32 --force # viral genomes are small: # using small false positive rate: 0.001 # using more hash functions: 3 kmcp index -I refseq-$name-k21-n5-D5/ -O refseq-viral.minh5.kmcp \\ -j 32 -f 0.001 -n 3 -x 100K \\ --log refseq-viral.minh5.kmcp.log --force # cp taxid and name mapping file to database directory cp taxid.map name.map refseq-viral.minh5.kmcp/ # ----------------------------------------------------------------- # for fungi name=fungi input=files.renamed # --------------------------------------------- # here we compute Closed Syncmers with s=16 kmcp compute -I $input -O refseq-$name-k21-n10-S16 \\ -k 21 -S 16 --seq-name-filter plasmid \\ --split-number 10 --split-overlap 100 \\ --log refseq-$name-k21-n10-S16.log -j 32 --force kmcp index -I refseq-$name-k21-n10-S16/ -O refseq-fungi.sync16.kmcp \\ -j 32 -f 0.2 -n 1 \\ --log refseq-fungi.sync16.kmcp.log --force # cp taxid and name mapping file to database directory cp taxid.map name.map refseq-fungi.sync16.kmcp/ # --------------------------------------------- # here we compute FracMinHash with D=5 kmcp compute -I $input -O refseq-$name-k21-n10-D5 \\ -k 21 -D 5 --seq-name-filter plasmid \\ --split-number 10 --split-overlap 100 \\ --log refseq-$name-k21-n10-D5.log -j 32 --force kmcp index -I refseq-$name-k21-n10-D5/ -O refseq-fungi.minh5.kmcp \\ -j 32 -f 0.2 -n 1 \\ --log refseq-fungi.minh5.kmcp.log --force # cp taxid and name mapping file to database directory cp taxid.map name.map refseq-fungi.minh5.kmcp/ # --------------------------------------------- # here we compute Minimizer with W=5 kmcp compute -I $input -O refseq-$name-k21-n10-W5 \\ -k 21 -W 5 --seq-name-filter plasmid \\ --split-number 10 --split-overlap 100 \\ --log refseq-$name-k21-n10-W5.log -j 32 --force kmcp index -I refseq-$name-k21-n10-W5/ -O refseq-fungi.mini5.kmcp \\ -j 32 -f 0.2 -n 1 \\ --log refseq-fungi.mini5.kmcp.log --force # cp taxid and name mapping file to database directory cp taxid.map name.map refseq-fungi.mini5.kmcp/ Genbank viral Tools genome_updater for downloading genomes from NCBI. Downloading viral sequences: name=viral # -k for dry-run # -i for fix time genome_updater.sh \\ -d \"genbank\"\\ -g $name \\ -c \"all\" \\ -l \"all\" \\ -f \"genomic.fna.gz\" \\ -o \"genbank-$name\" \\ -t 12 \\ -m -a -p # cd genbank-viral/2021-12-06_15-27-37/ # taxdump mkdir -p taxdump tar -zxvf taxdump.tar.gz -C taxdump # assembly accesion -> taxid cut -f 1,6 assembly_summary.txt > taxid.map # assembly accesion -> name cut -f 1,8 assembly_summary.txt > name.map # stats (optional) cat taxid.map \\ | csvtk freq -Ht -f 2 -nr \\ | taxonkit lineage -r -n -L --data-dir taxdump/ \\ | taxonkit reformat -I 1 -f '{k}\\t{p}\\t{c}\\t{o}\\t{f}\\t{g}\\t{s}' --data-dir taxdump/ \\ | csvtk add-header -t -n 'taxid,count,name,rank,superkindom,phylum,class,order,family,genus,species' \\ > taxid.map.stats.tsv seqkit stats -T -j 12 --infile-list <(find files -name \"*.fna.gz\") > files.stats.tsv # ------------------------------------------------------ # create another directory linking to genome files input=files.renamed mkdir -p $input # create soft links cd $input find ../files -name \"*.fna.gz\" \\ | rush 'ln -s {}' cd .. # rename brename -R -p '^(\\w{3}_\\d{9}\\.\\d+).+' -r '$1.fna.gz' $input keep at most 5 genomes for a taxid: # ----------------------------------------------------------------- # keep at most 5 genomes for a taxid # backup cat taxid.map > taxid.all.map cat name.map > name.all.map # keep at most 5 ids for a taxid cat taxid.all.map \\ | csvtk sort -Ht -k 2:n -k 1:n \\ | csvtk uniq -Ht -f 2 -n 5 \\ > taxid.map cat name.all.map \\ | csvtk grep -Ht -P <(cut -f 1 taxid.map) \\ > name.map # organize files input=files.renamed output=files.renamed.slim mkdir -p $output cd $output find ../$input -name \"*.fna.gz\" \\ | csvtk mutate -Ht -p '/([^\\/]+).fna.gz' \\ | csvtk grep -Ht -f 2 -P <(cut -f 1 ../taxid.map) \\ | rush 'ln -s {1}' cd .. # check number of genomes ls $output | wc -l wc -l taxid.map Building database (all k-mers, for profiling on short-reads): # ----------------------------------------------------------------- # for viral, only splitting into 5 fragments name=viral input=files.renamed.slim # ---------------- # all kmers kmcp compute -I $input -O genbank-$name-k21-n5 \\ -k 21 --seq-name-filter plasmid \\ --split-number 5 --split-overlap 100 \\ --log genbank-$name-k21-n5.log -j 32 --force # viral genomes are small: # using small false positive rate: 0.05 # still using one hash function: 1 kmcp index -I genbank-$name-k21-n5/ -O genbank-viral.kmcp \\ -j 32 -f 0.05 -n 1 -x 100K -8 1M \\ --log genbank-viral.kmcp.log --force # cp taxid and name mapping file to database directory cp taxid.map name.map genbank-viral.kmcp/ Building database (k-mer sketches, for profiling on long-reads): name=viral input=files.renamed.slim # ---------------------------------------------- # here we compute Closed Syncmers with s=16 kmcp compute -I $input -O genbank-$name-k21-n5-S16 \\ -k 21 -S 16 --seq-name-filter plasmid \\ --split-number 5 --split-overlap 100 \\ --log genbank-$name-k21-n5-S16.log -j 32 --force # viral genomes are small: # using small false positive rate: 0.001 # using more hash functions: 3 kmcp index -I genbank-$name-k21-n5-S16/ -O genbank-viral.sync16.kmcp \\ -j 32 -f 0.001 -n 3 -x 50K -8 1M \\ --log genbank-viral.sync16.kmcp.log --force # cp taxid and name mapping file to database directory cp taxid.map name.map genbank-viral.sync16.kmcp/ # ---------------------------------------------- # here we compute FracMinHash with D=5 kmcp compute -I $input -O genbank-$name-k21-n5-D5 \\ -k 21 -D 5 --seq-name-filter plasmid \\ --split-number 5 --split-overlap 100 \\ --log genbank-$name-k21-n5-D5.log -j 32 --force # viral genomes are small: # using small false positive rate: 0.001 # using more hash functions: 3 kmcp index -I genbank-$name-k21-n5-D5/ -O genbank-viral.minh5.kmcp \\ -j 32 -f 0.001 -n 3 -x 50K -8 1M \\ --log genbank-viral.minh5.kmcp.log --force # cp taxid and name mapping file to database directory cp taxid.map name.map genbank-viral.minh5.kmcp/ # ---------------------------------------------- # here we compute Minimizer with W=5 kmcp compute -I $input -O genbank-$name-k21-n5-W5 \\ -k 21 -W 5 --seq-name-filter plasmid \\ --split-number 5 --split-overlap 100 \\ --log genbank-$name-k21-n5-W5.log -j 32 --force # viral genomes are small: # using small false positive rate: 0.001 # using more hash functions: 3 kmcp index -I genbank-$name-k21-n5-W5/ -O genbank-viral.mini5.kmcp \\ -j 32 -f 0.001 -n 3 -x 50K -8 1M \\ --log genbank-viral.mini5.kmcp.log --force # cp taxid and name mapping file to database directory cp taxid.map name.map genbank-viral.mini5.kmcp/ Building small databases (all k-mers, for profiling with a computer cluster): name=genbank-viral input=files.renamed.slim find $input -name \"*.fna.gz\" > $input.files.txt # number of databases n=4 # split into $n chunks split -n l/$n $chunksize -d $input.files.txt $name.n$n- # create database for every chunks for f in $name.n$n-*; do echo $f kmcp compute -i $f -O $f-k21-n5 \\ -k 21 --seq-name-filter plasmid \\ --split-number 5 --split-overlap 100 \\ --log $f-k21-n5.log -j 32 --force # viral genomes are small: # using small false positive rate: 0.001 # using more hash functions: 3 kmcp index -I $f-k21-n5/ -O $f.kmcp \\ -j 32 -f 0.05 -n 1 -x 100K -8 1M \\ --log $f.kmcp.log --force # cp taxid and name mapping file to database directory cp taxid.map name.map $f.kmcp/ done Human genome Downloading human genome file from CHM13 : wget https://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/009/914/755/GCA_009914755.3_CHM13_T2T_v1.1/GCA_009914755.3_CHM13_T2T_v1.1_genomic.fna.gz Building database (all k-mers, < 6min): input=GCA_009914755.3_CHM13_T2T_v1.1_genomic.fna.gz # splitting human genome into 1024 fragments. # The regular expression '^(\\w{3}_\\d{9}\\.\\d+).+' is for extracting 'GCA_009914755.3' from the file name. kmcp compute $input -O human-chm13-k21-n1024 \\ --ref-name-regexp '^(\\w{3}_\\d{9}\\.\\d+).+' \\ -k 21 \\ --split-number 1024 --split-overlap 100 \\ --log human-chm13-k21-n1024.log -j 32 --force # using small false positive rate: 0.3 # using more hash functions: 1 kmcp index -I human-chm13-k21-n1024/ -O human-chm13.kmcp \\ -j 8 -f 0.3 -n 1 \\ --log human-chm13.kmcp.log --force # taxid.map echo -ne \"GCA_009914755.3\\t9606\\n\" > taxid.map # name.mapp echo -ne \"GCA_009914755.3\\tHomo sapiens isolate CHM13\\n\" > name.map # cp name mapping file to database directory cp taxid.map name.map human-chm13.kmcp/ Refseq plasmid Downloading plasmid sequences: wget https://ftp.ncbi.nlm.nih.gov/refseq/release/plasmid/ cat index.html \\ | perl -ne 'next unless /\"(plasmid.*genomic.fna.gz)\"/; print \"$1\\n\"' > files.txt baseurl=https://ftp.ncbi.nlm.nih.gov/refseq/release/plasmid/ outdir=archives; mkdir -p $outdir cat files.txt \\ | rush -j 12 -v b=$baseurl -v out=$outdir \\ 'wget -c {b}/{} -o /dev/null -O {out}/{}' -c -C download.rush # name mapping seqkit seq -n archives/*.fna.gz \\ | sed -E 's/\\s+/\\t/' \\ > name.map # length stats seqkit stats -b -a -j 12 -T archives/*.fna.gz > archives.stats.tsv # split to individual files for f in archives/*.fna.gz; do \\ seqkit split2 -s 1 --quiet $f -O refseq-plasmid; \\ done # rename files with sequence ID find refseq-plasmid -name \"*.fna.gz\" \\ | rush 'mv {} {/}/$(seqkit seq -ni {}).fna.gz' Building database (all k-mers): name=plasmid input=refseq-plasmid kmcp compute -I $input -O refseq-$name-k21-n5 \\ -k 21 --circular \\ --split-number 5 --split-overlap 100 \\ --log refseq-$name-k21-n5.log -j 32 --force # using small false positive rate: 0.01 # using more hash functions: 3 kmcp index -I refseq-$name-k21-n5/ -O refseq-$name.kmcp \\ -j 32 -f 0.01 -n 3 -x 200K -X 1024 \\ --log refseq-$name.kmcp.log --force # cp name mapping file to database directory cp name.map refseq-$name.kmcp/ Building database (FracMinHash/Scaled MinHash): name=plasmid input=refseq-plasmid kmcp compute -I $input -O refseq-$name-k31-D10 \\ -k 31 --circular --scale 10 \\ --log refseq-$name-k31-D10.log -j 32 --force # using small false positive rate: 0.01 # using more hash functions: 3 kmcp index -I refseq-$name-k31-D10/ -O refseq-$name.minhash.kmcp \\ -j 8 -f 0.01 -n 3 -x 100K -X 1024 \\ --log refseq-$name.minhash.kmcp.log --force # cp name mapping file to database directory cp name.map refseq-$name.minhash.kmcp/ Building database (Closed Syncmer): name=plasmid input=refseq-plasmid kmcp compute -I $input -O refseq-$name-k31-S21 \\ -k 31 --circular --syncmer-s 21 \\ --log refseq-$name-k31-S21.log -j 32 --force # using small false positive rate: 0.01 # using more hash functions: 3 kmcp index -I refseq-$name-k31-S21/ -O refseq-$name.syncmer.kmcp \\ -j 8 -f 0.01 -n 3 -x 100K -X 1024 \\ --log refseq-$name.syncmer.kmcp.log --force # cp name mapping file to database directory cp name.map refseq-$name.syncmer.kmcp/ HumGut HumGut is a comprehensive Human Gut prokaryotic genomes collection filtered by metagenome data. Dataset Genomes: HumGut.tar.gz Metadata: HumGut.tsv Taxdump files: NCBI taxonomy: ncbi_names.dump and ncbi_nodes.dump GTDB taxomomy: gtdb_names.dump and gtdb_nodes.dump Uncompressing and renaming: # uncompress tar -zxvf HumGut.tar.gz # taxdump files mkdir taxdump mv ncbi_names.dmp taxdump/names.dmp mv ncbi_nodes.dmp taxdump/nodes.dmp Mapping file: # assembly accesion -> taxid cat HumGut.tsv \\ | csvtk cut -t -f genome_file,ncbi_tax_id \\ | csvtk replace -f genome_file -t -p '\\..+$' \\ | csvtk del-header \\ > taxid.map # assembly accesion -> name cat HumGut.tsv \\ | csvtk cut -t -f genome_file,ncbi_organism_name \\ | csvtk replace -f genome_file -t -p '\\..+$' \\ | csvtk del-header \\ > name.map Stats: # ------------------------------------------------------------- # NCBI taxonomy # number of species/strains cat taxid.map \\ | taxonkit lineage --data-dir taxdump-ncbi -i 2 -r -n -L \\ | csvtk freq -Ht -f 4 -nr \\ | csvtk pretty -H -t \\ | tee taxid.map.stats species 23604 strain 6816 subspecies 161 no rank 69 serotype 38 genus 3 # number of unique species/strains cat taxid.map \\ | csvtk uniq -Ht -f 2 \\ | taxonkit lineage --data-dir taxdump-ncbi -i 2 -r -n -L \\ | csvtk freq -Ht -f 4 -nr \\ | csvtk pretty -H -t \\ | tee taxid.map.uniq.stats; species 1240 strain 458 subspecies 15 genus 1 no rank 1 serotype 1 # ------------------------------------------------------------- # GTDB taxonomy cat HumGut.tsv \\ | csvtk cut -t -f genome_file,gtdbtk_tax_id \\ | csvtk replace -f genome_file -t -p '\\..+$' \\ | csvtk del-header \\ > taxid-gtdb.map cat taxid-gtdb.map \\ | csvtk uniq -Ht -f 2 \\ | taxonkit lineage --data-dir taxdump-gtdb -i 2 -r -n -L \\ | csvtk freq -Ht -f 4 -nr \\ | csvtk pretty -H -t \\ | tee taxid-gtdb.map.uniq.stats species 2810 genus 434 family 52 order 12 class 2 Building database: # compute k-mers # sequence containing \"plasmid\" in name are ignored, # reference genomes are splitted into 10 fragments # k = 21 kmcp compute -I fna/ -k 21 -n 10 -B plasmid -O humgut-k21-n10 -j 32 --force # build database # number of index files: 32, for server with >= 32 CPU cores # bloom filter parameter: # number of hash function: 1 # false positive rate: 0.3 kmcp index -j 32 -I humgut-k21-n10 -O humgut.kmcp -n 1 -f 0.3 cp taxid.map taxid-gtdb.map humgut.kmcp/ proGenomes2 proGenomes v2.1 provides 84,096 consistently annotated bacterial and archaeal genomes from over 12000 species Dataset: Representative genomes: contigs.representatives.fasta.gz NCBI taxonomy: proGenomes2.1_specI_lineageNCBI.tab Organize sequences: # download wget https://progenomes.embl.de/data/repGenomes/freeze12.contigs.representatives.fasta.gz # unzip for splitting by genome ID time seqkit seq freeze12.contigs.representatives.fasta.gz -o freeze12.contigs.representatives.fasta # split by genome ID seqkit split --by-id --two-pass --id-regexp '(^\\d+\\.\\w+)\\.' freeze12.contigs.representatives.fasta --out-dir genomes # batch rename brename -p '^.+id_' genomes # compress genomes for saving space find genomes/ -name \"*.fasta\" | rush 'gzip {}' Mapping file: # download wget https://progenomes.embl.de/data/proGenomes2.1_specI_lineageNCBI.tab ls genomes/ | sed 's/.fasta.gz//' > id.txt # id -> taxid cut -f 1 proGenomes2.1_specI_lineageNCBI.tab \\ | awk -F . '{print $0\"\\t\"$1}' \\ | csvtk grep -Ht -P id.txt \\ > taxid.map cat taxid.map \\ | csvtk uniq -Ht -f 2 \\ | taxonkit lineage --data-dir taxdump -i 2 -r -n -L \\ | csvtk freq -Ht -f 4 -nr \\ | csvtk pretty -H -t \\ | tee taxid.map.uniq.stats species 8088 strain 3262 subspecies 37 isolate 25 no rank 16 forma specialis 14 biotype 1 # use the taxonomy verion of the refseq-virus: 2021-10-01 # id -> name cat taxid.map \\ | taxonkit lineage --data-dir taxdump -i 2 -n -L \\ | cut -f 1,3 \\ > name.map Building database: # compute k-mers # sequence containing \"plasmid\" in name are ignored, # reference genomes are splitted into 10 fragments # k = 21 kmcp compute -I genomes/ -k 21 -n 10 -B plasmid -O progenomes-k21-n10 --force # build database # number of index files: 32, for server with >= 32 CPU cores # bloom filter parameter: # number of hash function: 1 # false positive rate: 0.3 kmcp index -j 32 -I progenomes-k21-n10 -O progenomes.kmcp -n 1 -f 0.3 cp taxid.map name.map progenomes.kmcp/ Building custom databases Files: Genome files (Gzip-compressed) FASTA/Q format. One genome per file with the reference identifier in the file name. TaxId mapping file (for metagenomic profiling) Two-column (reference identifier and TaxId) tab-delimited. NCBI taxonomy dump files (for metagenomic profiling) names.dmp nodes.dmp merged.dmp (optional) delnodes.dmp (optional) Tools: kmcp for metagenomic profiling. rush for executing jobs in parallel. brename for batching renaming files (optional) Memory notes : By default, kmcp search loads the whole database into main memory (RAM) for fast searching. Optionally, the flag --low-mem can be set to avoid loading the whole database, while it's much slower, >10X slower on SSD and should be much slower on HDD disks. Another way is dividing the reference genomes into several parts and building smaller databases for all parts, so that the biggest database can be loaded into RAM. After performing database searching, search results on all small databases can be merged with kmcp merge for downstream analysis. Buiding small databases can also accelerate searching on a computer cluster , where every node searches a part of the database. Step 1. Computing k-mers Plain or gzip-compressed input genome sequence files better be saved in one directory, with multiple-level directories allowed. The file extension could be fa , fasta , fna , fq , fastq , fa.gz , fasta.gz , fna.gz , fq.gz or fastq.gz . Input files can be given as a list of FASTA/Q files via positional arguments or a directory (with multiple-level directories allowed) containing sequence files via the flag -I/--in-dir . A regular expression for matching sequencing files is available by the flag -r/--file-regexp . The default pattern matches files with extension of fa , fasta , fna , fq , fastq , fa.gz , fasta.gz , fna.gz , fq.gz or fastq.gz . Unwanted sequence like plasmid sequences can be filtered out by the name via regular expression(s) ( -B/--seq-name-filter ). How to compute k-mers : By default, kmcp computes k-mers (sketches) of every file, you can also use --by-seq to compute for every sequence, where sequence IDs in all input files better be distinct. It also supports splitting sequences into fragments, this could increase the specificity in profiling result in cost of slower searching speed . Splitting sequences : Sequences can be splitted into fragments by a fragment size ( -s/--split-size ) or number of fragments ( -n/--split-number ) with overlap (- l/--split-overlap ). When splitting by number of fragments, all sequences (except for these mathching any regular expression given by -B/--seq-name-filter ) in a sequence file are concatenated with k-1 Ns before splitting . Both sequence/reference IDs and fragments indices are saved for later use, in form of meta/description data in .unik files, and will be reported in kmcp search results. Meta data : Every outputted .unik file contains the sequence/reference ID, fragment index, number of fragments, and genome size of reference. When parsing whole sequence files or splitting by number of fragments, the identifier of a reference is the basename of the input file by default. It can also be extracted from the input file name via -N/--ref-name-regexp , e.g., ^(\\w{3}_\\d{9}\\.\\d+) for RefSeq assembly accessions . Multiple sizes of k-mers are supported, but a single k-mer size is good enough. Supported k-mer (sketches) types : K-mer: ntHash of k-mer ( -k ) K-mer sketchs (all using ntHash): Scaled MinHash ( -k -D ), reviously named Scaled MinHash Minimizer ( -k -W ), optionally scaling/down-sampling ( -D ) Closed Syncmer ( -k -S ), optionally scaling/down-sampling ( -D ) Output : All outputted .unik files are saved in ${outdir} , with path ${outdir}/xxx/yyy/zzz/${infile}-id_${seqID}.unik where dirctory tree /xxx/yyy/zzz/ is built for > 1000 output files. For splitting sequence mode ( --split-size > 0 or --split-number > 0 ), output files are: ${outdir}//xxx/yyy/zzz/${infile}/{seqID}-frag_${fragIdx}.unik A summary file ( ${outdir}/_info.txt ) is generated for later use. Users need to check if the reference IDs (column name ) are what supposed to be. Performance tips : Decrease value of -j/--threads for data in hard disk drives (HDD) to reduce I/O pressure. Commands ( usage ): # compute k-mers # sequence containing \"plasmid\" in name are ignored, # reference genomes are splitted into 10 fragments, # k = 21 kmcp compute --in-dir refs/ \\ --kmer 21 \\ --split-number 10 \\ --seq-name-filter plasmid \\ --ref-name-regexp '(.+).fasta.gz' \\ --out-dir refs-k21-n10 # demo output 22:33:10.685 [INFO] kmcp v0.7.0 22:33:10.685 [INFO] https://github.com/shenwei356/kmcp 22:33:10.685 [INFO] 22:33:10.685 [INFO] checking input files ... 22:33:10.685 [INFO] 9 input file(s) given 22:33:10.685 [INFO] 22:33:10.685 [INFO] -------------------- [main parameters] -------------------- 22:33:10.685 [INFO] input and output: 22:33:10.685 [INFO] input directory: refs/ 22:33:10.685 [INFO] regular expression of input files: (?i)\\.(f[aq](st[aq])?|fna)(.gz)?$ 22:33:10.685 [INFO] *regular expression for extracting reference name from file name: 22:33:10.685 [INFO] *regular expressions for filtering out sequences: [plasmid] 22:33:10.685 [INFO] output directory: refs-k21-n10 22:33:10.685 [INFO] 22:33:10.685 [INFO] sequences splitting: true 22:33:10.685 [INFO] split parts: 10, overlap: 0 bp 22:33:10.685 [INFO] 22:33:10.685 [INFO] k-mer (sketches) computing: 22:33:10.685 [INFO] k-mer size(s): 21 22:33:10.685 [INFO] circular genome: false 22:33:10.685 [INFO] saving exact number of k-mers: true 22:33:10.685 [INFO] 22:33:10.685 [INFO] -------------------- [main parameters] -------------------- 22:33:10.685 [INFO] 22:33:10.685 [INFO] computing ... processed files: 9 / 9 [======================================] ETA: 0s. done 22:33:11.121 [INFO] 22:33:11.121 [INFO] elapsed time: 436.367564ms 22:33:11.121 [INFO] A summary file ( _info.txt ) is generated for later use. Users need to check if the reference IDs (column name ) are what supposed to be . #path name fragIdx idxNum genomeSize kmers refs-k21-n10/672/060/672/NC_010655.1.fasta.gz/NC_010655.1-frag_0.unik NC_010655.1 0 10 2664102 264247 refs-k21-n10/672/060/672/NC_010655.1.fasta.gz/NC_010655.1-frag_1.unik NC_010655.1 1 10 2664102 266237 refs-k21-n10/595/162/595/NC_012971.2.fasta.gz/NC_012971.2-frag_0.unik NC_012971.2 0 10 4558953 450494 refs-k21-n10/292/039/292/NC_000913.3.fasta.gz/NC_000913.3-frag_0.unik NC_000913.3 0 10 4641652 459277 refs-k21-n10/934/859/934/NC_013654.1.fasta.gz/NC_013654.1-frag_0.unik NC_013654.1 0 10 4717338 470575 Meta data in the .unik file can be showed using kmcp utils unik-info : kmcp utils unik-info refs-k21-n10/072/380/072/NZ_CP028116.1.fasta.gz/NZ_CP028116.1-frag_0.unik -a Step 2. Building databases KMCP builds index for k-mers (sketches) with a modified Compact Bit-sliced Signature Index ( COBS ). We totally rewrite the algorithms, data structure and file format, and have improved the indexing and searching speed (check benchmark ). Input : The output directory generated by kmcp compute . Database size and searching accuracy : Use --dry-run to adjust parameters and check final number of index files (#index-files) and the total file size . -f/--false-positive-rate : the default value 0.3 is enough for a query with tens of matched k-mers (see BIGSI/COBS paper). Small values could largely increase the size of database. -n/--num-hash : large values could reduce the database size, in cost of slower searching speed. Values <=4 is recommended. Value of block size -b/--block-size better be multiple of 64. The default value is: (#unikFiles/#threads + 7) / 8 * 8 Use flag -x/--block-sizeX-kmers-t , -8/--block-size8-kmers-t , and -1/--block-size1-kmers-t to separately create index for inputs with huge number of k-mers, for precise control of database size. Taxonomy data : No taxonomy data are included in the database. Taxonomy information are only needed in kmcp profile . Performance tips : Number of blocks ( .uniki files) better be smaller than or equal to number of CPU cores for faster searching speed. We can set -j/--threads to control the blocks number . When more threads (>= 1.3 * #blocks) are given, extra workers are automatically created. #threads files are simultaneously opened, and the max number of opened files is limited by the flag -F/--max-open-files . You may use a small value of -F/--max-open-files for hard disk drive storage. When the database is used in a new computer with more CPU cores, kmcp search could automatically scale to utilize as many cores as possible. Commands ( usage ): # build database # number of index files: 32, for server with >= 32 CPU cores # bloom filter parameter: # number of hash function: 1 # false positive rate: 0.3 kmcp index -I refs-k21-n10 \\ --threads 32 \\ --num-hash 1 \\ --false-positive-rate 0.3 \\ --out-dir refs.kmcp # demo output 22:44:17.710 [INFO] kmcp v0.7.0 22:44:17.710 [INFO] https://github.com/shenwei356/kmcp 22:44:17.710 [INFO] 22:44:17.710 [INFO] loading .unik file infos from file: refs-k21-n10/_info.txt 22:44:17.716 [INFO] 90 cached file infos loaded 22:44:17.716 [INFO] 22:44:17.716 [INFO] -------------------- [main parameters] -------------------- 22:44:17.716 [INFO] number of hashes: 1 22:44:17.716 [INFO] false positive rate: 0.300000 22:44:17.717 [INFO] k-mer size(s): 21 22:44:17.717 [INFO] split seqequence size: 0, overlap: 0 22:44:17.717 [INFO] block-sizeX-kmers-t: 10.00 M 22:44:17.717 [INFO] block-sizeX : 256.00 22:44:17.717 [INFO] block-size8-kmers-t: 20.00 M 22:44:17.717 [INFO] block-size1-kmers-t: 200.00 M 22:44:17.717 [INFO] -------------------- [main parameters] -------------------- 22:44:17.717 [INFO] 22:44:17.717 [INFO] building index ... 22:44:17.726 [WARN] ignore -X/--block-size (256) which is >= -b/--block-size (8) 22:44:17.726 [INFO] 22:44:17.726 [INFO] block size: 8 22:44:17.726 [INFO] number of index files: 32 (may be more) 22:44:17.726 [INFO] 22:44:17.726 [block #001] 1 / 1 100 % 22:44:17.726 [block #002] 1 / 1 100 % 22:44:17.726 [block #003] 1 / 1 100 % 22:44:17.726 [block #004] 1 / 1 100 % 22:44:17.726 [block #005] 1 / 1 100 % 22:44:17.726 [block #006] 1 / 1 100 % 22:44:17.726 [block #007] 1 / 1 100 % 22:44:17.726 [block #008] 1 / 1 100 % 22:44:17.726 [block #009] 1 / 1 100 % 22:44:17.727 [block #010] 1 / 1 100 % 22:44:17.727 [block #011] 1 / 1 100 % 22:44:17.727 [block #012] 1 / 1 100 % [saved index files] 12 / 12 ETA: 0s. done 22:44:17.933 [INFO] 22:44:17.933 [INFO] kmcp database with 42713316 k-mers saved to refs.kmcp 22:44:17.933 [INFO] total file size: 15.66 MB 22:44:17.933 [INFO] total index files: 12 22:44:17.933 [INFO] 22:44:17.933 [INFO] elapsed time: 223.524128ms 22:44:17.933 [INFO] Output: refs.kmcp/ \u2514\u2500\u2500 R001 \u251c\u2500\u2500 _block001.uniki \u251c\u2500\u2500 _block002.uniki \u251c\u2500\u2500 _block003.uniki \u251c\u2500\u2500 _block004.uniki \u251c\u2500\u2500 _block005.uniki \u251c\u2500\u2500 _block006.uniki \u251c\u2500\u2500 _block007.uniki \u251c\u2500\u2500 _block008.uniki \u251c\u2500\u2500 _block009.uniki \u251c\u2500\u2500 _block010.uniki \u251c\u2500\u2500 _block011.uniki \u251c\u2500\u2500 _block012.uniki \u251c\u2500\u2500 __db.yml \u2514\u2500\u2500 __name_mapping.tsv __db.yml contains configuration of the database, and _blockXXX.uniki are index files. kmcp utils index-info could show the basic information of index files: kmcp utils index-info refs.kmcp/R001/_block001.uniki file k canonical num-hashes num-sigs num-names refs.kmcp/R001/_block001.uniki 21 true 1 746442 8 What's next? Check the tutorials .","title":"Databases"},{"location":"database/#database","text":"","title":"Database"},{"location":"database/#prebuilt-databases","text":"All prebuilt database are available at: OneDrive for global users. CowTransfer for Chinese users, a command-line tool is recommended. Hardware requirements Prebuilt databases were built for computers with >= 32 CPU cores in consideration of better parallelization, and computers should have at least 64 GB. By default, kmcp search loads the whole database into main memory (via mmap ) for fast searching. Optionally, the flag --low-mem can be set to avoid loading the whole database, while it's much slower, >10X slower on SSD and should be much slower on HDD disks. To reduce memory requirements on computers without enough memory, users can divide the reference genomes into several parts and build smaller databases for all parts, so that the biggest database can be loaded into RAM . This can also accelerate searching on a computer cluster , where every node searches a part of the database. After performing database searching, search results on all small databases can be merged with kmcp merge for downstream analysis.","title":"Prebuilt databases"},{"location":"database/#a-databases-for-metagenomic-profiling","text":"These databases are created following steps below . Users can also build custom databases , it's simple and fast. DB source #species #assemblies parameters archive file size Bacteria and Archaea GTDB r202 43252 47894 k=21, frags=10 gtdb.kmcp.tar.gz (50.16 GB, md5 ) 58.02 GB Bacteria and Archaea HumGut 23604 30691 k=21, frags=10 humgut.kmcp.tar.gz (18.70 GB, md5 ) 21.52 GB Fungi Refseq r208 161 403 k=21, frags=10 refseq-fungi.kmcp.tar.gz (3.67 GB, md5 ) 4.18 GB Viruses GenBank 246 19584 27936 k=21, frags=5 genbank-viral.kmcp.tar.gz (1.15 GB, md5 ) 3.75 GB Viruses Refseq r208 7189 11618 k=21, frags=5 refseq-viral.kmcp.tar.gz (967 MB, md5 ) 2.00 GB Human CHM13 1 1 k=21, frags=1024 human-chm13.kmcp.tar.gz (818 MB, md5 ) 946 MB Taxonomy data : Taxonomy dump file: taxdump.tar.gz (2021-12-06, md5 ) Taxonomy data for HumGut : Taxonomy dump file: taxdump-humgut.tar.gz ( md5 ) Taxid mapping file: taxid-humgut.map ( md5 ) Name mapping file: name-humgut.map ( md5 )","title":"A). Databases for metagenomic profiling"},{"location":"database/#b-databases-for-genome-similarity-estimation","text":"Check the tutorial . FracMinHash (Scaled MinHash): kingdoms source parameters file size Bacteria and Archaea GTDB r202 k=31, scale=1000 gtdb.minhash.kmcp.tar.gz (710 MB, md5 ) 1.52 GB Fungi Refseq r208 k=31, scale=1000 refseq-fungi.minhash.kmcp.tar.gz (49 MB, md5 ) 98 MB Viruses Genbank 246 k=31, scale=10 genbank-viral.minhash.kmcp.tar.gz (580 MB, md5 ) 1.19 GB Viruses Refseq r208 k=31, scale=10 refseq-viral.minhash.kmcp.tar.gz (205 MB, md5 ) 555 MB Closed Syncmers: kingdoms source parameters file size Bacteria and Archaea GTDB r202 k=31, s=15, scale=60 gtdb.syncmer.kmcp.tar.gz (1.03 GB, md5 ) 2.28 GB Fungi Refseq r208 k=31, s=15, scale=60 refseq-fungi.syncmer.kmcp.tar.gz (73 MB, md5 ) 145 MB Viruses Genbank 246 k=31, s=10 genbank-viral.syncmer.kmcp.tar.gz (473 MB, md5 ) 1.06 GB Viruses Refseq r208 k=31, s=21 refseq-viral.syncmer.kmcp.tar.gz (162 MB, md5 ) 441 MB","title":"B). Databases for genome similarity estimation"},{"location":"database/#c-databases-of-plasmid","text":"source # assembly type parameters file size Refseq r208 37318 All k-mers k=21 refseq-plasmid.kmcp.tar.gz (5.29 GB, md5 ) 7.80 GB Refseq r208 37318 FracMinHash K=31, scale=10 refseq-plasmid.minhash.kmcp.tar.gz (1.01 GB, md5 ) 2.00 GB Refseq r208 37318 Closed Syncmer K=31, s=21 refseq-plasmid.syncmer.kmcp.tar.gz (806 MB, md5 ) 1.54 GB","title":"C). Databases of plasmid"},{"location":"database/#building-databases","text":"","title":"Building databases"},{"location":"database/#gtdb","text":"Tools: brename for batching renaming files. rush for executing jobs in parallel. seqkit for FASTA file processing. kmcp for metagenomic profiling. Files: gtdb_genomes_reps_r202.tar.gz ar122_metadata_r202.tar.gz bac120_metadata_r202.tar.gz Uncompressing and renaming: # uncompress mkdir -p gtdb tar -zxvf gtdb_genomes_reps_r202.tar.gz -O gtdb # rename brename -R -p '^(\\w{3}_\\d{9}\\.\\d+).+' -r '$1.fna.gz' gtdb Mapping file: tar -zxvf ar122_metadata_r202.tar.gz bac120_metadata_r202.tar.gz # assembly accesion -> full head find gtdb/ -name \"*.fna.gz\" \\ | rush -k 'echo -ne \"{%@(.+).fna}\\t$(seqkit head -n 1 {} | seqkit seq -n)\\n\" ' \\ > name.map # assembly accesion -> taxid (cat ar122_metadata_r202.tsv; sed 1d bac120_metadata_r202.tsv) \\ | csvtk cut -t -f accession,ncbi_taxid \\ | csvtk replace -t -p '^.._' \\ | csvtk grep -t -P <(cut -f 1 name.map) \\ | csvtk del-header \\ > taxid.map # stats (optional) # number of species/strains cat taxid.map \\ | taxonkit lineage -i 2 -r -n -L \\ | csvtk freq -Ht -f 4 -nr \\ | csvtk pretty -H -t \\ | tee taxid.map.stats species 43566 strain 4108 subspecies 111 forma specialis 58 no rank 26 isolate 24 serotype 1 # number of unique species/strains cat taxid.map \\ | csvtk uniq -Ht -f 2 \\ | taxonkit lineage -i 2 -r -n -L \\ | csvtk freq -Ht -f 4 -nr \\ | csvtk pretty -H -t \\ | tee taxid.map.uniq.stats species 24739 strain 4101 subspecies 89 forma specialis 58 no rank 26 isolate 24 serotype 1 Building database (all k-mers, for profiling on short-reads): input=gtdb # compute k-mers # sequence containing \"plasmid\" in name are ignored, # reference genomes are splitted into 10 fragments with 100bp overlap # k = 21 kmcp compute -I $input -O gtdb-r202-k21-n10 -k 21 -n 10 -l 100 -B plasmid \\ --log gtdb-r202-k21-n10.log -j 32 --force # build database # number of index files: 32, for server with >= 32 CPU cores # bloom filter parameter: # number of hash function: 1 # false positive rate: 0.3 kmcp index -j 32 -I gtdb-r202-k21-n10 -O gtdb.kmcp -n 1 -f 0.3 \\ --log gtdb.kmcp.log # cp taxid and name mapping file to database directory cp taxid.map name.map gtdb.kmcp/ Building database (k-mer sketches, for profiling on long-reads): # ------------------------------------------------------------------------------------- # Closed Syncmers with s=16 input=gtdb # compute k-mers # sequence containing \"plasmid\" in name are ignored, # reference genomes are splitted into 10 fragments with 100bp overlap # k = 21 # s = 16 # Closed Syncmers kmcp compute -I $input -O gtdb-r202-k21-n10-S16 -k 21 -S 16 -n 10 -l 100 -B plasmid \\ --log gtdb-r202-k21-n10-S16.log -j 32 --force # build database # number of index files: 32, for server with >= 32 CPU cores # bloom filter parameter: # number of hash function: 1 # false positive rate: 0.2 kmcp index -j 32 -I gtdb-r202-k21-n10-S16 -O gtdb.sync16.kmcp -n 1 -f 0.2 \\ --log gtdb.sync16.kmcp.log # cp taxid and name mapping file to database directory cp taxid.map name.map gtdb.sync16.kmcp/ # ------------------------------------------------------------------------------------- # FracMinhash/Scaled MinHash with d=5 input=gtdb # compute k-mers # sequence containing \"plasmid\" in name are ignored, # reference genomes are splitted into 10 fragments with 100bp overlap # k = 21 # D = 5 # FracMinhash kmcp compute -I $input -O gtdb-r202-k21-n10-D5 -k 21 -D 5 -n 10 -l 100 -B plasmid \\ --log gtdb-r202-k21-n10-D5.log -j 32 --force # build database # number of index files: 32, for server with >= 32 CPU cores # bloom filter parameter: # number of hash function: 1 # false positive rate: 0.2 kmcp index -j 32 -I gtdb-r202-k21-n10-D5 -O gtdb.minh5.kmcp -n 1 -f 0.2 \\ --log gtdb.minh5.kmcp.log # cp taxid and name mapping file to database directory cp taxid.map name.map gtdb.minh5.kmcp/ # ------------------------------------------------------------------------------------- # Minimizer with W=5 input=gtdb # compute k-mers # sequence containing \"plasmid\" in name are ignored, # reference genomes are splitted into 10 fragments with 100bp overlap # k = 21 # W = 5 # Minimizer kmcp compute -I $input -O gtdb-r202-k21-n10-W5 -k 21 -W 5 -n 10 -l 100 -B plasmid \\ --log gtdb-r202-k21-n10-W5.log -j 32 --force # build database # number of index files: 32, for server with >= 32 CPU cores # bloom filter parameter: # number of hash function: 1 # false positive rate: 0.2 kmcp index -j 32 -I gtdb-r202-k21-n10-W5 -O gtdb.mini5.kmcp -n 1 -f 0.2 \\ --log gtdb.mini5.kmcp.log # cp taxid and name mapping file to database directory cp taxid.map name.map gtdb.mini5.kmcp/ Building small databases (all k-mers, for profiling with a computer cluster): input=gtdb find $input -name \"*.fna.gz\" > $input.files.txt # number of databases n=16 # split into $n chunks split -n l/$n $chunksize -d $input.files.txt $input.n$n- # create database for every chunks for f in $input.n$n-*; do echo $f # compute k-mers # sequence containing \"plasmid\" in name are ignored, # reference genomes are splitted into 10 fragments with 100bp overlap # k = 21 kmcp compute -i $f -O $f-k21-n10 -k 21 -n 10 -l 100 -B plasmid \\ --log $f-k21-n10.log -j 24 --force # build database # number of index files: 24, for server with >= 24 CPU cores # bloom filter parameter: # number of hash function: 1 # false positive rate: 0.3 kmcp index -j 24 -I $f-k21-n10 -O $f.kmcp -n 1 -f 0.3 \\ --log $f.kmcp.log # cp taxid and name mapping file to database directory cp taxid.map name.map $f.kmcp/ done","title":"GTDB"},{"location":"database/#refseq-viral-or-fungi","text":"Tools genome_updater for downloading genomes from NCBI. Downloading viral and fungi sequences: # name=fungi name=viral # -k for dry-run # -i for fix time genome_updater.sh \\ -d \"refseq\"\\ -g $name \\ -c \"all\" \\ -l \"all\" \\ -f \"genomic.fna.gz\" \\ -o \"refseq-$name\" \\ -t 12 \\ -m -a -p # cd to 2021-09-30_19-35-19 # taxdump mkdir -p taxdump tar -zxvf taxdump.tar.gz -C taxdump # assembly accesion -> taxid cut -f 1,6 assembly_summary.txt > taxid.map # assembly accesion -> name cut -f 1,8 assembly_summary.txt > name.map # stats (optional) cat taxid.map \\ | csvtk freq -Ht -f 2 -nr \\ | taxonkit lineage -r -n -L --data-dir taxdump/ \\ | taxonkit reformat -I 1 -f '{k}\\t{p}\\t{c}\\t{o}\\t{f}\\t{g}\\t{s}' --data-dir taxdump/ \\ | csvtk add-header -t -n 'taxid,count,name,rank,superkindom,phylum,class,order,family,genus,species' \\ > taxid.map.stats.tsv seqkit stats -T -j 12 --infile-list <(find files -name \"*.fna.gz\") > files.stats.tsv # ------------------------------------------------------ # create another directory linking to genome files input=files.renamed mkdir -p $input # create soft links cd $input find ../files -name \"*.fna.gz\" \\ | rush 'ln -s {}' cd .. # rename brename -R -p '^(\\w{3}_\\d{9}\\.\\d+).+' -r '$1.fna.gz' $input Building database (all k-mers, for profiling on short-reads): # ----------------------------------------------------------------- # for viral, only splitting into 5 fragments name=viral input=files.renamed # ------------- # all kmers kmcp compute -I $input -O refseq-$name-k21-n5 \\ -k 21 --seq-name-filter plasmid \\ --split-number 5 --split-overlap 100 \\ --log refseq-$name-k21-n5.log -j 32 --force # viral genomes are small: # using small false positive rate: 0.001 # using more hash functions: 3 kmcp index -I refseq-$name-k21-n5/ -O refseq-viral.kmcp \\ -j 32 -f 0.001 -n 3 -x 100K \\ --log refseq-viral.kmcp.log --force # cp taxid and name mapping file to database directory cp taxid.map name.map refseq-viral.kmcp/ # ----------------------------------------------------------------- # for fungi name=fungi input=files.renamed # ------------- # all kmers kmcp compute -I $input -O refseq-$name-k21-n10 \\ -k 21 --seq-name-filter plasmid \\ --split-number 10 --split-overlap 100 \\ --log refseq-$name-k21-n10.log -j 32 --force kmcp index -I refseq-$name-k21-n10/ -O refseq-fungi.kmcp \\ -j 32 -f 0.3 -n 1 \\ --log refseq-fungi.kmcp.log --force # cp taxid and name mapping file to database directory cp taxid.map name.map refseq-fungi.kmcp/ Building database (k-mer sketches, for profiling on long-reads): # ----------------------------------------------------------------- # for viral, only splitting into 5 fragments name=viral input=files.renamed # --------------------------------------------- # here we compute Closed Syncmers with s=16 kmcp compute -I $input -O refseq-$name-k21-n5-S16 \\ -k 21 -S 16 --seq-name-filter plasmid \\ --split-number 5 --split-overlap 100 \\ --log refseq-$name-k21-n5-S16.log -j 32 --force # viral genomes are small: # using small false positive rate: 0.001 # using more hash functions: 3 kmcp index -I refseq-$name-k21-n5-S16/ -O refseq-viral.sync16.kmcp \\ -j 32 -f 0.001 -n 3 -x 100K \\ --log refseq-viral.sync16.kmcp.log --force # cp taxid and name mapping file to database directory cp taxid.map name.map refseq-viral.sync16.kmcp/ # --------------------------------------------- # here we compute FracMinHash with D=5 kmcp compute -I $input -O refseq-$name-k21-n5-D5 \\ -k 21 -D 5 --seq-name-filter plasmid \\ --split-number 5 --split-overlap 100 \\ --log refseq-$name-k21-n5-D5.log -j 32 --force # viral genomes are small: # using small false positive rate: 0.001 # using more hash functions: 3 kmcp index -I refseq-$name-k21-n5-D5/ -O refseq-viral.minh5.kmcp \\ -j 32 -f 0.001 -n 3 -x 100K \\ --log refseq-viral.minh5.kmcp.log --force # cp taxid and name mapping file to database directory cp taxid.map name.map refseq-viral.minh5.kmcp/ # ----------------------------------------------------------------- # for fungi name=fungi input=files.renamed # --------------------------------------------- # here we compute Closed Syncmers with s=16 kmcp compute -I $input -O refseq-$name-k21-n10-S16 \\ -k 21 -S 16 --seq-name-filter plasmid \\ --split-number 10 --split-overlap 100 \\ --log refseq-$name-k21-n10-S16.log -j 32 --force kmcp index -I refseq-$name-k21-n10-S16/ -O refseq-fungi.sync16.kmcp \\ -j 32 -f 0.2 -n 1 \\ --log refseq-fungi.sync16.kmcp.log --force # cp taxid and name mapping file to database directory cp taxid.map name.map refseq-fungi.sync16.kmcp/ # --------------------------------------------- # here we compute FracMinHash with D=5 kmcp compute -I $input -O refseq-$name-k21-n10-D5 \\ -k 21 -D 5 --seq-name-filter plasmid \\ --split-number 10 --split-overlap 100 \\ --log refseq-$name-k21-n10-D5.log -j 32 --force kmcp index -I refseq-$name-k21-n10-D5/ -O refseq-fungi.minh5.kmcp \\ -j 32 -f 0.2 -n 1 \\ --log refseq-fungi.minh5.kmcp.log --force # cp taxid and name mapping file to database directory cp taxid.map name.map refseq-fungi.minh5.kmcp/ # --------------------------------------------- # here we compute Minimizer with W=5 kmcp compute -I $input -O refseq-$name-k21-n10-W5 \\ -k 21 -W 5 --seq-name-filter plasmid \\ --split-number 10 --split-overlap 100 \\ --log refseq-$name-k21-n10-W5.log -j 32 --force kmcp index -I refseq-$name-k21-n10-W5/ -O refseq-fungi.mini5.kmcp \\ -j 32 -f 0.2 -n 1 \\ --log refseq-fungi.mini5.kmcp.log --force # cp taxid and name mapping file to database directory cp taxid.map name.map refseq-fungi.mini5.kmcp/","title":"RefSeq viral or fungi"},{"location":"database/#genbank-viral","text":"Tools genome_updater for downloading genomes from NCBI. Downloading viral sequences: name=viral # -k for dry-run # -i for fix time genome_updater.sh \\ -d \"genbank\"\\ -g $name \\ -c \"all\" \\ -l \"all\" \\ -f \"genomic.fna.gz\" \\ -o \"genbank-$name\" \\ -t 12 \\ -m -a -p # cd genbank-viral/2021-12-06_15-27-37/ # taxdump mkdir -p taxdump tar -zxvf taxdump.tar.gz -C taxdump # assembly accesion -> taxid cut -f 1,6 assembly_summary.txt > taxid.map # assembly accesion -> name cut -f 1,8 assembly_summary.txt > name.map # stats (optional) cat taxid.map \\ | csvtk freq -Ht -f 2 -nr \\ | taxonkit lineage -r -n -L --data-dir taxdump/ \\ | taxonkit reformat -I 1 -f '{k}\\t{p}\\t{c}\\t{o}\\t{f}\\t{g}\\t{s}' --data-dir taxdump/ \\ | csvtk add-header -t -n 'taxid,count,name,rank,superkindom,phylum,class,order,family,genus,species' \\ > taxid.map.stats.tsv seqkit stats -T -j 12 --infile-list <(find files -name \"*.fna.gz\") > files.stats.tsv # ------------------------------------------------------ # create another directory linking to genome files input=files.renamed mkdir -p $input # create soft links cd $input find ../files -name \"*.fna.gz\" \\ | rush 'ln -s {}' cd .. # rename brename -R -p '^(\\w{3}_\\d{9}\\.\\d+).+' -r '$1.fna.gz' $input keep at most 5 genomes for a taxid: # ----------------------------------------------------------------- # keep at most 5 genomes for a taxid # backup cat taxid.map > taxid.all.map cat name.map > name.all.map # keep at most 5 ids for a taxid cat taxid.all.map \\ | csvtk sort -Ht -k 2:n -k 1:n \\ | csvtk uniq -Ht -f 2 -n 5 \\ > taxid.map cat name.all.map \\ | csvtk grep -Ht -P <(cut -f 1 taxid.map) \\ > name.map # organize files input=files.renamed output=files.renamed.slim mkdir -p $output cd $output find ../$input -name \"*.fna.gz\" \\ | csvtk mutate -Ht -p '/([^\\/]+).fna.gz' \\ | csvtk grep -Ht -f 2 -P <(cut -f 1 ../taxid.map) \\ | rush 'ln -s {1}' cd .. # check number of genomes ls $output | wc -l wc -l taxid.map Building database (all k-mers, for profiling on short-reads): # ----------------------------------------------------------------- # for viral, only splitting into 5 fragments name=viral input=files.renamed.slim # ---------------- # all kmers kmcp compute -I $input -O genbank-$name-k21-n5 \\ -k 21 --seq-name-filter plasmid \\ --split-number 5 --split-overlap 100 \\ --log genbank-$name-k21-n5.log -j 32 --force # viral genomes are small: # using small false positive rate: 0.05 # still using one hash function: 1 kmcp index -I genbank-$name-k21-n5/ -O genbank-viral.kmcp \\ -j 32 -f 0.05 -n 1 -x 100K -8 1M \\ --log genbank-viral.kmcp.log --force # cp taxid and name mapping file to database directory cp taxid.map name.map genbank-viral.kmcp/ Building database (k-mer sketches, for profiling on long-reads): name=viral input=files.renamed.slim # ---------------------------------------------- # here we compute Closed Syncmers with s=16 kmcp compute -I $input -O genbank-$name-k21-n5-S16 \\ -k 21 -S 16 --seq-name-filter plasmid \\ --split-number 5 --split-overlap 100 \\ --log genbank-$name-k21-n5-S16.log -j 32 --force # viral genomes are small: # using small false positive rate: 0.001 # using more hash functions: 3 kmcp index -I genbank-$name-k21-n5-S16/ -O genbank-viral.sync16.kmcp \\ -j 32 -f 0.001 -n 3 -x 50K -8 1M \\ --log genbank-viral.sync16.kmcp.log --force # cp taxid and name mapping file to database directory cp taxid.map name.map genbank-viral.sync16.kmcp/ # ---------------------------------------------- # here we compute FracMinHash with D=5 kmcp compute -I $input -O genbank-$name-k21-n5-D5 \\ -k 21 -D 5 --seq-name-filter plasmid \\ --split-number 5 --split-overlap 100 \\ --log genbank-$name-k21-n5-D5.log -j 32 --force # viral genomes are small: # using small false positive rate: 0.001 # using more hash functions: 3 kmcp index -I genbank-$name-k21-n5-D5/ -O genbank-viral.minh5.kmcp \\ -j 32 -f 0.001 -n 3 -x 50K -8 1M \\ --log genbank-viral.minh5.kmcp.log --force # cp taxid and name mapping file to database directory cp taxid.map name.map genbank-viral.minh5.kmcp/ # ---------------------------------------------- # here we compute Minimizer with W=5 kmcp compute -I $input -O genbank-$name-k21-n5-W5 \\ -k 21 -W 5 --seq-name-filter plasmid \\ --split-number 5 --split-overlap 100 \\ --log genbank-$name-k21-n5-W5.log -j 32 --force # viral genomes are small: # using small false positive rate: 0.001 # using more hash functions: 3 kmcp index -I genbank-$name-k21-n5-W5/ -O genbank-viral.mini5.kmcp \\ -j 32 -f 0.001 -n 3 -x 50K -8 1M \\ --log genbank-viral.mini5.kmcp.log --force # cp taxid and name mapping file to database directory cp taxid.map name.map genbank-viral.mini5.kmcp/ Building small databases (all k-mers, for profiling with a computer cluster): name=genbank-viral input=files.renamed.slim find $input -name \"*.fna.gz\" > $input.files.txt # number of databases n=4 # split into $n chunks split -n l/$n $chunksize -d $input.files.txt $name.n$n- # create database for every chunks for f in $name.n$n-*; do echo $f kmcp compute -i $f -O $f-k21-n5 \\ -k 21 --seq-name-filter plasmid \\ --split-number 5 --split-overlap 100 \\ --log $f-k21-n5.log -j 32 --force # viral genomes are small: # using small false positive rate: 0.001 # using more hash functions: 3 kmcp index -I $f-k21-n5/ -O $f.kmcp \\ -j 32 -f 0.05 -n 1 -x 100K -8 1M \\ --log $f.kmcp.log --force # cp taxid and name mapping file to database directory cp taxid.map name.map $f.kmcp/ done","title":"Genbank viral"},{"location":"database/#human-genome","text":"Downloading human genome file from CHM13 : wget https://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/009/914/755/GCA_009914755.3_CHM13_T2T_v1.1/GCA_009914755.3_CHM13_T2T_v1.1_genomic.fna.gz Building database (all k-mers, < 6min): input=GCA_009914755.3_CHM13_T2T_v1.1_genomic.fna.gz # splitting human genome into 1024 fragments. # The regular expression '^(\\w{3}_\\d{9}\\.\\d+).+' is for extracting 'GCA_009914755.3' from the file name. kmcp compute $input -O human-chm13-k21-n1024 \\ --ref-name-regexp '^(\\w{3}_\\d{9}\\.\\d+).+' \\ -k 21 \\ --split-number 1024 --split-overlap 100 \\ --log human-chm13-k21-n1024.log -j 32 --force # using small false positive rate: 0.3 # using more hash functions: 1 kmcp index -I human-chm13-k21-n1024/ -O human-chm13.kmcp \\ -j 8 -f 0.3 -n 1 \\ --log human-chm13.kmcp.log --force # taxid.map echo -ne \"GCA_009914755.3\\t9606\\n\" > taxid.map # name.mapp echo -ne \"GCA_009914755.3\\tHomo sapiens isolate CHM13\\n\" > name.map # cp name mapping file to database directory cp taxid.map name.map human-chm13.kmcp/","title":"Human genome"},{"location":"database/#refseq-plasmid","text":"Downloading plasmid sequences: wget https://ftp.ncbi.nlm.nih.gov/refseq/release/plasmid/ cat index.html \\ | perl -ne 'next unless /\"(plasmid.*genomic.fna.gz)\"/; print \"$1\\n\"' > files.txt baseurl=https://ftp.ncbi.nlm.nih.gov/refseq/release/plasmid/ outdir=archives; mkdir -p $outdir cat files.txt \\ | rush -j 12 -v b=$baseurl -v out=$outdir \\ 'wget -c {b}/{} -o /dev/null -O {out}/{}' -c -C download.rush # name mapping seqkit seq -n archives/*.fna.gz \\ | sed -E 's/\\s+/\\t/' \\ > name.map # length stats seqkit stats -b -a -j 12 -T archives/*.fna.gz > archives.stats.tsv # split to individual files for f in archives/*.fna.gz; do \\ seqkit split2 -s 1 --quiet $f -O refseq-plasmid; \\ done # rename files with sequence ID find refseq-plasmid -name \"*.fna.gz\" \\ | rush 'mv {} {/}/$(seqkit seq -ni {}).fna.gz' Building database (all k-mers): name=plasmid input=refseq-plasmid kmcp compute -I $input -O refseq-$name-k21-n5 \\ -k 21 --circular \\ --split-number 5 --split-overlap 100 \\ --log refseq-$name-k21-n5.log -j 32 --force # using small false positive rate: 0.01 # using more hash functions: 3 kmcp index -I refseq-$name-k21-n5/ -O refseq-$name.kmcp \\ -j 32 -f 0.01 -n 3 -x 200K -X 1024 \\ --log refseq-$name.kmcp.log --force # cp name mapping file to database directory cp name.map refseq-$name.kmcp/ Building database (FracMinHash/Scaled MinHash): name=plasmid input=refseq-plasmid kmcp compute -I $input -O refseq-$name-k31-D10 \\ -k 31 --circular --scale 10 \\ --log refseq-$name-k31-D10.log -j 32 --force # using small false positive rate: 0.01 # using more hash functions: 3 kmcp index -I refseq-$name-k31-D10/ -O refseq-$name.minhash.kmcp \\ -j 8 -f 0.01 -n 3 -x 100K -X 1024 \\ --log refseq-$name.minhash.kmcp.log --force # cp name mapping file to database directory cp name.map refseq-$name.minhash.kmcp/ Building database (Closed Syncmer): name=plasmid input=refseq-plasmid kmcp compute -I $input -O refseq-$name-k31-S21 \\ -k 31 --circular --syncmer-s 21 \\ --log refseq-$name-k31-S21.log -j 32 --force # using small false positive rate: 0.01 # using more hash functions: 3 kmcp index -I refseq-$name-k31-S21/ -O refseq-$name.syncmer.kmcp \\ -j 8 -f 0.01 -n 3 -x 100K -X 1024 \\ --log refseq-$name.syncmer.kmcp.log --force # cp name mapping file to database directory cp name.map refseq-$name.syncmer.kmcp/","title":"Refseq plasmid"},{"location":"database/#humgut","text":"HumGut is a comprehensive Human Gut prokaryotic genomes collection filtered by metagenome data. Dataset Genomes: HumGut.tar.gz Metadata: HumGut.tsv Taxdump files: NCBI taxonomy: ncbi_names.dump and ncbi_nodes.dump GTDB taxomomy: gtdb_names.dump and gtdb_nodes.dump Uncompressing and renaming: # uncompress tar -zxvf HumGut.tar.gz # taxdump files mkdir taxdump mv ncbi_names.dmp taxdump/names.dmp mv ncbi_nodes.dmp taxdump/nodes.dmp Mapping file: # assembly accesion -> taxid cat HumGut.tsv \\ | csvtk cut -t -f genome_file,ncbi_tax_id \\ | csvtk replace -f genome_file -t -p '\\..+$' \\ | csvtk del-header \\ > taxid.map # assembly accesion -> name cat HumGut.tsv \\ | csvtk cut -t -f genome_file,ncbi_organism_name \\ | csvtk replace -f genome_file -t -p '\\..+$' \\ | csvtk del-header \\ > name.map Stats: # ------------------------------------------------------------- # NCBI taxonomy # number of species/strains cat taxid.map \\ | taxonkit lineage --data-dir taxdump-ncbi -i 2 -r -n -L \\ | csvtk freq -Ht -f 4 -nr \\ | csvtk pretty -H -t \\ | tee taxid.map.stats species 23604 strain 6816 subspecies 161 no rank 69 serotype 38 genus 3 # number of unique species/strains cat taxid.map \\ | csvtk uniq -Ht -f 2 \\ | taxonkit lineage --data-dir taxdump-ncbi -i 2 -r -n -L \\ | csvtk freq -Ht -f 4 -nr \\ | csvtk pretty -H -t \\ | tee taxid.map.uniq.stats; species 1240 strain 458 subspecies 15 genus 1 no rank 1 serotype 1 # ------------------------------------------------------------- # GTDB taxonomy cat HumGut.tsv \\ | csvtk cut -t -f genome_file,gtdbtk_tax_id \\ | csvtk replace -f genome_file -t -p '\\..+$' \\ | csvtk del-header \\ > taxid-gtdb.map cat taxid-gtdb.map \\ | csvtk uniq -Ht -f 2 \\ | taxonkit lineage --data-dir taxdump-gtdb -i 2 -r -n -L \\ | csvtk freq -Ht -f 4 -nr \\ | csvtk pretty -H -t \\ | tee taxid-gtdb.map.uniq.stats species 2810 genus 434 family 52 order 12 class 2 Building database: # compute k-mers # sequence containing \"plasmid\" in name are ignored, # reference genomes are splitted into 10 fragments # k = 21 kmcp compute -I fna/ -k 21 -n 10 -B plasmid -O humgut-k21-n10 -j 32 --force # build database # number of index files: 32, for server with >= 32 CPU cores # bloom filter parameter: # number of hash function: 1 # false positive rate: 0.3 kmcp index -j 32 -I humgut-k21-n10 -O humgut.kmcp -n 1 -f 0.3 cp taxid.map taxid-gtdb.map humgut.kmcp/","title":"HumGut"},{"location":"database/#progenomes2","text":"proGenomes v2.1 provides 84,096 consistently annotated bacterial and archaeal genomes from over 12000 species Dataset: Representative genomes: contigs.representatives.fasta.gz NCBI taxonomy: proGenomes2.1_specI_lineageNCBI.tab Organize sequences: # download wget https://progenomes.embl.de/data/repGenomes/freeze12.contigs.representatives.fasta.gz # unzip for splitting by genome ID time seqkit seq freeze12.contigs.representatives.fasta.gz -o freeze12.contigs.representatives.fasta # split by genome ID seqkit split --by-id --two-pass --id-regexp '(^\\d+\\.\\w+)\\.' freeze12.contigs.representatives.fasta --out-dir genomes # batch rename brename -p '^.+id_' genomes # compress genomes for saving space find genomes/ -name \"*.fasta\" | rush 'gzip {}' Mapping file: # download wget https://progenomes.embl.de/data/proGenomes2.1_specI_lineageNCBI.tab ls genomes/ | sed 's/.fasta.gz//' > id.txt # id -> taxid cut -f 1 proGenomes2.1_specI_lineageNCBI.tab \\ | awk -F . '{print $0\"\\t\"$1}' \\ | csvtk grep -Ht -P id.txt \\ > taxid.map cat taxid.map \\ | csvtk uniq -Ht -f 2 \\ | taxonkit lineage --data-dir taxdump -i 2 -r -n -L \\ | csvtk freq -Ht -f 4 -nr \\ | csvtk pretty -H -t \\ | tee taxid.map.uniq.stats species 8088 strain 3262 subspecies 37 isolate 25 no rank 16 forma specialis 14 biotype 1 # use the taxonomy verion of the refseq-virus: 2021-10-01 # id -> name cat taxid.map \\ | taxonkit lineage --data-dir taxdump -i 2 -n -L \\ | cut -f 1,3 \\ > name.map Building database: # compute k-mers # sequence containing \"plasmid\" in name are ignored, # reference genomes are splitted into 10 fragments # k = 21 kmcp compute -I genomes/ -k 21 -n 10 -B plasmid -O progenomes-k21-n10 --force # build database # number of index files: 32, for server with >= 32 CPU cores # bloom filter parameter: # number of hash function: 1 # false positive rate: 0.3 kmcp index -j 32 -I progenomes-k21-n10 -O progenomes.kmcp -n 1 -f 0.3 cp taxid.map name.map progenomes.kmcp/","title":"proGenomes2"},{"location":"database/#building-custom-databases","text":"Files: Genome files (Gzip-compressed) FASTA/Q format. One genome per file with the reference identifier in the file name. TaxId mapping file (for metagenomic profiling) Two-column (reference identifier and TaxId) tab-delimited. NCBI taxonomy dump files (for metagenomic profiling) names.dmp nodes.dmp merged.dmp (optional) delnodes.dmp (optional) Tools: kmcp for metagenomic profiling. rush for executing jobs in parallel. brename for batching renaming files (optional) Memory notes : By default, kmcp search loads the whole database into main memory (RAM) for fast searching. Optionally, the flag --low-mem can be set to avoid loading the whole database, while it's much slower, >10X slower on SSD and should be much slower on HDD disks. Another way is dividing the reference genomes into several parts and building smaller databases for all parts, so that the biggest database can be loaded into RAM. After performing database searching, search results on all small databases can be merged with kmcp merge for downstream analysis. Buiding small databases can also accelerate searching on a computer cluster , where every node searches a part of the database.","title":"Building custom databases"},{"location":"database/#step-1-computing-k-mers","text":"Plain or gzip-compressed input genome sequence files better be saved in one directory, with multiple-level directories allowed. The file extension could be fa , fasta , fna , fq , fastq , fa.gz , fasta.gz , fna.gz , fq.gz or fastq.gz . Input files can be given as a list of FASTA/Q files via positional arguments or a directory (with multiple-level directories allowed) containing sequence files via the flag -I/--in-dir . A regular expression for matching sequencing files is available by the flag -r/--file-regexp . The default pattern matches files with extension of fa , fasta , fna , fq , fastq , fa.gz , fasta.gz , fna.gz , fq.gz or fastq.gz . Unwanted sequence like plasmid sequences can be filtered out by the name via regular expression(s) ( -B/--seq-name-filter ). How to compute k-mers : By default, kmcp computes k-mers (sketches) of every file, you can also use --by-seq to compute for every sequence, where sequence IDs in all input files better be distinct. It also supports splitting sequences into fragments, this could increase the specificity in profiling result in cost of slower searching speed . Splitting sequences : Sequences can be splitted into fragments by a fragment size ( -s/--split-size ) or number of fragments ( -n/--split-number ) with overlap (- l/--split-overlap ). When splitting by number of fragments, all sequences (except for these mathching any regular expression given by -B/--seq-name-filter ) in a sequence file are concatenated with k-1 Ns before splitting . Both sequence/reference IDs and fragments indices are saved for later use, in form of meta/description data in .unik files, and will be reported in kmcp search results. Meta data : Every outputted .unik file contains the sequence/reference ID, fragment index, number of fragments, and genome size of reference. When parsing whole sequence files or splitting by number of fragments, the identifier of a reference is the basename of the input file by default. It can also be extracted from the input file name via -N/--ref-name-regexp , e.g., ^(\\w{3}_\\d{9}\\.\\d+) for RefSeq assembly accessions . Multiple sizes of k-mers are supported, but a single k-mer size is good enough. Supported k-mer (sketches) types : K-mer: ntHash of k-mer ( -k ) K-mer sketchs (all using ntHash): Scaled MinHash ( -k -D ), reviously named Scaled MinHash Minimizer ( -k -W ), optionally scaling/down-sampling ( -D ) Closed Syncmer ( -k -S ), optionally scaling/down-sampling ( -D ) Output : All outputted .unik files are saved in ${outdir} , with path ${outdir}/xxx/yyy/zzz/${infile}-id_${seqID}.unik where dirctory tree /xxx/yyy/zzz/ is built for > 1000 output files. For splitting sequence mode ( --split-size > 0 or --split-number > 0 ), output files are: ${outdir}//xxx/yyy/zzz/${infile}/{seqID}-frag_${fragIdx}.unik A summary file ( ${outdir}/_info.txt ) is generated for later use. Users need to check if the reference IDs (column name ) are what supposed to be. Performance tips : Decrease value of -j/--threads for data in hard disk drives (HDD) to reduce I/O pressure. Commands ( usage ): # compute k-mers # sequence containing \"plasmid\" in name are ignored, # reference genomes are splitted into 10 fragments, # k = 21 kmcp compute --in-dir refs/ \\ --kmer 21 \\ --split-number 10 \\ --seq-name-filter plasmid \\ --ref-name-regexp '(.+).fasta.gz' \\ --out-dir refs-k21-n10 # demo output 22:33:10.685 [INFO] kmcp v0.7.0 22:33:10.685 [INFO] https://github.com/shenwei356/kmcp 22:33:10.685 [INFO] 22:33:10.685 [INFO] checking input files ... 22:33:10.685 [INFO] 9 input file(s) given 22:33:10.685 [INFO] 22:33:10.685 [INFO] -------------------- [main parameters] -------------------- 22:33:10.685 [INFO] input and output: 22:33:10.685 [INFO] input directory: refs/ 22:33:10.685 [INFO] regular expression of input files: (?i)\\.(f[aq](st[aq])?|fna)(.gz)?$ 22:33:10.685 [INFO] *regular expression for extracting reference name from file name: 22:33:10.685 [INFO] *regular expressions for filtering out sequences: [plasmid] 22:33:10.685 [INFO] output directory: refs-k21-n10 22:33:10.685 [INFO] 22:33:10.685 [INFO] sequences splitting: true 22:33:10.685 [INFO] split parts: 10, overlap: 0 bp 22:33:10.685 [INFO] 22:33:10.685 [INFO] k-mer (sketches) computing: 22:33:10.685 [INFO] k-mer size(s): 21 22:33:10.685 [INFO] circular genome: false 22:33:10.685 [INFO] saving exact number of k-mers: true 22:33:10.685 [INFO] 22:33:10.685 [INFO] -------------------- [main parameters] -------------------- 22:33:10.685 [INFO] 22:33:10.685 [INFO] computing ... processed files: 9 / 9 [======================================] ETA: 0s. done 22:33:11.121 [INFO] 22:33:11.121 [INFO] elapsed time: 436.367564ms 22:33:11.121 [INFO] A summary file ( _info.txt ) is generated for later use. Users need to check if the reference IDs (column name ) are what supposed to be . #path name fragIdx idxNum genomeSize kmers refs-k21-n10/672/060/672/NC_010655.1.fasta.gz/NC_010655.1-frag_0.unik NC_010655.1 0 10 2664102 264247 refs-k21-n10/672/060/672/NC_010655.1.fasta.gz/NC_010655.1-frag_1.unik NC_010655.1 1 10 2664102 266237 refs-k21-n10/595/162/595/NC_012971.2.fasta.gz/NC_012971.2-frag_0.unik NC_012971.2 0 10 4558953 450494 refs-k21-n10/292/039/292/NC_000913.3.fasta.gz/NC_000913.3-frag_0.unik NC_000913.3 0 10 4641652 459277 refs-k21-n10/934/859/934/NC_013654.1.fasta.gz/NC_013654.1-frag_0.unik NC_013654.1 0 10 4717338 470575 Meta data in the .unik file can be showed using kmcp utils unik-info : kmcp utils unik-info refs-k21-n10/072/380/072/NZ_CP028116.1.fasta.gz/NZ_CP028116.1-frag_0.unik -a","title":"Step 1. Computing k-mers"},{"location":"database/#step-2-building-databases","text":"KMCP builds index for k-mers (sketches) with a modified Compact Bit-sliced Signature Index ( COBS ). We totally rewrite the algorithms, data structure and file format, and have improved the indexing and searching speed (check benchmark ). Input : The output directory generated by kmcp compute . Database size and searching accuracy : Use --dry-run to adjust parameters and check final number of index files (#index-files) and the total file size . -f/--false-positive-rate : the default value 0.3 is enough for a query with tens of matched k-mers (see BIGSI/COBS paper). Small values could largely increase the size of database. -n/--num-hash : large values could reduce the database size, in cost of slower searching speed. Values <=4 is recommended. Value of block size -b/--block-size better be multiple of 64. The default value is: (#unikFiles/#threads + 7) / 8 * 8 Use flag -x/--block-sizeX-kmers-t , -8/--block-size8-kmers-t , and -1/--block-size1-kmers-t to separately create index for inputs with huge number of k-mers, for precise control of database size. Taxonomy data : No taxonomy data are included in the database. Taxonomy information are only needed in kmcp profile . Performance tips : Number of blocks ( .uniki files) better be smaller than or equal to number of CPU cores for faster searching speed. We can set -j/--threads to control the blocks number . When more threads (>= 1.3 * #blocks) are given, extra workers are automatically created. #threads files are simultaneously opened, and the max number of opened files is limited by the flag -F/--max-open-files . You may use a small value of -F/--max-open-files for hard disk drive storage. When the database is used in a new computer with more CPU cores, kmcp search could automatically scale to utilize as many cores as possible. Commands ( usage ): # build database # number of index files: 32, for server with >= 32 CPU cores # bloom filter parameter: # number of hash function: 1 # false positive rate: 0.3 kmcp index -I refs-k21-n10 \\ --threads 32 \\ --num-hash 1 \\ --false-positive-rate 0.3 \\ --out-dir refs.kmcp # demo output 22:44:17.710 [INFO] kmcp v0.7.0 22:44:17.710 [INFO] https://github.com/shenwei356/kmcp 22:44:17.710 [INFO] 22:44:17.710 [INFO] loading .unik file infos from file: refs-k21-n10/_info.txt 22:44:17.716 [INFO] 90 cached file infos loaded 22:44:17.716 [INFO] 22:44:17.716 [INFO] -------------------- [main parameters] -------------------- 22:44:17.716 [INFO] number of hashes: 1 22:44:17.716 [INFO] false positive rate: 0.300000 22:44:17.717 [INFO] k-mer size(s): 21 22:44:17.717 [INFO] split seqequence size: 0, overlap: 0 22:44:17.717 [INFO] block-sizeX-kmers-t: 10.00 M 22:44:17.717 [INFO] block-sizeX : 256.00 22:44:17.717 [INFO] block-size8-kmers-t: 20.00 M 22:44:17.717 [INFO] block-size1-kmers-t: 200.00 M 22:44:17.717 [INFO] -------------------- [main parameters] -------------------- 22:44:17.717 [INFO] 22:44:17.717 [INFO] building index ... 22:44:17.726 [WARN] ignore -X/--block-size (256) which is >= -b/--block-size (8) 22:44:17.726 [INFO] 22:44:17.726 [INFO] block size: 8 22:44:17.726 [INFO] number of index files: 32 (may be more) 22:44:17.726 [INFO] 22:44:17.726 [block #001] 1 / 1 100 % 22:44:17.726 [block #002] 1 / 1 100 % 22:44:17.726 [block #003] 1 / 1 100 % 22:44:17.726 [block #004] 1 / 1 100 % 22:44:17.726 [block #005] 1 / 1 100 % 22:44:17.726 [block #006] 1 / 1 100 % 22:44:17.726 [block #007] 1 / 1 100 % 22:44:17.726 [block #008] 1 / 1 100 % 22:44:17.726 [block #009] 1 / 1 100 % 22:44:17.727 [block #010] 1 / 1 100 % 22:44:17.727 [block #011] 1 / 1 100 % 22:44:17.727 [block #012] 1 / 1 100 % [saved index files] 12 / 12 ETA: 0s. done 22:44:17.933 [INFO] 22:44:17.933 [INFO] kmcp database with 42713316 k-mers saved to refs.kmcp 22:44:17.933 [INFO] total file size: 15.66 MB 22:44:17.933 [INFO] total index files: 12 22:44:17.933 [INFO] 22:44:17.933 [INFO] elapsed time: 223.524128ms 22:44:17.933 [INFO] Output: refs.kmcp/ \u2514\u2500\u2500 R001 \u251c\u2500\u2500 _block001.uniki \u251c\u2500\u2500 _block002.uniki \u251c\u2500\u2500 _block003.uniki \u251c\u2500\u2500 _block004.uniki \u251c\u2500\u2500 _block005.uniki \u251c\u2500\u2500 _block006.uniki \u251c\u2500\u2500 _block007.uniki \u251c\u2500\u2500 _block008.uniki \u251c\u2500\u2500 _block009.uniki \u251c\u2500\u2500 _block010.uniki \u251c\u2500\u2500 _block011.uniki \u251c\u2500\u2500 _block012.uniki \u251c\u2500\u2500 __db.yml \u2514\u2500\u2500 __name_mapping.tsv __db.yml contains configuration of the database, and _blockXXX.uniki are index files. kmcp utils index-info could show the basic information of index files: kmcp utils index-info refs.kmcp/R001/_block001.uniki file k canonical num-hashes num-sigs num-names refs.kmcp/R001/_block001.uniki 21 true 1 746442 8 What's next? Check the tutorials .","title":"Step 2. Building databases"},{"location":"download/","text":"Download KMCP is implemented in Go programming language, statically-linked executable binary files are freely available . SIMD instructions support SIMD extensions including AVX512 , AVX2 , SSE2 are sequentially detected and used in two packages for better searching performance. pand , for accelerating searching on databases constructed with multiple hash functions. pospop , for batch counting matched k-mers in bloom filters. Current Version v0.7.0 - 2021-01-24 Links OS Arch File, \u4e2d\u56fd\u955c\u50cf Download Count Linux 64-bit kmcp_linux_amd64.tar.gz , \u4e2d\u56fd\u955c\u50cf macOS 64-bit kmcp_darwin_amd64.tar.gz , \u4e2d\u56fd\u955c\u50cf Windows 64-bit kmcp_windows_amd64.exe.tar.gz , \u4e2d\u56fd\u955c\u50cf Notes: please open an issuse to request binaries for other platforms. run kmcp version to check update !!! run kmcp autocompletion to update shell autocompletion script !!! Installation Method 1: Install using conda conda install -c bioconda kmcp Method 2: Download binaries Download compressed executable file of your operating system, and decompress it with tar -zxvf *.tar.gz command or other tools. And then: For Linux-like systems If you have root privilege simply copy it to /usr/local/bin : sudo cp kmcp /usr/local/bin/ Or copy to anywhere in the environment variable PATH : mkdir -p $HOME/bin/; cp kmcp $HOME/bin/ For Windows , just copy kmcp.exe to C:\\WINDOWS\\system32 . Shell-completion Supported shell: bash|zsh|fish|powershell Bash: # generate completion shell kmcp autocompletion --shell bash # configure if never did. # install bash-completion if the \"complete\" command is not found. echo \"for bcfile in ~/.bash_completion.d/* ; do source \\$bcfile; done\" >> ~/.bash_completion echo \"source ~/.bash_completion\" >> ~/.bashrc Zsh: # generate completion shell kmcp autocompletion --shell zsh --file ~/.zfunc/_kmcp # configure if never did echo 'fpath=( ~/.zfunc \"${fpath[@]}\" )' >> ~/.zshrc echo \"autoload -U compinit; compinit\" >> ~/.zshrc fish: kmcp autocompletion --shell fish --file ~/.config/fish/completions/kmcp.fish Release History v0.7.0 - 2022-01-24 commands: new command utils filter : Filter search results and find species-specific queries. new command utils merge-regions : Merge species/assembly-specific regions. rename info to utils index-info . compute : skip k-mer containing Ns. when splitting genome into fragments, sequences are concatenated with k-1 'N's instead of directly concatenation. It eliminates fake k-mers at the concatenation position. set default value for flag -N/--ref-name-regexp : (?i)(.+)\\.(f[aq](st[aq])?|fna)(.gz)?$ . fix a rare bug when splitting FASTQ files. search : support searching with paired-end reads which has a higher specificity and a lower sensitivity. A flag --try-se is added for search read1/read2 when the paired end reads have no hits. fix matches order of a query. fix queries with many Ns. change default value of flag -t/--min-query-qcov from 0.6 to 0.55 (similarity ~96.5% ). change default value of flag -n/--keep-top-scores from 5 to 0 , i.e., keep all matches by default. new flag -w/--load-whole-db : load all index files into memory. 10-25% faster. better log. merge : fix adding up hits . fix bug of incorrect order, reduce memory usage. support one input file. profile : change analysis workflow, using 4 stages. output format change: new column coverage , fragsRelDepth and fragsRelDepthStd . change default file extension of binning file. check if the taxid of a target is given by taxid mapping file. automatically switch to the new taxid for a merged one. change computation of score . new flag -d/--max-frags-depth-stdev . new option -m/--mode . change default value of flag -t/--min-query-qcov from 0.6 to 0.55 (similarity ~96.5% ). change default value of flag -n/--keep-top-qcovs from 5 to 0 (keep all matches). change default value of falg -f/--max-fpr from 0.01 to 0.05 . change default value of flag -H/--min-hic-ureads-qcov from 0.8 to 0.75 (similarity ~98% ). faster search result parsing. v0.6.0 - 2021-08-13 new command: merge : merge search results from multiple databases. compute : fix splitting very short genomes. remove flag -e/--exact-number , making it default. index : do not roundup sizes of indexes. The searching speed is not affected and even faster due to optimization of search command. use three k-mers thresholds to control index file size. better control of cocurrency number and better progress bar. do not support RAMBO index anymore. search : 1.37X speedup, and faster for database with two or more hash functions. new flag -S/--do-not-sort . profile : fix a nil pointer bug when no taxid mapping data given. fix number of ureads. new flag -m/--keep-main-matches and --max-score-gap v0.5.0 - 2021-06-24 compute : support multiple sizes of k-mer. fix bug of --by-seq . more log. index : default block size is computed by -j/--threads instead of number of CPUs. search : show real-time processing speed. new flag -g/--query-whole-file . new flag -u/--kmer-dedup-threshold . new flag -m/--min-query-len . increase speed for database with mulitple hashes. profile : better decision of the existence of a reference. new flag -B/--binning-result for output reads binning result. new flag -m/--norm-abund . v0.4.0 - 2021-04-08 new command: profile for generating taxonomic profile from search result. compute : new flag -B/--seq-name-filter for filtering out unwanted sequences like plasmid. new flag -N/--ref-name-regexp for extracting reference name from sequence file. search : change default threshold value. new flag -n/--keep-top-scores for keeping matches with the top N score. v0.3.0 - 2021-03-16 use --quiet to replace --verbose , making printing log info default. search : fix computing intersetion between repeats. fix closing mmap on Windows. change output format and add Jaccard Index. speedup by parallelizing name mapping and database closing. flush result immediately. keep the output order by default compute : change default file regexp for matching .fna files. autocompletion : support bash, zsh, fish, powershell. v0.2.1 - 2020-12-31 index : reduce memory occupation. v0.2.0 - 2020-12-30 Add support of RAMBO like indexing. Limit to only one input database. Change output format. v0.1.0 - 2020-xx-xx First release with basic function.","title":"Download"},{"location":"download/#download","text":"KMCP is implemented in Go programming language, statically-linked executable binary files are freely available .","title":"Download"},{"location":"download/#simd-instructions-support","text":"SIMD extensions including AVX512 , AVX2 , SSE2 are sequentially detected and used in two packages for better searching performance. pand , for accelerating searching on databases constructed with multiple hash functions. pospop , for batch counting matched k-mers in bloom filters.","title":"SIMD instructions support"},{"location":"download/#current-version","text":"v0.7.0 - 2021-01-24","title":"Current Version"},{"location":"download/#links","text":"OS Arch File, \u4e2d\u56fd\u955c\u50cf Download Count Linux 64-bit kmcp_linux_amd64.tar.gz , \u4e2d\u56fd\u955c\u50cf macOS 64-bit kmcp_darwin_amd64.tar.gz , \u4e2d\u56fd\u955c\u50cf Windows 64-bit kmcp_windows_amd64.exe.tar.gz , \u4e2d\u56fd\u955c\u50cf Notes: please open an issuse to request binaries for other platforms. run kmcp version to check update !!! run kmcp autocompletion to update shell autocompletion script !!!","title":"Links"},{"location":"download/#installation","text":"","title":"Installation"},{"location":"download/#method-1-install-using-conda","text":"conda install -c bioconda kmcp","title":"Method 1: Install using conda"},{"location":"download/#method-2-download-binaries","text":"Download compressed executable file of your operating system, and decompress it with tar -zxvf *.tar.gz command or other tools. And then: For Linux-like systems If you have root privilege simply copy it to /usr/local/bin : sudo cp kmcp /usr/local/bin/ Or copy to anywhere in the environment variable PATH : mkdir -p $HOME/bin/; cp kmcp $HOME/bin/ For Windows , just copy kmcp.exe to C:\\WINDOWS\\system32 .","title":"Method 2: Download binaries"},{"location":"download/#shell-completion","text":"Supported shell: bash|zsh|fish|powershell Bash: # generate completion shell kmcp autocompletion --shell bash # configure if never did. # install bash-completion if the \"complete\" command is not found. echo \"for bcfile in ~/.bash_completion.d/* ; do source \\$bcfile; done\" >> ~/.bash_completion echo \"source ~/.bash_completion\" >> ~/.bashrc Zsh: # generate completion shell kmcp autocompletion --shell zsh --file ~/.zfunc/_kmcp # configure if never did echo 'fpath=( ~/.zfunc \"${fpath[@]}\" )' >> ~/.zshrc echo \"autoload -U compinit; compinit\" >> ~/.zshrc fish: kmcp autocompletion --shell fish --file ~/.config/fish/completions/kmcp.fish","title":"Shell-completion"},{"location":"download/#release-history","text":"","title":"Release History"},{"location":"download/#v070-2022-01-24","text":"commands: new command utils filter : Filter search results and find species-specific queries. new command utils merge-regions : Merge species/assembly-specific regions. rename info to utils index-info . compute : skip k-mer containing Ns. when splitting genome into fragments, sequences are concatenated with k-1 'N's instead of directly concatenation. It eliminates fake k-mers at the concatenation position. set default value for flag -N/--ref-name-regexp : (?i)(.+)\\.(f[aq](st[aq])?|fna)(.gz)?$ . fix a rare bug when splitting FASTQ files. search : support searching with paired-end reads which has a higher specificity and a lower sensitivity. A flag --try-se is added for search read1/read2 when the paired end reads have no hits. fix matches order of a query. fix queries with many Ns. change default value of flag -t/--min-query-qcov from 0.6 to 0.55 (similarity ~96.5% ). change default value of flag -n/--keep-top-scores from 5 to 0 , i.e., keep all matches by default. new flag -w/--load-whole-db : load all index files into memory. 10-25% faster. better log. merge : fix adding up hits . fix bug of incorrect order, reduce memory usage. support one input file. profile : change analysis workflow, using 4 stages. output format change: new column coverage , fragsRelDepth and fragsRelDepthStd . change default file extension of binning file. check if the taxid of a target is given by taxid mapping file. automatically switch to the new taxid for a merged one. change computation of score . new flag -d/--max-frags-depth-stdev . new option -m/--mode . change default value of flag -t/--min-query-qcov from 0.6 to 0.55 (similarity ~96.5% ). change default value of flag -n/--keep-top-qcovs from 5 to 0 (keep all matches). change default value of falg -f/--max-fpr from 0.01 to 0.05 . change default value of flag -H/--min-hic-ureads-qcov from 0.8 to 0.75 (similarity ~98% ). faster search result parsing.","title":"v0.7.0 - 2022-01-24"},{"location":"download/#v060-2021-08-13","text":"new command: merge : merge search results from multiple databases. compute : fix splitting very short genomes. remove flag -e/--exact-number , making it default. index : do not roundup sizes of indexes. The searching speed is not affected and even faster due to optimization of search command. use three k-mers thresholds to control index file size. better control of cocurrency number and better progress bar. do not support RAMBO index anymore. search : 1.37X speedup, and faster for database with two or more hash functions. new flag -S/--do-not-sort . profile : fix a nil pointer bug when no taxid mapping data given. fix number of ureads. new flag -m/--keep-main-matches and --max-score-gap","title":"v0.6.0 - 2021-08-13"},{"location":"download/#v050-2021-06-24","text":"compute : support multiple sizes of k-mer. fix bug of --by-seq . more log. index : default block size is computed by -j/--threads instead of number of CPUs. search : show real-time processing speed. new flag -g/--query-whole-file . new flag -u/--kmer-dedup-threshold . new flag -m/--min-query-len . increase speed for database with mulitple hashes. profile : better decision of the existence of a reference. new flag -B/--binning-result for output reads binning result. new flag -m/--norm-abund .","title":"v0.5.0 - 2021-06-24"},{"location":"download/#v040-2021-04-08","text":"new command: profile for generating taxonomic profile from search result. compute : new flag -B/--seq-name-filter for filtering out unwanted sequences like plasmid. new flag -N/--ref-name-regexp for extracting reference name from sequence file. search : change default threshold value. new flag -n/--keep-top-scores for keeping matches with the top N score.","title":"v0.4.0 - 2021-04-08"},{"location":"download/#v030-2021-03-16","text":"use --quiet to replace --verbose , making printing log info default. search : fix computing intersetion between repeats. fix closing mmap on Windows. change output format and add Jaccard Index. speedup by parallelizing name mapping and database closing. flush result immediately. keep the output order by default compute : change default file regexp for matching .fna files. autocompletion : support bash, zsh, fish, powershell.","title":"v0.3.0 - 2021-03-16"},{"location":"download/#v021-2020-12-31","text":"index : reduce memory occupation.","title":"v0.2.1 - 2020-12-31"},{"location":"download/#v020-2020-12-30","text":"Add support of RAMBO like indexing. Limit to only one input database. Change output format.","title":"v0.2.0 - 2020-12-30"},{"location":"download/#v010-2020-xx-xx","text":"First release with basic function.","title":"v0.1.0 - 2020-xx-xx"},{"location":"faq/","text":"Frequently Asked Questions How can I run KMCP on a computer without enough main memory? By default, kmcp search loads the whole database into main memory (RAM) for fast searching. Optionally, the flag --low-mem can be set to avoid loading the whole database, while it's much slower, >10X slower on SSD and should be much slower on HDD disks. Another way is dividing the reference genomes into several parts and building smaller databases for all parts, so that the biggest database can be loaded into RAM. After performing database searching, search results on all small databases can be merged with kmcp merge for downstream analysis. Buiding small databases can also accelerate searching on a computer cluster , where every node searches a part of the database. What k-mer size should I use to build the database? Multiple k-mer sizes are supported, but one value is good enough. Bigger k-mer sizes bring high specificity in cost of decrease of sensitivity. k = 21 is recommended for metagenomic profiling. How to add new genomes to the database? KMCP builds database very fast, you can eigher rebuilt the database after adding new genomes, or create a separate database with the new genomes, search against these databases, and merge the results. Unexpected EOF error Some files could corrupt during downloading, we recommend checking sequence file integrity using seqkit ( gzip -t failed for some files in my tests). List corrupted files # corrupted files find $genomes -name \"*.gz\" \\ | rush 'seqkit seq -w 0 {} > /dev/null; if [ $? -ne 0 ]; then echo {}; fi' \\ > failed.txt # empty files find $genomes -name \"*.gz\" -size 0 >> failed.txt Delete these files: cat failed.txt | rush '/bin/rm {}' Redownload these files. For example, from rush cache file download.rush (list of succeed commands), where the commands are in one line. grep -f failed.txt download.rush \\ | sed 's/__CMD__//g' \\ | rush '{}' For genome_updater , URLs of genomes can be found in files like 2021-09-30_13-32-30_url_downloaded.txt , you can extract URLs using grep -f failed.txt -v *url_downloaded.txt or some other ways, and batch redownload them using parallel .","title":"FAQs"},{"location":"faq/#frequently-asked-questions","text":"","title":"Frequently Asked Questions"},{"location":"faq/#how-can-i-run-kmcp-on-a-computer-without-enough-main-memory","text":"By default, kmcp search loads the whole database into main memory (RAM) for fast searching. Optionally, the flag --low-mem can be set to avoid loading the whole database, while it's much slower, >10X slower on SSD and should be much slower on HDD disks. Another way is dividing the reference genomes into several parts and building smaller databases for all parts, so that the biggest database can be loaded into RAM. After performing database searching, search results on all small databases can be merged with kmcp merge for downstream analysis. Buiding small databases can also accelerate searching on a computer cluster , where every node searches a part of the database.","title":"How can I run KMCP on a computer without enough main memory?"},{"location":"faq/#what-k-mer-size-should-i-use-to-build-the-database","text":"Multiple k-mer sizes are supported, but one value is good enough. Bigger k-mer sizes bring high specificity in cost of decrease of sensitivity. k = 21 is recommended for metagenomic profiling.","title":"What k-mer size should I use to build the database?"},{"location":"faq/#how-to-add-new-genomes-to-the-database","text":"KMCP builds database very fast, you can eigher rebuilt the database after adding new genomes, or create a separate database with the new genomes, search against these databases, and merge the results.","title":"How to add new genomes to the database?"},{"location":"faq/#unexpected-eof-error","text":"Some files could corrupt during downloading, we recommend checking sequence file integrity using seqkit ( gzip -t failed for some files in my tests). List corrupted files # corrupted files find $genomes -name \"*.gz\" \\ | rush 'seqkit seq -w 0 {} > /dev/null; if [ $? -ne 0 ]; then echo {}; fi' \\ > failed.txt # empty files find $genomes -name \"*.gz\" -size 0 >> failed.txt Delete these files: cat failed.txt | rush '/bin/rm {}' Redownload these files. For example, from rush cache file download.rush (list of succeed commands), where the commands are in one line. grep -f failed.txt download.rush \\ | sed 's/__CMD__//g' \\ | rush '{}' For genome_updater , URLs of genomes can be found in files like 2021-09-30_13-32-30_url_downloaded.txt , you can extract URLs using grep -f failed.txt -v *url_downloaded.txt or some other ways, and batch redownload them using parallel .","title":"Unexpected EOF error"},{"location":"usage/","text":"Usage KMCP is a command-line tool consisting of several subcommands. Program: kmcp (K-mer-based Metagenomic Classification and Profiling) Version: v0.7.0 Documents: https://bioinf.shenwei.me/kmcp Source code: https://github.com/shenwei356/kmcp KMCP is a tool for metagenomic classification and profiling. KMCP can also be used for: 1. Fast sequence search against large scales of genomic datasets as BIGSI and COBS do. 2. Fast assembly/genome similarity estimation as Mash and sourmash do, by utilizing Minimizer, FracMinHash (Scaled MinHash), or Closed Syncmers. Usage: kmcp [command] Available Commands: autocompletion Generate shell autocompletion script compute Generate k-mers (sketches) from FASTA/Q sequences index Construct database from k-mer files merge Merge search results from multiple databases profile Generate taxonomic profile from search results search Search sequence against a database utils Some utilities version Print version information and check for update Flags: -h, --help help for kmcp -i, --infile-list string \u25ba File of input files list (one file per line). If given, they are appended to files from CLI arguments. --log string \u25ba Log file. -q, --quiet \u25ba Do not print any verbose information. But you can write them to file with --log. -j, --threads int \u25ba Number of CPUs cores to use. (default 16) compute Generate k-mers (sketches) from FASTA/Q sequences Attentions: 1. Input files can be given as list of FASTA/Q files via positional arguments or a directory containing sequence files via the flag -I/--in-dir. A regular expression for matching sequencing files is available by the flag -r/--file-regexp. 2. Unwanted sequence like plasmid can be filtered out by the name via regular expressions (-B/--seq-name-filter). 3. By default, kmcp computes k-mers (sketches) of every file, you can also use --by-seq to compute for every sequence, where sequence IDs in all input files better be distinct. 4. It also supports splitting sequences into fragments, this could increase the specificity in profiling result in cost of slower searching speed. 5. Multiple sizes of k-mers are supported. Supported k-mer (sketches) types: 1. K-mer: 1). ntHash of k-mer (-k) 2. K-mer sketchs (all using ntHash): 1). FracMinHash (-k -D), previously named Scaled MinHash 2). Minimizer (-k -W), optionally scaling/down-sampling (-D) 3). Closed Syncmer (-k -S), optionally scaling/down-sampling (-D) Splitting sequences: 1. Sequences can be splitted into fragments by a fragment size (-s/--split-size) or number of fragments (-n/--split-number) with overlap (-l/--split-overlap). 2. When splitting by number of fragments, all sequences (except for these mathching any regular expression given by -B/--seq-name-filter) in a sequence file are concatenated with k-1 'N's before splitting. 3. Both sequence IDs and fragments indices are saved for later use, in form of meta/description data in .unik files. Meta data: 1. Every outputted .unik file contains the sequence/reference ID, fragment index, number of fragments, and genome size of reference. 2. When parsing whole sequence files or splitting by number of fragments, the identifier of a reference is the basename of the input file by default. It can also be extracted from the input file name via -N/--ref-name-regexp, e.g., \"^(\\w{3}_\\d{9}\\.\\d+)\" for refseq records. Output: 1. All outputted .unik files are saved in ${outdir}, with path ${outdir}/xxx/yyy/zzz/${infile}-id_${seqID}.unik where dirctory tree '/xxx/yyy/zzz/' is built for > 1000 output files. 2. For splitting sequence mode (--split-size > 0 or --split-number > 0), output files are: ${outdir}//xxx/yyy/zzz/${infile}/{seqID}-frag_${fragIdx}.unik 3. A summary file (\"${outdir}/_info.txt\") is generated for later use. Users need to check if the reference IDs (column \"name\") are what supposed to be. Performance tips: 1. Decrease value of -j/--threads for data in hard disk drives to reduce I/O pressure. Usage: kmcp compute [flags] Flags: --by-seq \u25ba Compute k-mers (sketches) for every sequence, instead of the whole file. --circular \u25ba Input sequences are circular. -c, --compress \u25ba Output gzipped .unik files, it's slower and can save little space. -r, --file-regexp string \u25ba Regular expression for matching sequence files in -I/--in-dir, case ignored. (default \"\\\\.(f[aq](st[aq])?|fna)(.gz)?$\") --force \u25ba Overwrite existed output directory. -h, --help help for compute -I, --in-dir string \u25ba Directory containing FASTA/Q files. Directory symlinks are followed. -k, --kmer ints \u25ba K-mer size(s). (default [21]) -W, --minimizer-w int \u25ba Minimizer window size. -O, --out-dir string \u25ba Output directory. -N, --ref-name-regexp string \u25ba Regular expression (must contains \"(\" and \")\") for extracting reference name from filename. (default \"(?i)(.+)\\\\.(f[aq](st[aq])?|fna)(.gz)?$\") -D, --scale int \u25ba Scale of the FracMinHash (Scaled MinHash), or down-sample factor for Syncmers and Minimizer. (default 1) -B, --seq-name-filter strings \u25ba List of regular expressions for filtering out sequences by header/name, case ignored. -m, --split-min-ref int \u25ba Only splitting sequences >= X bp. (default 1000) -n, --split-number int \u25ba Fragment number for splitting sequences, incompatible with -s/--split-size. -l, --split-overlap int \u25ba Fragment overlap for splitting sequences. -s, --split-size int \u25ba Fragment size for splitting sequences, incompatible with -n/--split-number. -S, --syncmer-s int \u25ba Length of the s-mer in Closed Syncmers. index Construct database from k-mer files We build index for k-mers (sketches) with a modified compact bit-sliced signature index (COBS). We totally rewrite the algorithms, data structure and file format, and have improved the indexing and searching speed. Attentions: 1. All input .unik files should be generated by \"kmcp compute\". Database size and searching accuracy: 0. Use --dry-run to adjust parameters and check final number of index files (#index-files) and the total file size. 1. -f/--false-positive-rate: the default value 0.3 is enough for a query with tens of matched k-mers (see BIGSI/COBS paper). Small values could largely increase the size of database. 2. -n/--num-hash: large values could reduce the database size, in cost of slower searching speed. Values <=4 is recommended. 3. Value of block size -b/--block-size better be multiple of 64. The default value is: (#unikFiles/#threads + 7) / 8 * 8 4. Use flag -x/--block-sizeX-kmers-t, -8/--block-size8-kmers-t, and -1/--block-size1-kmers-t to separately create index for inputs with huge number of k-mers, for precise control of database size. References: 1. COBS: https://arxiv.org/abs/1905.09624 Taxonomy data: 1. No taxonomy data are included in the database. 2. Taxonomy information are only needed in \"profile\" command. Performance tips: 1. Number of blocks (.uniki files) better be smaller than or equal to number of CPU cores for faster searching speed. We can set -j/--threads to control blocks number. When more threads (>= 1.3 * #blocks) are given, extra workers are automatically created. 2. #threads files are simultaneously opened, and max number of opened files is limited by the flag -F/--max-open-files. You may use a small value of -F/--max-open-files for hard disk drive storage. 3. When the database is used in a new computer with more CPU cores, 'kmcp search' could automatically scale to utilize as many cores as possible. Usage: kmcp index [flags] Flags: -a, --alias string \u25ba Database alias/name. (default: basename of --out-dir). You can also manually edit it in info file: ${outdir}/__db.yml. -b, --block-size int \u25ba Block size, better be multiple of 64 for large number of input files. (default: min(#.files/#theads, 8)) -1, --block-size1-kmers-t string \u25ba If k-mers of single .unik file exceeds this threshold, an individual index is created for this file. Supported units: K, M, G. (default \"200M\") -8, --block-size8-kmers-t string \u25ba If k-mers of single .unik file exceeds this threshold, block size is changed to 8. Supported units: K, M, G. (default \"20M\") -X, --block-sizeX int \u25ba If k-mers of single .unik file exceeds --block-sizeX-kmers-t, block size is changed to this value. (default 256) -x, --block-sizeX-kmers-t string \u25ba If k-mers of single .unik file exceeds this threshold, block size is changed to --block-sizeX. Supported units: K, M, G. (default \"10M\") --dry-run \u25ba Dry run, useful for adjusting parameters (highly recommended). -f, --false-positive-rate float \u25ba False positive rate of the bloom filters, range: (0, 1). (default 0.3) --file-regexp string \u25ba Regular expression for matching files in -I/--in-dir, case ignored. (default \".unik$\") --force \u25ba Overwrite existed output directory. -h, --help help for index -I, --in-dir string \u25ba Directory containing .unik files. Directory symlinks are followed. -F, --max-open-files int \u25ba Maximal number of opened files, please use a small value for hard disk drive storage. (default 256) -n, --num-hash int \u25ba Number of hashes functions in bloom filters. (default 1) -O, --out-dir string \u25ba Output directory. (default: ${indir}.kmcp-db) search Search sequences against a database Attentions: 1. Input format should be (gzipped) FASTA or FASTQ from files or stdin. - Paired-end files should be given via -1/--read1 and -2/--read2. kmcp search -d db -1 read_1.fq.gz -2 read_2.fq.gz -o read.tsv.gz - Single-end can be given as positional arguments or -1/-2. kmcp search -d db file1.fq.gz file2.fq.gz -o result.tsv.gz 2. A long query sequences may contain duplicated k-mers, which are not removed for short sequences by default. You may modify the value of -u/--kmer-dedup-threshold to remove duplicates. 3. For long reads or contigs, you should split them into short reads using \"seqkit sliding\", e.g., seqkit sliding -s 100 -W 300 Shared flags between \"search\" and \"profile\": 1. -t/--min-query-cov. 2. -N/--name-map. Special attentions: 1. The values of tCov and jacc in results only apply to single size of k-mer. Index files loading modes: 1. Using memory-mapped index files with mmap (default) - Faster startup speed when index files are buffered in memory. - Multiple KMCP processes can share the memory. 2. Loading the whole index files into memory (-w/--load-whole-db): - This mode occupies a little more memory. And Multiple KMCP processes can not share the database in memory. - It's slightly faster due to the use of physically contiguous memory. The speedup is more significant for smaller databases. - It's highly recommended when searching on computer clusters, where the default mmap mode would be very slow (in my test). 3. Low memory mode (--low-mem): - Do not load all index files into memory nor use mmap, using file seeking. - It's much slower, >4X slower on SSD and would be much slower on HDD disks. - Only use this mode for small number of queries or a huge database that can't be loaded into memory. Performance tips: 1. Increase value of -j/--threads for acceleratation, but values larger than number of CPU cores won't bring extra speedup. 2. When more threads (>= 1.3 * #blocks) are given, extra workers are automatically created. Usage: kmcp search [flags] Flags: -d, --db-dir string \u25ba Database directory created by \"kmcp index\". -D, --default-name-map \u25ba Load ${db}/__name_mapping.tsv for mapping name first. -S, --do-not-sort \u25ba Do not sort matches of a query. -h, --help help for search -n, --keep-top-scores int \u25ba Keep matches with the top N scores for a query, 0 for all. -K, --keep-unmatched \u25ba Keep unmatched query sequence information. -u, --kmer-dedup-threshold int \u25ba Remove duplicated kmers for a query with >= X k-mers. (default 256) -w, --load-whole-db \u25ba Load all index files into memory, it's faster for small databases but needs more memory. Please read \"Index files loading modes\" in \"kmcp search -h\". --low-mem \u25ba Do not load all index files into memory nor use mmap, the searching would be very very slow for a large number of queries. Please read \"Index files loading modes\" in \"kmcp search -h\". -c, --min-kmers int \u25ba Minimal number of matched k-mers (sketches). (default 30) -t, --min-query-cov float \u25ba Minimal query coverage, i.e., proportion of matched k-mers and unique k-mers of a query. (default 0.55) -m, --min-query-len int \u25ba Minimal query length. (default 70) -T, --min-target-cov float \u25ba Minimal target coverage, i.e., proportion of matched k-mers and unique k-mers of a target. -N, --name-map strings \u25ba Tabular two-column file(s) mapping names to user-defined values. -H, --no-header-row \u25ba Do not print header row. -o, --out-file string \u25ba Out file, supports and recommends a \".gz\" suffix (\"-\" for stdout). (default \"-\") --query-id string \u25ba Custom query Id when using the whole file as a query. -g, --query-whole-file \u25ba Use the whole file as a query, e.g., for genome similarity estimation against k-mer sketch database. -1, --read1 string \u25ba (Gzipped) read1 file. -2, --read2 string \u25ba (Gzipped) read2 file. -s, --sort-by string \u25ba Sort hits by \"qcov\", \"tcov\" or \"jacc\" (Jaccard Index). (default \"qcov\") --try-se \u25ba If paired-end reads have no hits, re-search with read1, if still fails, try read2. -G, --use-filename \u25ba Use file name as query ID when using the whole file as a query. merge Merge search results from multiple databases Input: *. Searching results of the same reads in different databases. *. The order of multiple input reads files should be the same during searching. *. When only one input given, we just copy and write to the input file. This is friendly to workflows which assume multiple inputs are given. Usage: kmcp merge [flags] Flags: -n, --field-hits int \u25ba Field of hits. (default 5) -f, --field-queryIdx int \u25ba Field of queryIdx. (default 15) -h, --help help for merge -H, --no-header-row \u25ba Do not print header row. -o, --out-file string \u25ba Out file, supports and recommends a \".gz\" suffix (\"-\" for stdout). (default \"-\") -s, --sort-by string \u25ba Sort hits by \"qcov\", \"tcov\" or \"jacc\" (Jaccard Index). (default \"qcov\") profile Generate taxonomic profile from search results Methods: 1. Reference genomes can be splitted into fragments when computing k-mers (sketches), which could help to increase the specificity via a threshold, i.e., the minimal proportion of matched fragments (-p/--min-frags-fraction). (***highly recommended***) Another flag -d/--max-frags-depth-stdev further reduces false positives. 2. We require part of the uniquely matched reads of a reference having high similarity, i.e., with high confidence for decreasing the false positive rate. 3. We also use the two-stage taxonomy assignment algorithm in MegaPath to reduce the false positive of ambiguous matches. 4. Multi-aligned queries are proportionally assigned to references with a similar strategy in Metalign. 5. Input files are parsed fours times, therefore STDIN is not supported. Reference: 1. MegaPath: https://doi.org/10.1186/s12864-020-06875-6 2. Metalign: https://doi.org/10.1186/s13059-020-02159-0 Accuracy notes: *. Smaller -t/--min-qcov increase sensitivity in cost of higher false positive rate (-f/--max-fpr) of a query. *. We require part of the uniquely matched reads of a reference having high similarity, i.e., with high confidence for decreasing the false positive rate. E.g., -H >= 0.8 and -P >= 0.1 equals to 90th percentile >= 0.8 *. -U/--min-hic-ureads, minimal number, >= 1 *. -H/--min-hic-ureads-qcov, minimal query coverage, >= -t/--min-qcov *. -P/--min-hic-ureads-prop, minimal proportion, higher values increase precision in cost of sensitivity. *. -R/--max-mismatch-err and -D/--min-dreads-prop is for determing the right reference for ambiguous reads. *. --keep-perfect-match is not recommended, which decreases sensitivity. *. --keep-main-match is not recommended, which affects accuracy of abundance estimation. *. -n/--keep-top-qcovs is not recommended, which affects accuracy of abundance estimation. Profiling modes: We preset six profiling modes, availabe with the flag -m/--mode: - 0 (for pathogen detection) - 1 (higher recall) - 2 (high recall) - 3 (default) - 4 (high precision) - 5 (higher precision) Using this flag will override the relevant options. options m=0 m=1 m=2 m=3 m=4 m=5 -------------------------- ---- --- --- ---- --- ---- -r/--min-frags-reads 1 20 30 50 100 100 -p/--min-frags-fraction 0.2 0.5 0.7 0.8 1 1 -d/--max-frags-depth-stdev 10 10 3 2 2 1.5 -u/--min-uniq-reads 1 20 20 20 50 50 -U/--min-hic-ureads 1 5 5 5 10 10 -H/--min-hic-ureads-qcov 0.55 0.7 0.7 0.75 0.8 0.8 -P/--min-hic-ureads-prop 0.01 0.1 0.2 0.1 0.1 0.15 Taxonomy data: 1. Mapping references IDs to TaxIds: -T/--taxid-map 2. NCBI taxonomy dump files: -X/--taxdump Performance notes: 1. Searching results are parsed in parallel, and the number of lines proceeded by a thread can be set by the flag --chunk-size. 2. However using a lot of threads does not always accelerate processing, 4 threads with chunk size of 500-5000 is fast enough. Profiling output formats: 1. KMCP (-o/--out-prefix) 2. CAMI (-M/--metaphlan-report) 3. MetaPhlAn (-C/--cami-report) Taxonomic binning formats: 1. CAMI (-B/--binning-result) Usage: kmcp profile [flags] Flags: -B, --binning-result string \u25ba Save extra binning result in CAMI report. -C, --cami-report string \u25ba Save extra CAMI-like report. --chunk-size int \u25ba Number of lines to process for each thread, and 4 threads is fast enough. Type \"kmcp profile -h\" for details. (default 5000) --debug string \u25ba Debug output file. -F, --filter-low-pct float \u25ba Filter out predictions with the smallest relative abundances summing up X%. Range: [0,100). -h, --help help for profile --keep-main-match \u25ba Only keep main matches, abandon matches with sharply decreased qcov (> --max-qcov-gap). --keep-perfect-match \u25ba Only keep the perfect matches (qcov == 1) if there are. -n, --keep-top-qcovs int \u25ba Keep matches with the top N qcovs for a query, 0 for all. --level string \u25ba Level to estimate abundance at. Available values: species, strain/assembly. (default \"species\") -f, --max-fpr float \u25ba Maximal false positive rate of a read in search result. (default 0.05) -d, --max-frags-depth-stdev float \u25ba Maximal standard deviation of relative depths of all fragments. (default 2) -R, --max-mismatch-err float \u25ba Maximal error rate of a read being matched to a wrong reference, for determing the right reference for ambiguous reads. Range: (0, 1). (default 0.05) --max-qcov-gap float \u25ba Max qcov gap between adjacent matches. (default 0.2) -M, --metaphlan-report string \u25ba Save extra metaphlan-like report. -D, --min-dreads-prop float \u25ba Minimal proportion of distinct reads, for determing the right reference for ambiguous reads. Range: (0, 1). (default 0.05) -p, --min-frags-fraction float \u25ba Minimal fraction of matched reference fragments with reads >= -r/--min-frags-reads. (default 0.8) -r, --min-frags-reads int \u25ba Minimal number of reads for a reference fragment. (default 50) -U, --min-hic-ureads int \u25ba Minimal number of high-confidence uniquely matched reads for a reference. (default 5) -P, --min-hic-ureads-prop float \u25ba Minimal proportion of high-confidence uniquely matched reads. (default 0.1) -H, --min-hic-ureads-qcov float \u25ba Minimal query coverage of high-confidence uniquely matched reads. (default 0.75) -t, --min-query-cov float \u25ba Minimal query coverage of a read in search result. (default 0.55) -u, --min-uniq-reads int \u25ba Minimal number of uniquely matched reads for a reference. (default 20) -m, --mode int \u25ba Profiling mode, type \"kmcp profile -h\" for details. available values: 0 (for pathogen detection), 1 (higherrecall), 2 (high recall), 3 (default), 4 (high precision), 5 (higher precision). (default 3) -N, --name-map strings \u25ba Tabular two-column file(s) mapping reference IDs to reference names. --no-amb-corr \u25ba Do not correct ambiguous reads (just for benchmark). --norm-abund string \u25ba Method for normalize abundance of a reference by the mean/min/max abundance in all fragments, available values: mean, min, max. (default \"mean\") -o, --out-prefix string \u25ba Out file prefix (\"-\" for stdout). (default \"-\") --rank-prefix strings \u25ba Prefixes of taxon name in certain ranks, used with --metaphlan-report. (default [k__,p__,c__,o__,f__,g__,s__,t__]) -s, --sample-id string \u25ba Sample ID in result file. -S, --separator string \u25ba Separator of TaxIds and taxonomy names. (default \";\") --show-rank strings \u25ba Only show TaxIds and names of these ranks. (default [superkingdom,phylum,class,order,family,genus,species,strain]) -X, --taxdump string \u25ba Directory of NCBI taxonomy dump files: names.dmp, nodes.dmp, optional with merged.dmp and delnodes.dmp. -T, --taxid-map strings \u25ba Tabular two-column file(s) mapping reference IDs to TaxIds. --taxonomy-id string \u25ba Taxonomy ID in result file. utils Some utilities Usage: kmcp utils [command] Available Commands: filter Filter search results and find species/assembly-specific queries index-info Print information of index file merge-regions Merge species/assembly-specific regions unik-info Print information of .unik file filter Filter search results and find species/assembly-specific queries Taxonomy data: 1. Mapping references IDs to TaxIds: -T/--taxid-map 2. NCBI taxonomy dump files: -X/--taxdump Performance notes: 1. Searching results are parsed in parallel, and the number of lines proceeded by a thread can be set by the flag --chunk-size. 2. However using a lot of threads does not always accelerate processing, 4 threads with chunk size of 500-5000 is fast enough. Usage: kmcp utils filter [flags] Flags: --chunk-size int \u25ba Number of lines to process for each thread, and 4 threads is fast enough. Type \"kmcp profile -h\" for details. (default 5000) -h, --help help for filter --level string \u25ba Level to filter. available values: species, strain/assembly. (default \"species\") -f, --max-fpr float \u25ba Maximal false positive rate of a read in search result. (default 0.05) -t, --min-query-cov float \u25ba Minimal query coverage of a read in search result. (default 0.55) -H, --no-header-row \u25ba Do not print header row. -o, --out-prefix string \u25ba Out file prefix (\"-\" for stdout). (default \"-\") -X, --taxdump string \u25ba Directory of NCBI taxonomy dump files: names.dmp, nodes.dmp, optional with merged.dmp and delnodes.dmp. -T, --taxid-map strings \u25ba Tabular two-column file(s) mapping reference IDs to TaxIds. index-info Print information of index file Usage: kmcp utils index-info [flags] Flags: -a, --all \u25ba Show all information. -b, --basename \u25ba Only output basenames of files. -h, --help help for index-info -o, --out-prefix string \u25ba Out file prefix (\"-\" for stdout). (default \"-\") merge-regions Merge species/assembly-specific regions Steps: # 1. Simulating reads and searching on one or more databases. seqkit sliding --step 10 --window 100 ref.fna.gz \\ | kmcp search -d db1.kmcp -o ref.fna.gz.kmcp@db1.tsv.gz seqkit sliding --step 10 --window 100 ref.fna.gz \\ | kmcp search -d db2.kmcp -o ref.fna.gz.kmcp@db2.tsv.gz # 2. Merging and filtering searching results kmcp merge ref.fna.gz.kmcp@*.tsv.gz \\ | kmcp utils filter -X taxdump -T taxid.map \\ -o ref.fna.gz.kmcp.uniq.tsv.gz # 3. Merging regions. # Here the value of --min-overlap should be k-1. kmcp utils merge-regions --min-overlap 20 ref.fna.gz.kmcp.uniq.tsv.gz \\ -o ref.fna.gz.kmcp.uniq.tsv.gz.bed Output (BED6 format): 1. chrom - chromosome name 2. chromStart - starting position (0-based) 3. chromEnd - ending position (0-based) 4. name - \"species-specific\" or \"assembly-specific\" 5. score - 0-1000, 1000 for \"assembly-specific\", others for \"\"species-specific\" 6. strand - \".\" Performance notes: 1. Searching results are parsed in parallel, and the number of lines proceeded by a thread can be set by the flag --chunk-size. 2. However using a lot of threads does not always accelerate processing, 4 threads with chunk size of 500-5000 is fast enough. Usage: kmcp utils merge-regions [flags] Flags: --chunk-size int \u25ba Number of lines to process for each thread, and 4 threads is fast enough. Type \"kmcp profile -h\" for details. (default 5000) -h, --help help for merge-regions -I, --ignore-type \u25ba Merge species and assembly-specific regions. -f, --max-fpr float \u25ba Maximal false positive rate of a read in search result. (default 0.05) -g, --max-gap int \u25ba Maximal distance of starting positions of two adjacent regions, 0 for no limitation, 1 for no merging. -l, --min-overlap int \u25ba Minimal overlap of two adjacent regions, recommend K-1. (default 1) -t, --min-query-cov float \u25ba Minimal query coverage of a read in search result. (default 0.55) -a, --name-assembly string \u25ba Name of assembly-specific regions. (default \"assembly-specific\") -s, --name-species string \u25ba Name of species-specific regions. (default \"species-specific\") -o, --out-prefix string \u25ba Out file prefix (\"-\" for stdout). (default \"-\") -r, --regexp string \u25ba Regular expression for extract reference name and query locations. (default \"^(.+)_sliding:(\\\\d+)\\\\-(\\\\d+)$\") unik-info Print information of .unik file Tips: 1. For lots of small files (especially on SDD), use big value of '-j' to parallelize counting. Usage: kmcp utils unik-info [flags] Flags: -a, --all \u25ba All information, including the number of k-mers. -b, --basename \u25ba Only output basename of files. -h, --help help for unik-info -o, --out-file string \u25ba Out file (\"-\" for stdout, suffix .gz for gzipped out.) (default \"-\") -e, --skip-err \u25ba Skip error, only show warning message. --symbol-false string \u25ba Smybol for false. (default \"\u2715\") --symbol-true string \u25ba Smybol for true. (default \"\u2713\") -T, --tabular \u25ba Output in machine-friendly tabular format. autocompletion Generate shell autocompletion script Supported shell: bash|zsh|fish|powershell Bash: # generate completion shell kmcp autocompletion --shell bash # configure if never did. # install bash-completion if the \"complete\" command is not found. echo \"for bcfile in ~/.bash_completion.d/* ; do source \\$bcfile; done\" >> ~/.bash_completion echo \"source ~/.bash_completion\" >> ~/.bashrc Zsh: # generate completion shell kmcp autocompletion --shell zsh --file ~/.zfunc/_kmcp # configure if never did echo 'fpath=( ~/.zfunc \"${fpath[@]}\" )' >> ~/.zshrc echo \"autoload -U compinit; compinit\" >> ~/.zshrc fish: kmcp autocompletion --shell fish --file ~/.config/fish/completions/kmcp.fish Usage: kmcp autocompletion [flags] Flags: --file string autocompletion file (default \"/home/shenwei/.bash_completion.d/kmcp.sh\") -h, --help help for autocompletion --shell string autocompletion type (bash|zsh|fish|powershell) (default \"bash\")","title":"Usage"},{"location":"usage/#usage","text":"KMCP is a command-line tool consisting of several subcommands. Program: kmcp (K-mer-based Metagenomic Classification and Profiling) Version: v0.7.0 Documents: https://bioinf.shenwei.me/kmcp Source code: https://github.com/shenwei356/kmcp KMCP is a tool for metagenomic classification and profiling. KMCP can also be used for: 1. Fast sequence search against large scales of genomic datasets as BIGSI and COBS do. 2. Fast assembly/genome similarity estimation as Mash and sourmash do, by utilizing Minimizer, FracMinHash (Scaled MinHash), or Closed Syncmers. Usage: kmcp [command] Available Commands: autocompletion Generate shell autocompletion script compute Generate k-mers (sketches) from FASTA/Q sequences index Construct database from k-mer files merge Merge search results from multiple databases profile Generate taxonomic profile from search results search Search sequence against a database utils Some utilities version Print version information and check for update Flags: -h, --help help for kmcp -i, --infile-list string \u25ba File of input files list (one file per line). If given, they are appended to files from CLI arguments. --log string \u25ba Log file. -q, --quiet \u25ba Do not print any verbose information. But you can write them to file with --log. -j, --threads int \u25ba Number of CPUs cores to use. (default 16)","title":"Usage"},{"location":"usage/#compute","text":"Generate k-mers (sketches) from FASTA/Q sequences Attentions: 1. Input files can be given as list of FASTA/Q files via positional arguments or a directory containing sequence files via the flag -I/--in-dir. A regular expression for matching sequencing files is available by the flag -r/--file-regexp. 2. Unwanted sequence like plasmid can be filtered out by the name via regular expressions (-B/--seq-name-filter). 3. By default, kmcp computes k-mers (sketches) of every file, you can also use --by-seq to compute for every sequence, where sequence IDs in all input files better be distinct. 4. It also supports splitting sequences into fragments, this could increase the specificity in profiling result in cost of slower searching speed. 5. Multiple sizes of k-mers are supported. Supported k-mer (sketches) types: 1. K-mer: 1). ntHash of k-mer (-k) 2. K-mer sketchs (all using ntHash): 1). FracMinHash (-k -D), previously named Scaled MinHash 2). Minimizer (-k -W), optionally scaling/down-sampling (-D) 3). Closed Syncmer (-k -S), optionally scaling/down-sampling (-D) Splitting sequences: 1. Sequences can be splitted into fragments by a fragment size (-s/--split-size) or number of fragments (-n/--split-number) with overlap (-l/--split-overlap). 2. When splitting by number of fragments, all sequences (except for these mathching any regular expression given by -B/--seq-name-filter) in a sequence file are concatenated with k-1 'N's before splitting. 3. Both sequence IDs and fragments indices are saved for later use, in form of meta/description data in .unik files. Meta data: 1. Every outputted .unik file contains the sequence/reference ID, fragment index, number of fragments, and genome size of reference. 2. When parsing whole sequence files or splitting by number of fragments, the identifier of a reference is the basename of the input file by default. It can also be extracted from the input file name via -N/--ref-name-regexp, e.g., \"^(\\w{3}_\\d{9}\\.\\d+)\" for refseq records. Output: 1. All outputted .unik files are saved in ${outdir}, with path ${outdir}/xxx/yyy/zzz/${infile}-id_${seqID}.unik where dirctory tree '/xxx/yyy/zzz/' is built for > 1000 output files. 2. For splitting sequence mode (--split-size > 0 or --split-number > 0), output files are: ${outdir}//xxx/yyy/zzz/${infile}/{seqID}-frag_${fragIdx}.unik 3. A summary file (\"${outdir}/_info.txt\") is generated for later use. Users need to check if the reference IDs (column \"name\") are what supposed to be. Performance tips: 1. Decrease value of -j/--threads for data in hard disk drives to reduce I/O pressure. Usage: kmcp compute [flags] Flags: --by-seq \u25ba Compute k-mers (sketches) for every sequence, instead of the whole file. --circular \u25ba Input sequences are circular. -c, --compress \u25ba Output gzipped .unik files, it's slower and can save little space. -r, --file-regexp string \u25ba Regular expression for matching sequence files in -I/--in-dir, case ignored. (default \"\\\\.(f[aq](st[aq])?|fna)(.gz)?$\") --force \u25ba Overwrite existed output directory. -h, --help help for compute -I, --in-dir string \u25ba Directory containing FASTA/Q files. Directory symlinks are followed. -k, --kmer ints \u25ba K-mer size(s). (default [21]) -W, --minimizer-w int \u25ba Minimizer window size. -O, --out-dir string \u25ba Output directory. -N, --ref-name-regexp string \u25ba Regular expression (must contains \"(\" and \")\") for extracting reference name from filename. (default \"(?i)(.+)\\\\.(f[aq](st[aq])?|fna)(.gz)?$\") -D, --scale int \u25ba Scale of the FracMinHash (Scaled MinHash), or down-sample factor for Syncmers and Minimizer. (default 1) -B, --seq-name-filter strings \u25ba List of regular expressions for filtering out sequences by header/name, case ignored. -m, --split-min-ref int \u25ba Only splitting sequences >= X bp. (default 1000) -n, --split-number int \u25ba Fragment number for splitting sequences, incompatible with -s/--split-size. -l, --split-overlap int \u25ba Fragment overlap for splitting sequences. -s, --split-size int \u25ba Fragment size for splitting sequences, incompatible with -n/--split-number. -S, --syncmer-s int \u25ba Length of the s-mer in Closed Syncmers.","title":"compute"},{"location":"usage/#index","text":"Construct database from k-mer files We build index for k-mers (sketches) with a modified compact bit-sliced signature index (COBS). We totally rewrite the algorithms, data structure and file format, and have improved the indexing and searching speed. Attentions: 1. All input .unik files should be generated by \"kmcp compute\". Database size and searching accuracy: 0. Use --dry-run to adjust parameters and check final number of index files (#index-files) and the total file size. 1. -f/--false-positive-rate: the default value 0.3 is enough for a query with tens of matched k-mers (see BIGSI/COBS paper). Small values could largely increase the size of database. 2. -n/--num-hash: large values could reduce the database size, in cost of slower searching speed. Values <=4 is recommended. 3. Value of block size -b/--block-size better be multiple of 64. The default value is: (#unikFiles/#threads + 7) / 8 * 8 4. Use flag -x/--block-sizeX-kmers-t, -8/--block-size8-kmers-t, and -1/--block-size1-kmers-t to separately create index for inputs with huge number of k-mers, for precise control of database size. References: 1. COBS: https://arxiv.org/abs/1905.09624 Taxonomy data: 1. No taxonomy data are included in the database. 2. Taxonomy information are only needed in \"profile\" command. Performance tips: 1. Number of blocks (.uniki files) better be smaller than or equal to number of CPU cores for faster searching speed. We can set -j/--threads to control blocks number. When more threads (>= 1.3 * #blocks) are given, extra workers are automatically created. 2. #threads files are simultaneously opened, and max number of opened files is limited by the flag -F/--max-open-files. You may use a small value of -F/--max-open-files for hard disk drive storage. 3. When the database is used in a new computer with more CPU cores, 'kmcp search' could automatically scale to utilize as many cores as possible. Usage: kmcp index [flags] Flags: -a, --alias string \u25ba Database alias/name. (default: basename of --out-dir). You can also manually edit it in info file: ${outdir}/__db.yml. -b, --block-size int \u25ba Block size, better be multiple of 64 for large number of input files. (default: min(#.files/#theads, 8)) -1, --block-size1-kmers-t string \u25ba If k-mers of single .unik file exceeds this threshold, an individual index is created for this file. Supported units: K, M, G. (default \"200M\") -8, --block-size8-kmers-t string \u25ba If k-mers of single .unik file exceeds this threshold, block size is changed to 8. Supported units: K, M, G. (default \"20M\") -X, --block-sizeX int \u25ba If k-mers of single .unik file exceeds --block-sizeX-kmers-t, block size is changed to this value. (default 256) -x, --block-sizeX-kmers-t string \u25ba If k-mers of single .unik file exceeds this threshold, block size is changed to --block-sizeX. Supported units: K, M, G. (default \"10M\") --dry-run \u25ba Dry run, useful for adjusting parameters (highly recommended). -f, --false-positive-rate float \u25ba False positive rate of the bloom filters, range: (0, 1). (default 0.3) --file-regexp string \u25ba Regular expression for matching files in -I/--in-dir, case ignored. (default \".unik$\") --force \u25ba Overwrite existed output directory. -h, --help help for index -I, --in-dir string \u25ba Directory containing .unik files. Directory symlinks are followed. -F, --max-open-files int \u25ba Maximal number of opened files, please use a small value for hard disk drive storage. (default 256) -n, --num-hash int \u25ba Number of hashes functions in bloom filters. (default 1) -O, --out-dir string \u25ba Output directory. (default: ${indir}.kmcp-db)","title":"index"},{"location":"usage/#search","text":"Search sequences against a database Attentions: 1. Input format should be (gzipped) FASTA or FASTQ from files or stdin. - Paired-end files should be given via -1/--read1 and -2/--read2. kmcp search -d db -1 read_1.fq.gz -2 read_2.fq.gz -o read.tsv.gz - Single-end can be given as positional arguments or -1/-2. kmcp search -d db file1.fq.gz file2.fq.gz -o result.tsv.gz 2. A long query sequences may contain duplicated k-mers, which are not removed for short sequences by default. You may modify the value of -u/--kmer-dedup-threshold to remove duplicates. 3. For long reads or contigs, you should split them into short reads using \"seqkit sliding\", e.g., seqkit sliding -s 100 -W 300 Shared flags between \"search\" and \"profile\": 1. -t/--min-query-cov. 2. -N/--name-map. Special attentions: 1. The values of tCov and jacc in results only apply to single size of k-mer. Index files loading modes: 1. Using memory-mapped index files with mmap (default) - Faster startup speed when index files are buffered in memory. - Multiple KMCP processes can share the memory. 2. Loading the whole index files into memory (-w/--load-whole-db): - This mode occupies a little more memory. And Multiple KMCP processes can not share the database in memory. - It's slightly faster due to the use of physically contiguous memory. The speedup is more significant for smaller databases. - It's highly recommended when searching on computer clusters, where the default mmap mode would be very slow (in my test). 3. Low memory mode (--low-mem): - Do not load all index files into memory nor use mmap, using file seeking. - It's much slower, >4X slower on SSD and would be much slower on HDD disks. - Only use this mode for small number of queries or a huge database that can't be loaded into memory. Performance tips: 1. Increase value of -j/--threads for acceleratation, but values larger than number of CPU cores won't bring extra speedup. 2. When more threads (>= 1.3 * #blocks) are given, extra workers are automatically created. Usage: kmcp search [flags] Flags: -d, --db-dir string \u25ba Database directory created by \"kmcp index\". -D, --default-name-map \u25ba Load ${db}/__name_mapping.tsv for mapping name first. -S, --do-not-sort \u25ba Do not sort matches of a query. -h, --help help for search -n, --keep-top-scores int \u25ba Keep matches with the top N scores for a query, 0 for all. -K, --keep-unmatched \u25ba Keep unmatched query sequence information. -u, --kmer-dedup-threshold int \u25ba Remove duplicated kmers for a query with >= X k-mers. (default 256) -w, --load-whole-db \u25ba Load all index files into memory, it's faster for small databases but needs more memory. Please read \"Index files loading modes\" in \"kmcp search -h\". --low-mem \u25ba Do not load all index files into memory nor use mmap, the searching would be very very slow for a large number of queries. Please read \"Index files loading modes\" in \"kmcp search -h\". -c, --min-kmers int \u25ba Minimal number of matched k-mers (sketches). (default 30) -t, --min-query-cov float \u25ba Minimal query coverage, i.e., proportion of matched k-mers and unique k-mers of a query. (default 0.55) -m, --min-query-len int \u25ba Minimal query length. (default 70) -T, --min-target-cov float \u25ba Minimal target coverage, i.e., proportion of matched k-mers and unique k-mers of a target. -N, --name-map strings \u25ba Tabular two-column file(s) mapping names to user-defined values. -H, --no-header-row \u25ba Do not print header row. -o, --out-file string \u25ba Out file, supports and recommends a \".gz\" suffix (\"-\" for stdout). (default \"-\") --query-id string \u25ba Custom query Id when using the whole file as a query. -g, --query-whole-file \u25ba Use the whole file as a query, e.g., for genome similarity estimation against k-mer sketch database. -1, --read1 string \u25ba (Gzipped) read1 file. -2, --read2 string \u25ba (Gzipped) read2 file. -s, --sort-by string \u25ba Sort hits by \"qcov\", \"tcov\" or \"jacc\" (Jaccard Index). (default \"qcov\") --try-se \u25ba If paired-end reads have no hits, re-search with read1, if still fails, try read2. -G, --use-filename \u25ba Use file name as query ID when using the whole file as a query.","title":"search"},{"location":"usage/#merge","text":"Merge search results from multiple databases Input: *. Searching results of the same reads in different databases. *. The order of multiple input reads files should be the same during searching. *. When only one input given, we just copy and write to the input file. This is friendly to workflows which assume multiple inputs are given. Usage: kmcp merge [flags] Flags: -n, --field-hits int \u25ba Field of hits. (default 5) -f, --field-queryIdx int \u25ba Field of queryIdx. (default 15) -h, --help help for merge -H, --no-header-row \u25ba Do not print header row. -o, --out-file string \u25ba Out file, supports and recommends a \".gz\" suffix (\"-\" for stdout). (default \"-\") -s, --sort-by string \u25ba Sort hits by \"qcov\", \"tcov\" or \"jacc\" (Jaccard Index). (default \"qcov\")","title":"merge"},{"location":"usage/#profile","text":"Generate taxonomic profile from search results Methods: 1. Reference genomes can be splitted into fragments when computing k-mers (sketches), which could help to increase the specificity via a threshold, i.e., the minimal proportion of matched fragments (-p/--min-frags-fraction). (***highly recommended***) Another flag -d/--max-frags-depth-stdev further reduces false positives. 2. We require part of the uniquely matched reads of a reference having high similarity, i.e., with high confidence for decreasing the false positive rate. 3. We also use the two-stage taxonomy assignment algorithm in MegaPath to reduce the false positive of ambiguous matches. 4. Multi-aligned queries are proportionally assigned to references with a similar strategy in Metalign. 5. Input files are parsed fours times, therefore STDIN is not supported. Reference: 1. MegaPath: https://doi.org/10.1186/s12864-020-06875-6 2. Metalign: https://doi.org/10.1186/s13059-020-02159-0 Accuracy notes: *. Smaller -t/--min-qcov increase sensitivity in cost of higher false positive rate (-f/--max-fpr) of a query. *. We require part of the uniquely matched reads of a reference having high similarity, i.e., with high confidence for decreasing the false positive rate. E.g., -H >= 0.8 and -P >= 0.1 equals to 90th percentile >= 0.8 *. -U/--min-hic-ureads, minimal number, >= 1 *. -H/--min-hic-ureads-qcov, minimal query coverage, >= -t/--min-qcov *. -P/--min-hic-ureads-prop, minimal proportion, higher values increase precision in cost of sensitivity. *. -R/--max-mismatch-err and -D/--min-dreads-prop is for determing the right reference for ambiguous reads. *. --keep-perfect-match is not recommended, which decreases sensitivity. *. --keep-main-match is not recommended, which affects accuracy of abundance estimation. *. -n/--keep-top-qcovs is not recommended, which affects accuracy of abundance estimation. Profiling modes: We preset six profiling modes, availabe with the flag -m/--mode: - 0 (for pathogen detection) - 1 (higher recall) - 2 (high recall) - 3 (default) - 4 (high precision) - 5 (higher precision) Using this flag will override the relevant options. options m=0 m=1 m=2 m=3 m=4 m=5 -------------------------- ---- --- --- ---- --- ---- -r/--min-frags-reads 1 20 30 50 100 100 -p/--min-frags-fraction 0.2 0.5 0.7 0.8 1 1 -d/--max-frags-depth-stdev 10 10 3 2 2 1.5 -u/--min-uniq-reads 1 20 20 20 50 50 -U/--min-hic-ureads 1 5 5 5 10 10 -H/--min-hic-ureads-qcov 0.55 0.7 0.7 0.75 0.8 0.8 -P/--min-hic-ureads-prop 0.01 0.1 0.2 0.1 0.1 0.15 Taxonomy data: 1. Mapping references IDs to TaxIds: -T/--taxid-map 2. NCBI taxonomy dump files: -X/--taxdump Performance notes: 1. Searching results are parsed in parallel, and the number of lines proceeded by a thread can be set by the flag --chunk-size. 2. However using a lot of threads does not always accelerate processing, 4 threads with chunk size of 500-5000 is fast enough. Profiling output formats: 1. KMCP (-o/--out-prefix) 2. CAMI (-M/--metaphlan-report) 3. MetaPhlAn (-C/--cami-report) Taxonomic binning formats: 1. CAMI (-B/--binning-result) Usage: kmcp profile [flags] Flags: -B, --binning-result string \u25ba Save extra binning result in CAMI report. -C, --cami-report string \u25ba Save extra CAMI-like report. --chunk-size int \u25ba Number of lines to process for each thread, and 4 threads is fast enough. Type \"kmcp profile -h\" for details. (default 5000) --debug string \u25ba Debug output file. -F, --filter-low-pct float \u25ba Filter out predictions with the smallest relative abundances summing up X%. Range: [0,100). -h, --help help for profile --keep-main-match \u25ba Only keep main matches, abandon matches with sharply decreased qcov (> --max-qcov-gap). --keep-perfect-match \u25ba Only keep the perfect matches (qcov == 1) if there are. -n, --keep-top-qcovs int \u25ba Keep matches with the top N qcovs for a query, 0 for all. --level string \u25ba Level to estimate abundance at. Available values: species, strain/assembly. (default \"species\") -f, --max-fpr float \u25ba Maximal false positive rate of a read in search result. (default 0.05) -d, --max-frags-depth-stdev float \u25ba Maximal standard deviation of relative depths of all fragments. (default 2) -R, --max-mismatch-err float \u25ba Maximal error rate of a read being matched to a wrong reference, for determing the right reference for ambiguous reads. Range: (0, 1). (default 0.05) --max-qcov-gap float \u25ba Max qcov gap between adjacent matches. (default 0.2) -M, --metaphlan-report string \u25ba Save extra metaphlan-like report. -D, --min-dreads-prop float \u25ba Minimal proportion of distinct reads, for determing the right reference for ambiguous reads. Range: (0, 1). (default 0.05) -p, --min-frags-fraction float \u25ba Minimal fraction of matched reference fragments with reads >= -r/--min-frags-reads. (default 0.8) -r, --min-frags-reads int \u25ba Minimal number of reads for a reference fragment. (default 50) -U, --min-hic-ureads int \u25ba Minimal number of high-confidence uniquely matched reads for a reference. (default 5) -P, --min-hic-ureads-prop float \u25ba Minimal proportion of high-confidence uniquely matched reads. (default 0.1) -H, --min-hic-ureads-qcov float \u25ba Minimal query coverage of high-confidence uniquely matched reads. (default 0.75) -t, --min-query-cov float \u25ba Minimal query coverage of a read in search result. (default 0.55) -u, --min-uniq-reads int \u25ba Minimal number of uniquely matched reads for a reference. (default 20) -m, --mode int \u25ba Profiling mode, type \"kmcp profile -h\" for details. available values: 0 (for pathogen detection), 1 (higherrecall), 2 (high recall), 3 (default), 4 (high precision), 5 (higher precision). (default 3) -N, --name-map strings \u25ba Tabular two-column file(s) mapping reference IDs to reference names. --no-amb-corr \u25ba Do not correct ambiguous reads (just for benchmark). --norm-abund string \u25ba Method for normalize abundance of a reference by the mean/min/max abundance in all fragments, available values: mean, min, max. (default \"mean\") -o, --out-prefix string \u25ba Out file prefix (\"-\" for stdout). (default \"-\") --rank-prefix strings \u25ba Prefixes of taxon name in certain ranks, used with --metaphlan-report. (default [k__,p__,c__,o__,f__,g__,s__,t__]) -s, --sample-id string \u25ba Sample ID in result file. -S, --separator string \u25ba Separator of TaxIds and taxonomy names. (default \";\") --show-rank strings \u25ba Only show TaxIds and names of these ranks. (default [superkingdom,phylum,class,order,family,genus,species,strain]) -X, --taxdump string \u25ba Directory of NCBI taxonomy dump files: names.dmp, nodes.dmp, optional with merged.dmp and delnodes.dmp. -T, --taxid-map strings \u25ba Tabular two-column file(s) mapping reference IDs to TaxIds. --taxonomy-id string \u25ba Taxonomy ID in result file.","title":"profile"},{"location":"usage/#utils","text":"Some utilities Usage: kmcp utils [command] Available Commands: filter Filter search results and find species/assembly-specific queries index-info Print information of index file merge-regions Merge species/assembly-specific regions unik-info Print information of .unik file","title":"utils"},{"location":"usage/#filter","text":"Filter search results and find species/assembly-specific queries Taxonomy data: 1. Mapping references IDs to TaxIds: -T/--taxid-map 2. NCBI taxonomy dump files: -X/--taxdump Performance notes: 1. Searching results are parsed in parallel, and the number of lines proceeded by a thread can be set by the flag --chunk-size. 2. However using a lot of threads does not always accelerate processing, 4 threads with chunk size of 500-5000 is fast enough. Usage: kmcp utils filter [flags] Flags: --chunk-size int \u25ba Number of lines to process for each thread, and 4 threads is fast enough. Type \"kmcp profile -h\" for details. (default 5000) -h, --help help for filter --level string \u25ba Level to filter. available values: species, strain/assembly. (default \"species\") -f, --max-fpr float \u25ba Maximal false positive rate of a read in search result. (default 0.05) -t, --min-query-cov float \u25ba Minimal query coverage of a read in search result. (default 0.55) -H, --no-header-row \u25ba Do not print header row. -o, --out-prefix string \u25ba Out file prefix (\"-\" for stdout). (default \"-\") -X, --taxdump string \u25ba Directory of NCBI taxonomy dump files: names.dmp, nodes.dmp, optional with merged.dmp and delnodes.dmp. -T, --taxid-map strings \u25ba Tabular two-column file(s) mapping reference IDs to TaxIds.","title":"filter"},{"location":"usage/#index-info","text":"Print information of index file Usage: kmcp utils index-info [flags] Flags: -a, --all \u25ba Show all information. -b, --basename \u25ba Only output basenames of files. -h, --help help for index-info -o, --out-prefix string \u25ba Out file prefix (\"-\" for stdout). (default \"-\")","title":"index-info"},{"location":"usage/#merge-regions","text":"Merge species/assembly-specific regions Steps: # 1. Simulating reads and searching on one or more databases. seqkit sliding --step 10 --window 100 ref.fna.gz \\ | kmcp search -d db1.kmcp -o ref.fna.gz.kmcp@db1.tsv.gz seqkit sliding --step 10 --window 100 ref.fna.gz \\ | kmcp search -d db2.kmcp -o ref.fna.gz.kmcp@db2.tsv.gz # 2. Merging and filtering searching results kmcp merge ref.fna.gz.kmcp@*.tsv.gz \\ | kmcp utils filter -X taxdump -T taxid.map \\ -o ref.fna.gz.kmcp.uniq.tsv.gz # 3. Merging regions. # Here the value of --min-overlap should be k-1. kmcp utils merge-regions --min-overlap 20 ref.fna.gz.kmcp.uniq.tsv.gz \\ -o ref.fna.gz.kmcp.uniq.tsv.gz.bed Output (BED6 format): 1. chrom - chromosome name 2. chromStart - starting position (0-based) 3. chromEnd - ending position (0-based) 4. name - \"species-specific\" or \"assembly-specific\" 5. score - 0-1000, 1000 for \"assembly-specific\", others for \"\"species-specific\" 6. strand - \".\" Performance notes: 1. Searching results are parsed in parallel, and the number of lines proceeded by a thread can be set by the flag --chunk-size. 2. However using a lot of threads does not always accelerate processing, 4 threads with chunk size of 500-5000 is fast enough. Usage: kmcp utils merge-regions [flags] Flags: --chunk-size int \u25ba Number of lines to process for each thread, and 4 threads is fast enough. Type \"kmcp profile -h\" for details. (default 5000) -h, --help help for merge-regions -I, --ignore-type \u25ba Merge species and assembly-specific regions. -f, --max-fpr float \u25ba Maximal false positive rate of a read in search result. (default 0.05) -g, --max-gap int \u25ba Maximal distance of starting positions of two adjacent regions, 0 for no limitation, 1 for no merging. -l, --min-overlap int \u25ba Minimal overlap of two adjacent regions, recommend K-1. (default 1) -t, --min-query-cov float \u25ba Minimal query coverage of a read in search result. (default 0.55) -a, --name-assembly string \u25ba Name of assembly-specific regions. (default \"assembly-specific\") -s, --name-species string \u25ba Name of species-specific regions. (default \"species-specific\") -o, --out-prefix string \u25ba Out file prefix (\"-\" for stdout). (default \"-\") -r, --regexp string \u25ba Regular expression for extract reference name and query locations. (default \"^(.+)_sliding:(\\\\d+)\\\\-(\\\\d+)$\")","title":"merge-regions"},{"location":"usage/#unik-info","text":"Print information of .unik file Tips: 1. For lots of small files (especially on SDD), use big value of '-j' to parallelize counting. Usage: kmcp utils unik-info [flags] Flags: -a, --all \u25ba All information, including the number of k-mers. -b, --basename \u25ba Only output basename of files. -h, --help help for unik-info -o, --out-file string \u25ba Out file (\"-\" for stdout, suffix .gz for gzipped out.) (default \"-\") -e, --skip-err \u25ba Skip error, only show warning message. --symbol-false string \u25ba Smybol for false. (default \"\u2715\") --symbol-true string \u25ba Smybol for true. (default \"\u2713\") -T, --tabular \u25ba Output in machine-friendly tabular format.","title":"unik-info"},{"location":"usage/#autocompletion","text":"Generate shell autocompletion script Supported shell: bash|zsh|fish|powershell Bash: # generate completion shell kmcp autocompletion --shell bash # configure if never did. # install bash-completion if the \"complete\" command is not found. echo \"for bcfile in ~/.bash_completion.d/* ; do source \\$bcfile; done\" >> ~/.bash_completion echo \"source ~/.bash_completion\" >> ~/.bashrc Zsh: # generate completion shell kmcp autocompletion --shell zsh --file ~/.zfunc/_kmcp # configure if never did echo 'fpath=( ~/.zfunc \"${fpath[@]}\" )' >> ~/.zshrc echo \"autoload -U compinit; compinit\" >> ~/.zshrc fish: kmcp autocompletion --shell fish --file ~/.config/fish/completions/kmcp.fish Usage: kmcp autocompletion [flags] Flags: --file string autocompletion file (default \"/home/shenwei/.bash_completion.d/kmcp.sh\") -h, --help help for autocompletion --shell string autocompletion type (bash|zsh|fish|powershell) (default \"bash\")","title":"autocompletion"},{"location":"benchmark/","text":"","title":"Index"},{"location":"benchmark/profiling/","text":"Benchmark 64 simulated mouse gut short-read datasets from CAMI2 challenge (prokaryotes) Software, databases and commands details . Softwares: mOTUs 2.5.1 MetaPHlAn 2.9.21 Bracken 2.5 KMCP v0.7.0 Databases: RefSeq and Taxonomy snapshot provided by CAMI2 (2019-01-08) 25 simulated prokaryotic communities from Sun et al (prokaryotes) Software, databases and commands details . Softwares: KMCP ( v0.7.0 ) mOTUs 3.0.1 (Jul 28, 2021) MetaPhlAn 3.0.13 (27 Jul, 2021) Kraken v2.1.2 , Bracken v2.6.2 Centrifuge v1.0.4 Databases and taxonomy version: KMCP, GTDB-RS202 (2021-04-27) + Genbank-viral (r246, 2021-12-06) + Refseq-fungi (r208, 2021-09-30), 2021-12-06 Centrifuge, built with the genomes same to KMCP. mOTUs, 3.0.1 (2021-06-28), 2019-01 MetaPhlAn, mpa_v30_CHOCOPhlAn_201901 (?), 2019-01 Kraken, PlusPF (2021-05-17), 2021-05-17 In this benchmark, we generate metagenomic profiles with the same NCBI Taxonomy version 2021-12-06, including the gold-standard profiles. Where KMCP* does not search against viral database. 16 mock virome communities from Roux et al (viruses/phages) Software, databases and commands details . Softwares: KMCP v0.7.0 MetaPhlAn 3.0.13 (27 Jul, 2021) Kraken v2.1.2 , Bracken v2.6.2 Centrifuge v1.0.4 Databases and taxonomy version: KMCP, GTDB-RS202 (2021-04-27) + Genbank-viral (r246, 2021-12-06) + Refseq-fungi (r208, 2021-09-30), 2021-12-06 Centrifuge, built with the genomes same to KMCP. MetaPhlAn, mpa_v30_CHOCOPhlAn_201901 (?), 2019-01 Kraken, PlusPF (2021-05-17), 2021-05-17 In this benchmark, we generate metagenomic profiles with the same NCBI Taxonomy version 2021-12-06, including the gold-standard profiles. Rankings 87 metagenomic samples of infected body fluids (bacteria pathogens, low coverage) Software, databases and commands details . Softwares: KMCP v0.7.0 MetaPhlAn 3.0.13 (27 Jul, 2021) Kraken v2.1.2 , Bracken v2.6.2 Centrifuge v1.0.4 Databases and taxonomy version: KMCP, GTDB-RS202 (2021-04-27) + Genbank-viral (r246, 2021-12-06) + Refseq-fungi (r208, 2021-09-30), 2021-12-06 Centrifuge, built with the genomes same to KMCP. MetaPhlAn, mpa_v30_CHOCOPhlAn_201901 (?), 2019-01 Kraken, PlusPF (2021-05-17), 2021-05-17 In this benchmark, we generate metagenomic profiles with the same NCBI Taxonomy version 2021-12-06, including the gold-standard profiles. sensitivity specificity KMCP 81.43% 100.00% Kraken2+Bracken2 80.00% 81.82% Kraken2+Braken2 (KMCP) 87.14% 100.00% Centrifuge (KMCP) 87.14% 72.73% Analysis time and storage requirement Database size (GB) Building time Building memory (GB) KMCP 66 21 m 14 Kraken2 300 5 h 23 m 255 Bracken2 4 4 h 45 m 258 Centrifuge 97 44 h 35m 522 MetaPhlAn3 3 / / mOTUs3 8 / /","title":"Taxonomic profiling"},{"location":"benchmark/profiling/#benchmark","text":"","title":"Benchmark"},{"location":"benchmark/profiling/#64-simulated-mouse-gut-short-read-datasets-from-cami2-challenge-prokaryotes","text":"Software, databases and commands details . Softwares: mOTUs 2.5.1 MetaPHlAn 2.9.21 Bracken 2.5 KMCP v0.7.0 Databases: RefSeq and Taxonomy snapshot provided by CAMI2 (2019-01-08)","title":"64 simulated mouse gut short-read datasets from CAMI2 challenge (prokaryotes)"},{"location":"benchmark/profiling/#25-simulated-prokaryotic-communities-from-sun-et-al-prokaryotes","text":"Software, databases and commands details . Softwares: KMCP ( v0.7.0 ) mOTUs 3.0.1 (Jul 28, 2021) MetaPhlAn 3.0.13 (27 Jul, 2021) Kraken v2.1.2 , Bracken v2.6.2 Centrifuge v1.0.4 Databases and taxonomy version: KMCP, GTDB-RS202 (2021-04-27) + Genbank-viral (r246, 2021-12-06) + Refseq-fungi (r208, 2021-09-30), 2021-12-06 Centrifuge, built with the genomes same to KMCP. mOTUs, 3.0.1 (2021-06-28), 2019-01 MetaPhlAn, mpa_v30_CHOCOPhlAn_201901 (?), 2019-01 Kraken, PlusPF (2021-05-17), 2021-05-17 In this benchmark, we generate metagenomic profiles with the same NCBI Taxonomy version 2021-12-06, including the gold-standard profiles. Where KMCP* does not search against viral database.","title":"25 simulated prokaryotic communities from Sun et al (prokaryotes)"},{"location":"benchmark/profiling/#16-mock-virome-communities-from-roux-et-al-virusesphages","text":"Software, databases and commands details . Softwares: KMCP v0.7.0 MetaPhlAn 3.0.13 (27 Jul, 2021) Kraken v2.1.2 , Bracken v2.6.2 Centrifuge v1.0.4 Databases and taxonomy version: KMCP, GTDB-RS202 (2021-04-27) + Genbank-viral (r246, 2021-12-06) + Refseq-fungi (r208, 2021-09-30), 2021-12-06 Centrifuge, built with the genomes same to KMCP. MetaPhlAn, mpa_v30_CHOCOPhlAn_201901 (?), 2019-01 Kraken, PlusPF (2021-05-17), 2021-05-17 In this benchmark, we generate metagenomic profiles with the same NCBI Taxonomy version 2021-12-06, including the gold-standard profiles. Rankings","title":"16 mock virome communities from Roux et al (viruses/phages)"},{"location":"benchmark/profiling/#87-metagenomic-samples-of-infected-body-fluids-bacteria-pathogens-low-coverage","text":"Software, databases and commands details . Softwares: KMCP v0.7.0 MetaPhlAn 3.0.13 (27 Jul, 2021) Kraken v2.1.2 , Bracken v2.6.2 Centrifuge v1.0.4 Databases and taxonomy version: KMCP, GTDB-RS202 (2021-04-27) + Genbank-viral (r246, 2021-12-06) + Refseq-fungi (r208, 2021-09-30), 2021-12-06 Centrifuge, built with the genomes same to KMCP. MetaPhlAn, mpa_v30_CHOCOPhlAn_201901 (?), 2019-01 Kraken, PlusPF (2021-05-17), 2021-05-17 In this benchmark, we generate metagenomic profiles with the same NCBI Taxonomy version 2021-12-06, including the gold-standard profiles. sensitivity specificity KMCP 81.43% 100.00% Kraken2+Bracken2 80.00% 81.82% Kraken2+Braken2 (KMCP) 87.14% 100.00% Centrifuge (KMCP) 87.14% 72.73%","title":"87 metagenomic samples of infected body fluids (bacteria pathogens, low coverage)"},{"location":"benchmark/profiling/#analysis-time-and-storage-requirement","text":"Database size (GB) Building time Building memory (GB) KMCP 66 21 m 14 Kraken2 300 5 h 23 m 255 Bracken2 4 4 h 45 m 258 Centrifuge 97 44 h 35m 522 MetaPhlAn3 3 / / mOTUs3 8 / /","title":"Analysis time and storage requirement"},{"location":"benchmark/searching/","text":"Searching benchmarks Software, datasets and commands details . Softwares COBS ( 1915fc0 ) Sourmash (v4.2.2) KMCP ( v0.7.0 ) GTDB r202 representative genomes are used for tests: file size: 46.26 GB files: 47,894 bases: 151.94 Gb KMCP vs COBS All k-mers are indexed and searched. Database size and building time: cobs kmcp database size 86.96GB 55.15GB building time 29m:55s 24min52s temporary files 160.76GB 1.19TB Searching with bacterial genomes or short reads (~1M reads). KMCP vs Mash and Sourmash Only FracMinHash (Scaled MinHash) (scale=1000 for Sourmash and KMCP) or MinHash (scale=3400 for Mash) are indexed and searched. Database size and building time: mash sourmash kmcp database size 743MB 5.19GB 1.52GB building time 11m39s 89m59s 7min02s temporary files - - 3.41GB Searching with bacterial genomes. Result","title":"Sequence and genome searching"},{"location":"benchmark/searching/#searching-benchmarks","text":"Software, datasets and commands details . Softwares COBS ( 1915fc0 ) Sourmash (v4.2.2) KMCP ( v0.7.0 ) GTDB r202 representative genomes are used for tests: file size: 46.26 GB files: 47,894 bases: 151.94 Gb","title":"Searching benchmarks"},{"location":"benchmark/searching/#kmcp-vs-cobs","text":"All k-mers are indexed and searched. Database size and building time: cobs kmcp database size 86.96GB 55.15GB building time 29m:55s 24min52s temporary files 160.76GB 1.19TB Searching with bacterial genomes or short reads (~1M reads).","title":"KMCP vs COBS"},{"location":"benchmark/searching/#kmcp-vs-mash-and-sourmash","text":"Only FracMinHash (Scaled MinHash) (scale=1000 for Sourmash and KMCP) or MinHash (scale=3400 for Mash) are indexed and searched. Database size and building time: mash sourmash kmcp database size 743MB 5.19GB 1.52GB building time 11m39s 89m59s 7min02s temporary files - - 3.41GB Searching with bacterial genomes.","title":"KMCP vs Mash and Sourmash"},{"location":"benchmark/searching/#result","text":"","title":"Result"},{"location":"tutorial/","text":"Tutorials Taxonomic profiling Sequence and genome searching","title":"Tutorials"},{"location":"tutorial/#tutorials","text":"Taxonomic profiling Sequence and genome searching","title":"Tutorials"},{"location":"tutorial/profiling/","text":"Metagenomic profiling Requirements Database Prebuilt databases are available. Or build custom databases . Hardware. CPU: \u2265 32 cores preferred. RAM: \u2265 64 GB, depends on file size of the maximal database. Datasets Short reads, single or paired end. Long reads (PacBio HIFI). Steps Step 1. Preprocessing reads For example, removing adapters and trimming using fastp : fastp -i in_1.fq.gz -I in_2.fq.gz \\ -o out_1.fq.gz -O out_2.fq.gz \\ -l 75 -q 20 -W 4 -M 20 -3 20 --thread 32 \\ --html out.fastp.html Step 2. Removing host reads Tools: bowtie2 is recommended for removing host reads. samtools is also used for processing reads mapping file. pigz is a parallel implementation of gzip , which is much faster than gzip . Host reference genomes: Human: CHM13 . We also provide a database of CHM13 for fast removing human reads. Building the index (~60min): bowtie2-build --threads 32 GCA_009914755.3_CHM13_T2T_v1.1_genomic.fna.gz chm13 Mapping and removing mapped reads: index=~/ws/db/bowtie2/chm13 bowtie2 --threads 32 -x $index -1 in_1.fq.gz -2 in_2.fq.gz \\ | samtools view -buS -f 4 - \\ | samtools fastq - \\ | gzip -c > sample.fq.gz Step 3. Searching Reads can be searched against multiple databases which can be built with different parameters , and the results can be fastly merged for downstream analysis. Attentions Input format should be (gzipped) FASTA or FASTQ from files or stdin. Paired-End reads should be given via -1/--read1 and -2/--read2 . kmcp search -d db -1 read_1.fq.gz -2 read_2.fq.gz -o read.tsv.gz Single-end can be given as positional arguments or -1 / -2 . kmcp search -d db file1.fq.gz file2.fq.gz -o result.tsv.gz Single-end mode is recommended for pair-end reads, for higher sensitivity . See benchmark . A long query sequences may contain duplicated k-mers, which are not removed for short sequences by default. You may modify the value of -u/--kmer-dedup-threshold (default 256 ) to remove duplicates. For long reads or contigs, you should split them into short reads using seqkit sliding , e.g., seqkit sliding -s 100 -W 300 The values of tCov and jacc in results only apply for single size of k-mer. kmcp search and kmcp profile share some flags , therefore users can use stricter criteria in kmcp profile . -t/--min-query-cov , minimal query coverage, i.e., proportion of matched k-mers and unique k-mers of a query (default 0.55 , close to ~96.5% sequence similarity)) -N/--name-map , tabular two-column file(s) mapping names to user-defined values. Index files loading modes : Using memory-mapped index files with mmap (default) Faster startup speed when index files are buffered in memory. Multiple KMCP processes can share the memory. Loading the whole index files into memory ( -w/--load-whole-db ): This mode occupies a little more memory. And Multiple KMCP processes can not share the database in memory. It's slightly faster due to the use of physically contiguous memory. The speedup is more significant for smaller databases . It's highly recommended when searching on computer clusters , where the default mmap mode would be very slow (in my test). Low memory mode ( --low-mem ): Do not load all index files into memory nor use mmap, using file seeking. It's much slower, >4X slower on SSD and would be much slower on HDD disks. Only use this mode for small number of queries or a huge database that can't be loaded into memory . Performance tips : Increase value of -j/--threads for acceleratation, but values larger than the number of CPU cores won't bring extra speedup. Commands Single-end mode is recommended for pair-end reads, for higher sensitivity: # --------------------------------------------------- # single-end (recommended) read1=sample_1.fq.gz read2=sample_2.fq.gz sample=sample for db in refseq-fungi.kmcp genbank-viral.kmcp gtdb.kmcp ; do dbname=$(basename $db) kmcp search \\ --threads 32 \\ --db-dir $db \\ --min-kmers 30 \\ --min-query-len 70 \\ --min-query-cov 0.55 \\ $read1 $read2 \\ --out-file $sample.kmcp@$dbname.tsv.gz \\ --log $sample.kmcp@$dbname.tsv.gz.log done Pair-end reads: # --------------------------------------------------- # paired-end read1=sample_1.fq.gz read2=sample_2.fq.gz sample=sample for db in refseq-fungi.kmcp genbank-viral.kmcp gtdb.kmcp ; do dbname=$(basename $db) kmcp search \\ --threads 32 \\ --db-dir $db \\ --min-kmers 30 \\ --min-query-len 70 \\ --min-query-cov 0.55 \\ --read1 $read1 \\ --read2 $read2 \\ --out-file $sample.kmcp@$dbname.tsv.gz \\ --log $sample.kmcp@$dbname.tsv.gz.log done Merging searching results on multiple database: kmcp merge $sample.kmcp@*.tsv.gz --out-file $sample.kmcp.tsv.gz Searching on a computer cluster Here, we divided genomes of GTDB into 16 parts and build a database for every part, so we can use computer cluster to accelerate the searching. The genbank-viral genomes are also diveded into 4 parts. A helper script easy_sbatch is used for batch submitting Slurm jobs via script templates. # --------------------------------------------------- # searching j=32 reads=reads # ----------------- # gtdb dbprefix=~/ws/db/kmcp/gtdb.n16- for file in $reads/*.left.fq.gz; do prefix=$(echo $file | sed 's/.left.fq.gz//') read1=$file read2=$(echo $file | sed 's/left.fq.gz/right.fq.gz/') ls -d $dbprefix*.kmcp \\ | easy_sbatch \\ -c $j -J $(basename $prefix) \\ \"kmcp search \\ --load-whole-db \\ --threads $j \\ --db-dir {} \\ $read1 $read2 \\ --out-file $prefix.kmcp@\\$(basename {}).tsv.gz \\ --log $prefix.kmcp@\\$(basename {}).tsv.gz.log \\ --quiet \" done # ----------------- # viral dbprefix=~/ws/db/kmcp/genbank-viral.n4- for file in $reads/*.left.fq.gz; do prefix=$(echo $file | sed 's/.left.fq.gz//') read1=$file read2=$(echo $file | sed 's/left.fq.gz/right.fq.gz/') ls -d $dbprefix*.kmcp \\ | easy_sbatch \\ -c $j -J $(basename $prefix) \\ \"kmcp search \\ --load-whole-db \\ --threads $j \\ --db-dir {} \\ $read1 $read2 \\ --out-file $prefix.kmcp@\\$(basename {}).tsv.gz \\ --log $prefix.kmcp@\\$(basename {}).tsv.gz.log \\ --quiet \" done # ----------------- # fungi dbprefix=~/ws/db/kmcp/refseq-fungi for file in $reads/*.left.fq.gz; do prefix=$(echo $file | sed 's/.left.fq.gz//') read1=$file read2=$(echo $file | sed 's/left.fq.gz/right.fq.gz/') ls -d $dbprefix*.kmcp \\ | easy_sbatch \\ -c $j -J $(basename $prefix) \\ \"kmcp search \\ --load-whole-db \\ --threads $j \\ --db-dir {} \\ $read1 $read2 \\ --out-file $prefix.kmcp@\\$(basename {}).tsv.gz \\ --log $prefix.kmcp@\\$(basename {}).tsv.gz.log \\ --quiet \" done # --------------------------------------------------- # wait all job being done # --------------------------------------------------- # merge result and profiling # merge results # there's no need to submit to slurm, which could make it slower, cause the bottleneck is file IO for file in $reads/*.left.fq.gz; do prefix=$(echo $file | sed 's/.left.fq.gz//') echo $prefix; date kmcp merge $prefix.kmcp@*.tsv.gz --out-file $prefix.kmcp.tsv.gz \\ --quiet --log $prefix.kmcp.tsv.gz.merge.log done # profiling X=taxdump/ T=taxid.map fd kmcp.tsv.gz$ $reads/ \\ | rush -v X=$X -v T=$T \\ 'kmcp profile -X {X} -T {T} {} -o {}.k.profile -C {}.c.profile -s {%:} \\ --log {}.k.profile.log' Searching result format 1. query, Identifier of query sequence 2. qLen, Query length 3. qKmers, K-mer number of query sequence 4. FPR, False positive rate 5. hits, Number of matches 6. target, Identifier of target sequence 7. fragIdx, Index of reference fragment 8. frags, Number of reference fragments 9. tLen, Reference length 10. kSize, K-mer size 11. mKmers, Number of matched k-mers 12. qCov, Query coverage, equals to: mKmers / qKmers 13. tCov, Target coverage, equals to: mKmers / K-mer number of reference fragment 14. jacc, Jaccard index 15. queryIdx, Index of query sequence, only for merging Note: The header line starts with # , you need to assign another comment charactor if using csvtk for analysis. e.g., csvtk filter2 -C '$' -t -f '$qCov > 0.7' mock.fastq.gz.kmcp.gz Demo result: #query qLen qKmers FPR hits target fragIdx frags tLen kSize mKmers qCov tCov jacc queryIdx NC_000913.3_sliding:1244941-1245090 150 120 2.1127e-08 6 NC_012971.2 2 10 4558953 31 120 1.0000 0.0003 0.0003 0 NC_000913.3_sliding:1244941-1245090 150 120 2.1127e-08 6 NC_000913.3 2 10 4641652 31 120 1.0000 0.0003 0.0003 0 NC_000913.3_sliding:1244941-1245090 150 120 2.1127e-08 6 NC_018658.1 5 10 5273097 31 120 1.0000 0.0002 0.0002 0 NC_000913.3_sliding:1244941-1245090 150 120 2.1127e-08 6 NZ_CP028116.1 2 10 5648177 31 79 0.6583 0.0002 0.0002 0 NC_000913.3_sliding:1244941-1245090 150 120 2.1127e-08 6 NZ_CP007592.1 3 10 5104557 31 69 0.5750 0.0001 0.0001 0 NC_000913.3_sliding:1244941-1245090 150 120 2.1127e-08 6 NC_002695.2 3 10 5498578 31 69 0.5750 0.0001 0.0001 0 NC_013654.1_sliding:344871-345020 150 120 2.1127e-08 8 NC_012971.2 0 10 4558953 31 120 1.0000 0.0003 0.0003 1 NC_013654.1_sliding:344871-345020 150 120 2.1127e-08 8 NC_000913.3 0 10 4641652 31 120 1.0000 0.0003 0.0003 1 NC_013654.1_sliding:344871-345020 150 120 2.1127e-08 8 NC_013654.1 0 10 4717338 31 120 1.0000 0.0003 0.0003 1 Step 4. Profiling Input TaxId mapping file(s). Taxdump files. KMCP search results. Methods Reference genomes can be splitted into fragments when computing k-mers (sketches), which could help to increase the specificity via a threshold, i.e., the minimal proportion of matched fragments ( -p/--min-frags-fraction ). ( highly recommended ) Another flag -d/--max-frags-cov-stdev further reduces false positives. We require part of the uniquely matched reads of a reference having high similarity, i.e., with high confidence for decreasing the false positive rate. We also use the two-stage taxonomy assignment algorithm in MegaPath to reduce the false positive of ambiguous matches. Multi-aligned queries are proportionally assigned to references with a similar strategy in Metalign . Input files are parsed 4 times, therefore STDIN is not supported. Three-rounds profiling: Accuracy notes : Smaller -t/--min-qcov increase sensitivity in cost of higher false positive rate ( -f/--max-fpr ) of a query. And we require part of the uniquely matched reads of a reference having high similarity, i.e., with high confidence to decrease the false positive. E.g., -H >= 0.8 and -P >= 0.1 equals to 90th percentile >= 0.8 -U/--min-hic-ureads , minimal number, >= 1 -H/--min-hic-ureads-qcov , minimal query coverage, >= -t/--min-qcov -P/--min-hic-ureads-prop , minimal proportion, higher values increase precision in cost of sensitivity. -R/--max-mismatch-err and -D/--min-dreads-prop is for determing the right reference for ambigous reads. --keep-perfect-match is not recommended, which decreases sensitivity. -n/--keep-top-qcovs is not recommended, which affects accuracy of abundance estimation. Profiling modes We preset six profiling modes, availabe with the flag -m/--mode . 0 (for pathogen detection) 1 (higher recall) 2 (high recall) 3 (default) 4 (high precision) 5 (higher precision) Using this flag will override the relevant options. options m=0 m=1 m=2 m=3 m=4 m=5 -------------------------- ---- --- --- ---- --- ---- -r/--min-frags-reads 1 20 30 50 100 100 -p/--min-frags-fraction 0.2 0.5 0.7 0.8 1 1 -d/--max-frags-depth-stdev 10 10 3 2 2 1.5 -u/--min-uniq-reads 1 20 20 20 50 50 -U/--min-hic-ureads 1 5 5 5 10 10 -H/--min-hic-ureads-qcov 0.55 0.7 0.7 0.75 0.8 0.8 -P/--min-hic-ureads-prop 0.01 0.1 0.2 0.1 0.1 0.15 Taxonomy data : Mapping references IDs to TaxIds: -T/--taxid-map NCBI taxonomy dump files: -X/--taxdump Performance notes : Searching results are parsed in parallel, and the number of lines proceeded by a thread can be set by the flag --chunk-size . However using a lot of threads does not always accelerate processing, 4 threads with chunk size of 500-5000 is fast enough. Commands # taxid mapping files, multiple files supported. taxid_map=gtdb.kmcp/taxid.map,refseq-viral.kmcp/taxid.map,refseq-fungi.kmcp # taxdump directory taxdump=taxdump/ sfile=$file.kmcp.tsv.gz kmcp profile \\ --taxid-map $taxid_map \\ --taxdump $taxdump \\ --level species \\ --min-query-cov 0.55 \\ --min-frags-reads 50 \\ --min-frags-fraction 0.8 \\ --max-frags-depth-stdev 2 \\ --min-uniq-reads 10 \\ --min-hic-ureads 1 \\ --min-hic-ureads-qcov 0.75 \\ --min-hic-ureads-prop 0.1 \\ $sfile \\ --out-prefix $sfile.kmcp.profile \\ --metaphlan-report $sfile.metaphlan.profile \\ --cami-report $sfile.cami.profile \\ --sample-id \"0\" \\ --binning-result $sfile.binning.gz Profiling result formats Supported profiling output formats : KMCP ( -o/--out-prefix ) CAMI ( -M/--metaphlan-report , sample name: -s/--sample-id ) MetaPhlAn ( -C/--cami-report , sample name: -s/--sample-id )) Supported taxonomic binning formats : CAMI ( -B/--binning-result ) KMCP format: 1. ref, Identifier of the reference genome 2. percentage, Relative abundance of a reference 3. score, The 90th percentile of qCov of uniquely matched reads 4. fragsFrac, Genome fragments fraction 5. fragsRelDepth, Relative depths of reference fragments 6. fragsRelDepthStd, The strandard deviation of fragsRelDepth 7. reads, Total number of matched reads of this reference 8. ureads, Number of uniquely matched reads 9. hicureads, Number of uniquely matched reads with high-confidence 10. refsize, Reference size 11. refname, Reference name, optional via name mapping file 12. taxid, TaxId of the reference 13. rank, Taxonomic rank 14. taxname, Taxonomic name 15. taxpath, Complete lineage 16. taxpathsn, Corresponding TaxIds of taxons in the complete lineage Demo output: ref percentage score fragsFrac fragsRelDepth fragsRelDepthStd reads ureads hicureads refsize refname taxid rank taxname taxpath taxpathsn NC_013654.1 48.321535 100.00 1.00 0.99;1.00;0.99;1.00;0.99;0.99;0.99;0.98;1.05;1.02 0.02 287936 226225 226225 4717338 431946 strain Escherichia coli SE15 Bacteria;Proteobacteria;Gammaproteobacteria;Enterobacterales;Enterobacteriaceae;Escherichia;Escherichia coli;Escherichia coli SE15 2;1224;1236;91347;543;561;562;431946 NC_000913.3 46.194629 100.00 1.00 1.04;0.99;1.00;1.00;0.99;0.99;0.99;0.97;1.04;0.98 0.02 270846 175686 175686 4641652 511145 no rank Escherichia coli str. K-12 substr. MG1655 Bacteria;Proteobacteria;Gammaproteobacteria;Enterobacterales;Enterobacteriaceae;Escherichia;Escherichia coli;Escherichia coli K-12 2;1224;1236;91347;543;561;562;83333 NC_002695.2 5.014025 100.00 1.00 0.97;0.98;0.92;1.12;1.01;0.95;1.00;1.01;1.03;1.00 0.05 34825 22945 22945 5498578 386585 strain Escherichia coli O157:H7 str. Sakai Bacteria;Proteobacteria;Gammaproteobacteria;Enterobacterales;Enterobacteriaceae;Escherichia;Escherichia coli;Escherichia coli O157:H7 str. Sakai 2;1224;1236;91347;543;561;562;386585 NC_010655.1 0.469811 100.00 1.00 1.03;0.87;0.90;0.98;1.15;1.17;0.90;0.96;0.96;1.09 0.10 1581 1581 1581 2664102 349741 strain Akkermansia muciniphila ATCC BAA-835 Bacteria;Verrucomicrobia;Verrucomicrobiae;Verrucomicrobiales;Akkermansiaceae;Akkermansia;Akkermansia muciniphila;Akkermansia muciniphila ATCC BAA-835 2;74201;203494;48461;1647988;239934;239935;349741 CAMI format : @SampleID: @Version:0.10.0 @Ranks:superkingdom|phylum|class|order|family|genus|species|strain @TaxonomyID:ncbi-taxonomy @@TAXID RANK TAXPATH TAXPATHSN PERCENTAGE 2 superkingdom 2 Bacteria 100.000000 1224 phylum 2|1224 Bacteria|Proteobacteria 99.530189 74201 phylum 2|74201 Bacteria|Verrucomicrobia 0.469811 1236 class 2|1224|1236 Bacteria|Proteobacteria|Gammaproteobacteria 99.530189 203494 class 2|74201|203494 Bacteria|Verrucomicrobia|Verrucomicrobiae 0.469811 91347 order 2|1224|1236|91347 Bacteria|Proteobacteria|Gammaproteobacteria|Enterobacterales 99.530189 48461 order 2|74201|203494|48461 Bacteria|Verrucomicrobia|Verrucomicrobiae|Verrucomicrobiales 0.469811 543 family 2|1224|1236|91347|543 Bacteria|Proteobacteria|Gammaproteobacteria|Enterobacterales|Enterobacteriaceae 99.530189 1647988 family 2|74201|203494|48461|1647988 Bacteria|Verrucomicrobia|Verrucomicrobiae|Verrucomicrobiales|Akkermansiaceae 0.469811 561 genus 2|1224|1236|91347|543|561 Bacteria|Proteobacteria|Gammaproteobacteria|Enterobacterales|Enterobacteriaceae|Escherichia 99.530189 239934 genus 2|74201|203494|48461|1647988|239934 Bacteria|Verrucomicrobia|Verrucomicrobiae|Verrucomicrobiales|Akkermansiaceae|Akkermansia 0.469811 562 species 2|1224|1236|91347|543|561|562 Bacteria|Proteobacteria|Gammaproteobacteria|Enterobacterales|Enterobacteriaceae|Escherichia|Escherichia coli 99.530189 239935 species 2|74201|203494|48461|1647988|239934|239935 Bacteria|Verrucomicrobia|Verrucomicrobiae|Verrucomicrobiales|Akkermansiaceae|Akkermansia|Akkermansia muciniphila 0.469811 431946 strain 2|1224|1236|91347|543|561|562|431946 Bacteria|Proteobacteria|Gammaproteobacteria|Enterobacterales|Enterobacteriaceae|Escherichia|Escherichia coli|Escherichia coli SE15 48.321535 83333 strain 2|1224|1236|91347|543|561|562|83333 Bacteria|Proteobacteria|Gammaproteobacteria|Enterobacterales|Enterobacteriaceae|Escherichia|Escherichia coli|Escherichia coli K-12 46.194629 386585 strain 2|1224|1236|91347|543|561|562|386585 Bacteria|Proteobacteria|Gammaproteobacteria|Enterobacterales|Enterobacteriaceae|Escherichia|Escherichia coli|Escherichia coli O157:H7 str. Sakai 5.014025 349741 strain 2|74201|203494|48461|1647988|239934|239935|349741 Bacteria|Verrucomicrobia|Verrucomicrobiae|Verrucomicrobiales|Akkermansiaceae|Akkermansia|Akkermansia muciniphila|Akkermansia muciniphila ATCC BAA-835 0.469811 taxonkit profile2cami can also converts any metagenomic profile table with TaxIds to CAMI format. Metaphlan format: #SampleID k__Bacteria 100.000000 k__Bacteria|p__Proteobacteria 99.530189 k__Bacteria|p__Verrucomicrobia 0.469811 k__Bacteria|p__Proteobacteria|c__Gammaproteobacteria 99.530189 k__Bacteria|p__Verrucomicrobia|c__Verrucomicrobiae 0.469811 k__Bacteria|p__Proteobacteria|c__Gammaproteobacteria|o__Enterobacterales 99.530189 k__Bacteria|p__Verrucomicrobia|c__Verrucomicrobiae|o__Verrucomicrobiales 0.469811 k__Bacteria|p__Proteobacteria|c__Gammaproteobacteria|o__Enterobacterales|f__Enterobacteriaceae 99.530189 k__Bacteria|p__Verrucomicrobia|c__Verrucomicrobiae|o__Verrucomicrobiales|f__Akkermansiaceae 0.469811 k__Bacteria|p__Proteobacteria|c__Gammaproteobacteria|o__Enterobacterales|f__Enterobacteriaceae|g__Escherichia 99.530189 k__Bacteria|p__Verrucomicrobia|c__Verrucomicrobiae|o__Verrucomicrobiales|f__Akkermansiaceae|g__Akkermansia 0.469811 k__Bacteria|p__Proteobacteria|c__Gammaproteobacteria|o__Enterobacterales|f__Enterobacteriaceae|g__Escherichia|s__Escherichia coli 99.530189 k__Bacteria|p__Verrucomicrobia|c__Verrucomicrobiae|o__Verrucomicrobiales|f__Akkermansiaceae|g__Akkermansia|s__Akkermansia muciniphila 0.469811 k__Bacteria|p__Proteobacteria|c__Gammaproteobacteria|o__Enterobacterales|f__Enterobacteriaceae|g__Escherichia|s__Escherichia coli|t__Escherichia coli SE15 48.321535 k__Bacteria|p__Proteobacteria|c__Gammaproteobacteria|o__Enterobacterales|f__Enterobacteriaceae|g__Escherichia|s__Escherichia coli|t__Escherichia coli K-12 46.194629 k__Bacteria|p__Proteobacteria|c__Gammaproteobacteria|o__Enterobacterales|f__Enterobacteriaceae|g__Escherichia|s__Escherichia coli|t__Escherichia coli O157:H7 str. Sakai 5.014025 k__Bacteria|p__Verrucomicrobia|c__Verrucomicrobiae|o__Verrucomicrobiales|f__Akkermansiaceae|g__Akkermansia|s__Akkermansia muciniphila|t__Akkermansia muciniphila ATCC BAA-835 0.469811 Binning result : # This is the bioboxes.org binning output format at # https://github.com/bioboxes/rfc/tree/master/data-format @Version:0.10.0 @SampleID: @@SEQUENCEID TAXID NC_000913.3_sliding:1244941-1245090 511145 NC_013654.1_sliding:344871-345020 562 NC_000913.3_sliding:3801041-3801190 511145 NC_013654.1_sliding:752751-752900 562 NC_000913.3_sliding:4080871-4081020 562 NC_000913.3_sliding:3588091-3588240 511145 NC_000913.3_sliding:2249621-2249770 562 NC_013654.1_sliding:2080171-2080320 431946 NC_000913.3_sliding:2354841-2354990 511145 NC_013654.1_sliding:437671-437820 431946","title":"Taxonomic profiling"},{"location":"tutorial/profiling/#metagenomic-profiling","text":"","title":"Metagenomic profiling"},{"location":"tutorial/profiling/#requirements","text":"Database Prebuilt databases are available. Or build custom databases . Hardware. CPU: \u2265 32 cores preferred. RAM: \u2265 64 GB, depends on file size of the maximal database.","title":"Requirements"},{"location":"tutorial/profiling/#datasets","text":"Short reads, single or paired end. Long reads (PacBio HIFI).","title":"Datasets"},{"location":"tutorial/profiling/#steps","text":"","title":"Steps"},{"location":"tutorial/profiling/#step-1-preprocessing-reads","text":"For example, removing adapters and trimming using fastp : fastp -i in_1.fq.gz -I in_2.fq.gz \\ -o out_1.fq.gz -O out_2.fq.gz \\ -l 75 -q 20 -W 4 -M 20 -3 20 --thread 32 \\ --html out.fastp.html","title":"Step 1. Preprocessing reads"},{"location":"tutorial/profiling/#step-2-removing-host-reads","text":"Tools: bowtie2 is recommended for removing host reads. samtools is also used for processing reads mapping file. pigz is a parallel implementation of gzip , which is much faster than gzip . Host reference genomes: Human: CHM13 . We also provide a database of CHM13 for fast removing human reads. Building the index (~60min): bowtie2-build --threads 32 GCA_009914755.3_CHM13_T2T_v1.1_genomic.fna.gz chm13 Mapping and removing mapped reads: index=~/ws/db/bowtie2/chm13 bowtie2 --threads 32 -x $index -1 in_1.fq.gz -2 in_2.fq.gz \\ | samtools view -buS -f 4 - \\ | samtools fastq - \\ | gzip -c > sample.fq.gz","title":"Step 2. Removing host reads"},{"location":"tutorial/profiling/#step-3-searching","text":"Reads can be searched against multiple databases which can be built with different parameters , and the results can be fastly merged for downstream analysis.","title":"Step 3. Searching"},{"location":"tutorial/profiling/#attentions","text":"Input format should be (gzipped) FASTA or FASTQ from files or stdin. Paired-End reads should be given via -1/--read1 and -2/--read2 . kmcp search -d db -1 read_1.fq.gz -2 read_2.fq.gz -o read.tsv.gz Single-end can be given as positional arguments or -1 / -2 . kmcp search -d db file1.fq.gz file2.fq.gz -o result.tsv.gz Single-end mode is recommended for pair-end reads, for higher sensitivity . See benchmark . A long query sequences may contain duplicated k-mers, which are not removed for short sequences by default. You may modify the value of -u/--kmer-dedup-threshold (default 256 ) to remove duplicates. For long reads or contigs, you should split them into short reads using seqkit sliding , e.g., seqkit sliding -s 100 -W 300 The values of tCov and jacc in results only apply for single size of k-mer. kmcp search and kmcp profile share some flags , therefore users can use stricter criteria in kmcp profile . -t/--min-query-cov , minimal query coverage, i.e., proportion of matched k-mers and unique k-mers of a query (default 0.55 , close to ~96.5% sequence similarity)) -N/--name-map , tabular two-column file(s) mapping names to user-defined values. Index files loading modes : Using memory-mapped index files with mmap (default) Faster startup speed when index files are buffered in memory. Multiple KMCP processes can share the memory. Loading the whole index files into memory ( -w/--load-whole-db ): This mode occupies a little more memory. And Multiple KMCP processes can not share the database in memory. It's slightly faster due to the use of physically contiguous memory. The speedup is more significant for smaller databases . It's highly recommended when searching on computer clusters , where the default mmap mode would be very slow (in my test). Low memory mode ( --low-mem ): Do not load all index files into memory nor use mmap, using file seeking. It's much slower, >4X slower on SSD and would be much slower on HDD disks. Only use this mode for small number of queries or a huge database that can't be loaded into memory . Performance tips : Increase value of -j/--threads for acceleratation, but values larger than the number of CPU cores won't bring extra speedup.","title":"Attentions"},{"location":"tutorial/profiling/#commands","text":"Single-end mode is recommended for pair-end reads, for higher sensitivity: # --------------------------------------------------- # single-end (recommended) read1=sample_1.fq.gz read2=sample_2.fq.gz sample=sample for db in refseq-fungi.kmcp genbank-viral.kmcp gtdb.kmcp ; do dbname=$(basename $db) kmcp search \\ --threads 32 \\ --db-dir $db \\ --min-kmers 30 \\ --min-query-len 70 \\ --min-query-cov 0.55 \\ $read1 $read2 \\ --out-file $sample.kmcp@$dbname.tsv.gz \\ --log $sample.kmcp@$dbname.tsv.gz.log done Pair-end reads: # --------------------------------------------------- # paired-end read1=sample_1.fq.gz read2=sample_2.fq.gz sample=sample for db in refseq-fungi.kmcp genbank-viral.kmcp gtdb.kmcp ; do dbname=$(basename $db) kmcp search \\ --threads 32 \\ --db-dir $db \\ --min-kmers 30 \\ --min-query-len 70 \\ --min-query-cov 0.55 \\ --read1 $read1 \\ --read2 $read2 \\ --out-file $sample.kmcp@$dbname.tsv.gz \\ --log $sample.kmcp@$dbname.tsv.gz.log done Merging searching results on multiple database: kmcp merge $sample.kmcp@*.tsv.gz --out-file $sample.kmcp.tsv.gz","title":"Commands"},{"location":"tutorial/profiling/#searching-on-a-computer-cluster","text":"Here, we divided genomes of GTDB into 16 parts and build a database for every part, so we can use computer cluster to accelerate the searching. The genbank-viral genomes are also diveded into 4 parts. A helper script easy_sbatch is used for batch submitting Slurm jobs via script templates. # --------------------------------------------------- # searching j=32 reads=reads # ----------------- # gtdb dbprefix=~/ws/db/kmcp/gtdb.n16- for file in $reads/*.left.fq.gz; do prefix=$(echo $file | sed 's/.left.fq.gz//') read1=$file read2=$(echo $file | sed 's/left.fq.gz/right.fq.gz/') ls -d $dbprefix*.kmcp \\ | easy_sbatch \\ -c $j -J $(basename $prefix) \\ \"kmcp search \\ --load-whole-db \\ --threads $j \\ --db-dir {} \\ $read1 $read2 \\ --out-file $prefix.kmcp@\\$(basename {}).tsv.gz \\ --log $prefix.kmcp@\\$(basename {}).tsv.gz.log \\ --quiet \" done # ----------------- # viral dbprefix=~/ws/db/kmcp/genbank-viral.n4- for file in $reads/*.left.fq.gz; do prefix=$(echo $file | sed 's/.left.fq.gz//') read1=$file read2=$(echo $file | sed 's/left.fq.gz/right.fq.gz/') ls -d $dbprefix*.kmcp \\ | easy_sbatch \\ -c $j -J $(basename $prefix) \\ \"kmcp search \\ --load-whole-db \\ --threads $j \\ --db-dir {} \\ $read1 $read2 \\ --out-file $prefix.kmcp@\\$(basename {}).tsv.gz \\ --log $prefix.kmcp@\\$(basename {}).tsv.gz.log \\ --quiet \" done # ----------------- # fungi dbprefix=~/ws/db/kmcp/refseq-fungi for file in $reads/*.left.fq.gz; do prefix=$(echo $file | sed 's/.left.fq.gz//') read1=$file read2=$(echo $file | sed 's/left.fq.gz/right.fq.gz/') ls -d $dbprefix*.kmcp \\ | easy_sbatch \\ -c $j -J $(basename $prefix) \\ \"kmcp search \\ --load-whole-db \\ --threads $j \\ --db-dir {} \\ $read1 $read2 \\ --out-file $prefix.kmcp@\\$(basename {}).tsv.gz \\ --log $prefix.kmcp@\\$(basename {}).tsv.gz.log \\ --quiet \" done # --------------------------------------------------- # wait all job being done # --------------------------------------------------- # merge result and profiling # merge results # there's no need to submit to slurm, which could make it slower, cause the bottleneck is file IO for file in $reads/*.left.fq.gz; do prefix=$(echo $file | sed 's/.left.fq.gz//') echo $prefix; date kmcp merge $prefix.kmcp@*.tsv.gz --out-file $prefix.kmcp.tsv.gz \\ --quiet --log $prefix.kmcp.tsv.gz.merge.log done # profiling X=taxdump/ T=taxid.map fd kmcp.tsv.gz$ $reads/ \\ | rush -v X=$X -v T=$T \\ 'kmcp profile -X {X} -T {T} {} -o {}.k.profile -C {}.c.profile -s {%:} \\ --log {}.k.profile.log'","title":"Searching on a computer cluster"},{"location":"tutorial/profiling/#searching-result-format","text":"1. query, Identifier of query sequence 2. qLen, Query length 3. qKmers, K-mer number of query sequence 4. FPR, False positive rate 5. hits, Number of matches 6. target, Identifier of target sequence 7. fragIdx, Index of reference fragment 8. frags, Number of reference fragments 9. tLen, Reference length 10. kSize, K-mer size 11. mKmers, Number of matched k-mers 12. qCov, Query coverage, equals to: mKmers / qKmers 13. tCov, Target coverage, equals to: mKmers / K-mer number of reference fragment 14. jacc, Jaccard index 15. queryIdx, Index of query sequence, only for merging Note: The header line starts with # , you need to assign another comment charactor if using csvtk for analysis. e.g., csvtk filter2 -C '$' -t -f '$qCov > 0.7' mock.fastq.gz.kmcp.gz Demo result: #query qLen qKmers FPR hits target fragIdx frags tLen kSize mKmers qCov tCov jacc queryIdx NC_000913.3_sliding:1244941-1245090 150 120 2.1127e-08 6 NC_012971.2 2 10 4558953 31 120 1.0000 0.0003 0.0003 0 NC_000913.3_sliding:1244941-1245090 150 120 2.1127e-08 6 NC_000913.3 2 10 4641652 31 120 1.0000 0.0003 0.0003 0 NC_000913.3_sliding:1244941-1245090 150 120 2.1127e-08 6 NC_018658.1 5 10 5273097 31 120 1.0000 0.0002 0.0002 0 NC_000913.3_sliding:1244941-1245090 150 120 2.1127e-08 6 NZ_CP028116.1 2 10 5648177 31 79 0.6583 0.0002 0.0002 0 NC_000913.3_sliding:1244941-1245090 150 120 2.1127e-08 6 NZ_CP007592.1 3 10 5104557 31 69 0.5750 0.0001 0.0001 0 NC_000913.3_sliding:1244941-1245090 150 120 2.1127e-08 6 NC_002695.2 3 10 5498578 31 69 0.5750 0.0001 0.0001 0 NC_013654.1_sliding:344871-345020 150 120 2.1127e-08 8 NC_012971.2 0 10 4558953 31 120 1.0000 0.0003 0.0003 1 NC_013654.1_sliding:344871-345020 150 120 2.1127e-08 8 NC_000913.3 0 10 4641652 31 120 1.0000 0.0003 0.0003 1 NC_013654.1_sliding:344871-345020 150 120 2.1127e-08 8 NC_013654.1 0 10 4717338 31 120 1.0000 0.0003 0.0003 1","title":"Searching result format"},{"location":"tutorial/profiling/#step-4-profiling","text":"","title":"Step 4. Profiling"},{"location":"tutorial/profiling/#input","text":"TaxId mapping file(s). Taxdump files. KMCP search results.","title":"Input"},{"location":"tutorial/profiling/#methods","text":"Reference genomes can be splitted into fragments when computing k-mers (sketches), which could help to increase the specificity via a threshold, i.e., the minimal proportion of matched fragments ( -p/--min-frags-fraction ). ( highly recommended ) Another flag -d/--max-frags-cov-stdev further reduces false positives. We require part of the uniquely matched reads of a reference having high similarity, i.e., with high confidence for decreasing the false positive rate. We also use the two-stage taxonomy assignment algorithm in MegaPath to reduce the false positive of ambiguous matches. Multi-aligned queries are proportionally assigned to references with a similar strategy in Metalign . Input files are parsed 4 times, therefore STDIN is not supported. Three-rounds profiling: Accuracy notes : Smaller -t/--min-qcov increase sensitivity in cost of higher false positive rate ( -f/--max-fpr ) of a query. And we require part of the uniquely matched reads of a reference having high similarity, i.e., with high confidence to decrease the false positive. E.g., -H >= 0.8 and -P >= 0.1 equals to 90th percentile >= 0.8 -U/--min-hic-ureads , minimal number, >= 1 -H/--min-hic-ureads-qcov , minimal query coverage, >= -t/--min-qcov -P/--min-hic-ureads-prop , minimal proportion, higher values increase precision in cost of sensitivity. -R/--max-mismatch-err and -D/--min-dreads-prop is for determing the right reference for ambigous reads. --keep-perfect-match is not recommended, which decreases sensitivity. -n/--keep-top-qcovs is not recommended, which affects accuracy of abundance estimation.","title":"Methods"},{"location":"tutorial/profiling/#profiling-modes","text":"We preset six profiling modes, availabe with the flag -m/--mode . 0 (for pathogen detection) 1 (higher recall) 2 (high recall) 3 (default) 4 (high precision) 5 (higher precision) Using this flag will override the relevant options. options m=0 m=1 m=2 m=3 m=4 m=5 -------------------------- ---- --- --- ---- --- ---- -r/--min-frags-reads 1 20 30 50 100 100 -p/--min-frags-fraction 0.2 0.5 0.7 0.8 1 1 -d/--max-frags-depth-stdev 10 10 3 2 2 1.5 -u/--min-uniq-reads 1 20 20 20 50 50 -U/--min-hic-ureads 1 5 5 5 10 10 -H/--min-hic-ureads-qcov 0.55 0.7 0.7 0.75 0.8 0.8 -P/--min-hic-ureads-prop 0.01 0.1 0.2 0.1 0.1 0.15 Taxonomy data : Mapping references IDs to TaxIds: -T/--taxid-map NCBI taxonomy dump files: -X/--taxdump Performance notes : Searching results are parsed in parallel, and the number of lines proceeded by a thread can be set by the flag --chunk-size . However using a lot of threads does not always accelerate processing, 4 threads with chunk size of 500-5000 is fast enough.","title":"Profiling modes"},{"location":"tutorial/profiling/#commands_1","text":"# taxid mapping files, multiple files supported. taxid_map=gtdb.kmcp/taxid.map,refseq-viral.kmcp/taxid.map,refseq-fungi.kmcp # taxdump directory taxdump=taxdump/ sfile=$file.kmcp.tsv.gz kmcp profile \\ --taxid-map $taxid_map \\ --taxdump $taxdump \\ --level species \\ --min-query-cov 0.55 \\ --min-frags-reads 50 \\ --min-frags-fraction 0.8 \\ --max-frags-depth-stdev 2 \\ --min-uniq-reads 10 \\ --min-hic-ureads 1 \\ --min-hic-ureads-qcov 0.75 \\ --min-hic-ureads-prop 0.1 \\ $sfile \\ --out-prefix $sfile.kmcp.profile \\ --metaphlan-report $sfile.metaphlan.profile \\ --cami-report $sfile.cami.profile \\ --sample-id \"0\" \\ --binning-result $sfile.binning.gz","title":"Commands"},{"location":"tutorial/profiling/#profiling-result-formats","text":"Supported profiling output formats : KMCP ( -o/--out-prefix ) CAMI ( -M/--metaphlan-report , sample name: -s/--sample-id ) MetaPhlAn ( -C/--cami-report , sample name: -s/--sample-id )) Supported taxonomic binning formats : CAMI ( -B/--binning-result ) KMCP format: 1. ref, Identifier of the reference genome 2. percentage, Relative abundance of a reference 3. score, The 90th percentile of qCov of uniquely matched reads 4. fragsFrac, Genome fragments fraction 5. fragsRelDepth, Relative depths of reference fragments 6. fragsRelDepthStd, The strandard deviation of fragsRelDepth 7. reads, Total number of matched reads of this reference 8. ureads, Number of uniquely matched reads 9. hicureads, Number of uniquely matched reads with high-confidence 10. refsize, Reference size 11. refname, Reference name, optional via name mapping file 12. taxid, TaxId of the reference 13. rank, Taxonomic rank 14. taxname, Taxonomic name 15. taxpath, Complete lineage 16. taxpathsn, Corresponding TaxIds of taxons in the complete lineage Demo output: ref percentage score fragsFrac fragsRelDepth fragsRelDepthStd reads ureads hicureads refsize refname taxid rank taxname taxpath taxpathsn NC_013654.1 48.321535 100.00 1.00 0.99;1.00;0.99;1.00;0.99;0.99;0.99;0.98;1.05;1.02 0.02 287936 226225 226225 4717338 431946 strain Escherichia coli SE15 Bacteria;Proteobacteria;Gammaproteobacteria;Enterobacterales;Enterobacteriaceae;Escherichia;Escherichia coli;Escherichia coli SE15 2;1224;1236;91347;543;561;562;431946 NC_000913.3 46.194629 100.00 1.00 1.04;0.99;1.00;1.00;0.99;0.99;0.99;0.97;1.04;0.98 0.02 270846 175686 175686 4641652 511145 no rank Escherichia coli str. K-12 substr. MG1655 Bacteria;Proteobacteria;Gammaproteobacteria;Enterobacterales;Enterobacteriaceae;Escherichia;Escherichia coli;Escherichia coli K-12 2;1224;1236;91347;543;561;562;83333 NC_002695.2 5.014025 100.00 1.00 0.97;0.98;0.92;1.12;1.01;0.95;1.00;1.01;1.03;1.00 0.05 34825 22945 22945 5498578 386585 strain Escherichia coli O157:H7 str. Sakai Bacteria;Proteobacteria;Gammaproteobacteria;Enterobacterales;Enterobacteriaceae;Escherichia;Escherichia coli;Escherichia coli O157:H7 str. Sakai 2;1224;1236;91347;543;561;562;386585 NC_010655.1 0.469811 100.00 1.00 1.03;0.87;0.90;0.98;1.15;1.17;0.90;0.96;0.96;1.09 0.10 1581 1581 1581 2664102 349741 strain Akkermansia muciniphila ATCC BAA-835 Bacteria;Verrucomicrobia;Verrucomicrobiae;Verrucomicrobiales;Akkermansiaceae;Akkermansia;Akkermansia muciniphila;Akkermansia muciniphila ATCC BAA-835 2;74201;203494;48461;1647988;239934;239935;349741 CAMI format : @SampleID: @Version:0.10.0 @Ranks:superkingdom|phylum|class|order|family|genus|species|strain @TaxonomyID:ncbi-taxonomy @@TAXID RANK TAXPATH TAXPATHSN PERCENTAGE 2 superkingdom 2 Bacteria 100.000000 1224 phylum 2|1224 Bacteria|Proteobacteria 99.530189 74201 phylum 2|74201 Bacteria|Verrucomicrobia 0.469811 1236 class 2|1224|1236 Bacteria|Proteobacteria|Gammaproteobacteria 99.530189 203494 class 2|74201|203494 Bacteria|Verrucomicrobia|Verrucomicrobiae 0.469811 91347 order 2|1224|1236|91347 Bacteria|Proteobacteria|Gammaproteobacteria|Enterobacterales 99.530189 48461 order 2|74201|203494|48461 Bacteria|Verrucomicrobia|Verrucomicrobiae|Verrucomicrobiales 0.469811 543 family 2|1224|1236|91347|543 Bacteria|Proteobacteria|Gammaproteobacteria|Enterobacterales|Enterobacteriaceae 99.530189 1647988 family 2|74201|203494|48461|1647988 Bacteria|Verrucomicrobia|Verrucomicrobiae|Verrucomicrobiales|Akkermansiaceae 0.469811 561 genus 2|1224|1236|91347|543|561 Bacteria|Proteobacteria|Gammaproteobacteria|Enterobacterales|Enterobacteriaceae|Escherichia 99.530189 239934 genus 2|74201|203494|48461|1647988|239934 Bacteria|Verrucomicrobia|Verrucomicrobiae|Verrucomicrobiales|Akkermansiaceae|Akkermansia 0.469811 562 species 2|1224|1236|91347|543|561|562 Bacteria|Proteobacteria|Gammaproteobacteria|Enterobacterales|Enterobacteriaceae|Escherichia|Escherichia coli 99.530189 239935 species 2|74201|203494|48461|1647988|239934|239935 Bacteria|Verrucomicrobia|Verrucomicrobiae|Verrucomicrobiales|Akkermansiaceae|Akkermansia|Akkermansia muciniphila 0.469811 431946 strain 2|1224|1236|91347|543|561|562|431946 Bacteria|Proteobacteria|Gammaproteobacteria|Enterobacterales|Enterobacteriaceae|Escherichia|Escherichia coli|Escherichia coli SE15 48.321535 83333 strain 2|1224|1236|91347|543|561|562|83333 Bacteria|Proteobacteria|Gammaproteobacteria|Enterobacterales|Enterobacteriaceae|Escherichia|Escherichia coli|Escherichia coli K-12 46.194629 386585 strain 2|1224|1236|91347|543|561|562|386585 Bacteria|Proteobacteria|Gammaproteobacteria|Enterobacterales|Enterobacteriaceae|Escherichia|Escherichia coli|Escherichia coli O157:H7 str. Sakai 5.014025 349741 strain 2|74201|203494|48461|1647988|239934|239935|349741 Bacteria|Verrucomicrobia|Verrucomicrobiae|Verrucomicrobiales|Akkermansiaceae|Akkermansia|Akkermansia muciniphila|Akkermansia muciniphila ATCC BAA-835 0.469811 taxonkit profile2cami can also converts any metagenomic profile table with TaxIds to CAMI format. Metaphlan format: #SampleID k__Bacteria 100.000000 k__Bacteria|p__Proteobacteria 99.530189 k__Bacteria|p__Verrucomicrobia 0.469811 k__Bacteria|p__Proteobacteria|c__Gammaproteobacteria 99.530189 k__Bacteria|p__Verrucomicrobia|c__Verrucomicrobiae 0.469811 k__Bacteria|p__Proteobacteria|c__Gammaproteobacteria|o__Enterobacterales 99.530189 k__Bacteria|p__Verrucomicrobia|c__Verrucomicrobiae|o__Verrucomicrobiales 0.469811 k__Bacteria|p__Proteobacteria|c__Gammaproteobacteria|o__Enterobacterales|f__Enterobacteriaceae 99.530189 k__Bacteria|p__Verrucomicrobia|c__Verrucomicrobiae|o__Verrucomicrobiales|f__Akkermansiaceae 0.469811 k__Bacteria|p__Proteobacteria|c__Gammaproteobacteria|o__Enterobacterales|f__Enterobacteriaceae|g__Escherichia 99.530189 k__Bacteria|p__Verrucomicrobia|c__Verrucomicrobiae|o__Verrucomicrobiales|f__Akkermansiaceae|g__Akkermansia 0.469811 k__Bacteria|p__Proteobacteria|c__Gammaproteobacteria|o__Enterobacterales|f__Enterobacteriaceae|g__Escherichia|s__Escherichia coli 99.530189 k__Bacteria|p__Verrucomicrobia|c__Verrucomicrobiae|o__Verrucomicrobiales|f__Akkermansiaceae|g__Akkermansia|s__Akkermansia muciniphila 0.469811 k__Bacteria|p__Proteobacteria|c__Gammaproteobacteria|o__Enterobacterales|f__Enterobacteriaceae|g__Escherichia|s__Escherichia coli|t__Escherichia coli SE15 48.321535 k__Bacteria|p__Proteobacteria|c__Gammaproteobacteria|o__Enterobacterales|f__Enterobacteriaceae|g__Escherichia|s__Escherichia coli|t__Escherichia coli K-12 46.194629 k__Bacteria|p__Proteobacteria|c__Gammaproteobacteria|o__Enterobacterales|f__Enterobacteriaceae|g__Escherichia|s__Escherichia coli|t__Escherichia coli O157:H7 str. Sakai 5.014025 k__Bacteria|p__Verrucomicrobia|c__Verrucomicrobiae|o__Verrucomicrobiales|f__Akkermansiaceae|g__Akkermansia|s__Akkermansia muciniphila|t__Akkermansia muciniphila ATCC BAA-835 0.469811 Binning result : # This is the bioboxes.org binning output format at # https://github.com/bioboxes/rfc/tree/master/data-format @Version:0.10.0 @SampleID: @@SEQUENCEID TAXID NC_000913.3_sliding:1244941-1245090 511145 NC_013654.1_sliding:344871-345020 562 NC_000913.3_sliding:3801041-3801190 511145 NC_013654.1_sliding:752751-752900 562 NC_000913.3_sliding:4080871-4081020 562 NC_000913.3_sliding:3588091-3588240 511145 NC_000913.3_sliding:2249621-2249770 562 NC_013654.1_sliding:2080171-2080320 431946 NC_000913.3_sliding:2354841-2354990 511145 NC_013654.1_sliding:437671-437820 431946","title":"Profiling result formats"},{"location":"tutorial/searching/","text":"Sequence and genome searching Using cases Searching sequences against raws reads. For checking existence: Building database with raws reads and searching with query sequences, optionally using k-mer sketches for long query sequences. For abundance estimation: For long sequences (similar to taxonomic profiling): Building database with query sequences, searching with raws reads, and profiling. For short (shorter than reads length) sequences: Not capable. Searching sequences against assemblies/genomes. For checking existence: For short sequences (short reads, e.g., detecting host contamination): Building database with assemblies/genomes and searching with raws reads. For long sequences: Building database with assemblies/genomes using k-mer sketches. For genome similarity estimation: Building database with assemblies/genomes using k-mer sketches. For taxonomic profiling: For short reads: Building database with assemblies/genomes, searching with raws reads, and profiling. For long reads: Split long reads into short reads before searching. Sequence search KMCP can be used for fast sequence search against large scales of genomic datasets as BIGSI and COBS do. KMCP reimplemented and modified the Compact Bit-Sliced Signature index (COBS) algorithm, bringing a small database size and much faster searching speed (check the benchmark ). Step 1. Building databases The database building process is similar to that of metagenomic profiling, with one difference: Reference genomes are not splitted into fragments which slow down searching speed. Taken GTDB for example: # mask low-complexity region mkdir -p gtdb.masked find gtdb/ -name \"*.fna.gz\" \\ | rush 'dustmasker -in <(zcat {}) -outfmt fasta \\ | sed -e \"/^>/!s/[a-z]/n/g\" \\ | gzip -c > gtdb.masked/{%}' # compute k-mers # sequence containing \"plasmid\" in name are ignored, # k = 21 kmcp compute -I gtdb.masked/ -k 21 -B plasmid -O gtdb-r202-k21 --force # build database # number of index files: 32, for server with >= 32 CPU cores # bloom filter parameter: # number of hash function: 1 # false positive rate: 0.3 kmcp index -j 32 -I gtdb-r202-k21 -O gtdb-r202-k21-n 1 -f 0.3 # cp name mapping file to database directory cp name.map gtdb-r202-k21.kmcp/ The size of database is 56GB. By default, kmcp search loads the whole database into main memory (RAM) for fast searching. Optionally, the flag --low-mem can be set to avoid loading the whole database, while it's much slower, >10X slower on SSD and should be much slower on HDD disks. Step 2. Searching kmcp search supports FASTA/Q format from STDIN or files ( usage ). kmcp search -d gtdb-r202-k21.kmcp/ test.fq.gz -o result.tsv.gz 13:36:14.522 [INFO] kmcp v0.7.0 13:36:14.522 [INFO] https://github.com/shenwei356/kmcp 13:36:14.522 [INFO] 13:36:14.522 [INFO] checking input files ... 13:36:14.522 [INFO] 1 input file(s) given 13:36:14.522 [INFO] loading database with mmap enabled ... 13:36:14.523 [INFO] number of extra workers for every index file: 3 13:36:14.571 [INFO] database loaded: gtdb-r202-k21.kmcp/ 13:36:14.571 [INFO] 13:36:14.571 [INFO] -------------------- [main parameters] -------------------- 13:36:14.571 [INFO] minimum query length: 70 13:36:14.571 [INFO] minimum matched k-mers: 30 13:36:14.571 [INFO] minimum query coverage: 0.550000 13:36:14.571 [INFO] minimum target coverage: 0.000000 13:36:14.571 [INFO] minimum target coverage: 0.000000 13:36:14.571 [INFO] -------------------- [main parameters] -------------------- 13:36:14.571 [INFO] 13:36:14.571 [INFO] searching ... 13:36:14.575 [INFO] reading sequence file: test.fq.gz processed queries: 999424, speed: 2.47 million queries per minute 13:36:38.843 [INFO] 13:36:38.843 [INFO] processed queries: 1000000, speed: 2.47 million queries per minute 13:36:38.843 [INFO] 68.2500% (682500/1000000) queries matched 13:36:38.843 [INFO] done searching 13:36:42.852 [INFO] 13:36:42.853 [INFO] elapsed time: 28.331134572s 13:36:42.853 [INFO] The result is tab-delimited. #query qLen qKmers FPR hits target fragIdx frags tLen kSize mKmers qCov tCov jacc queryIdx S0R0/1 150 130 3.0168e-03 2 GCF_002872255.1 0 1 2582291 21 88 0.6769 0.0000 0.0000 0 S0R0/1 150 130 3.0168e-03 2 GCF_001434585.1 0 1 2219511 21 74 0.5692 0.0000 0.0000 0 S0R0/2 150 130 3.0168e-03 5 GCF_002872255.1 0 1 2582291 21 81 0.6231 0.0000 0.0000 1 S0R0/2 150 130 3.0168e-03 5 GCF_001434585.1 0 1 2219511 21 80 0.6154 0.0000 0.0000 1 S0R0/2 150 130 3.0168e-03 5 GCF_001437405.1 0 1 2260906 21 77 0.5923 0.0000 0.0000 1 Reference IDs (column target ) can be optionally mapped to their names when searching: kmcp search -d gtdb-r202-k21.kmcp/ -N name.map test.fq.gz -o result.tsv.gz Or after searching using csvtk : csvtk replace -t -C $ -f target -k name.map -p '(.+)' -r '{kv}' result.tsv.gz Print the main columns only: csvtk head -t -C $ -n 5 result.tsv.gz \\ | csvtk rename -t -C $ -f 1 -n query \\ | csvtk cut -t -f query,FPR,qCov,target \\ | csvtk csv2md -t query FPR qCov target S0R0/1 3.0168e-03 0.6769 GCF_002872255.1 S0R0/1 3.0168e-03 0.5692 GCF_001434585.1 S0R0/2 3.0168e-03 0.6231 GCF_002872255.1 S0R0/2 3.0168e-03 0.6154 GCF_001434585.1 S0R0/2 3.0168e-03 0.5923 GCF_001437405.1 Genome similarity estimation KMCP can be used for fast similarity estimation of newly assembled genome against known reference genomes . BLAST is an option while it focuses on local similarity. Besides, the database is big and the searching speed is relative slow. Genome sketching is a method of utilizing small and approximate summaries of genomic data for fast searching and comparison. Mash and Sourmash provide fast genome distance estimation using MinHash (Mash) or FracMinHash (Scaled MinHash) (Sourmash). Here KMCP utilizes multiple sketches ( Minimizer , FracMinHash (previously named Scaled MinHash ) and Syncmers ) for genome similarity estimation. Prebuilt databases are available and users can also build custom databases following steps below. Step 1. Building databases The database building process is similar to that of metagenomic profiling, with few differences: K-mer sketches instead of all k-mers are computed. Reference genomes are not splitted into fragments. Smaller false positive rate ( -f ) and more than one hash functions ( -n ) are used to improve accuracy. Using bigger k-mer size: 31. Supported k-mer (sketches) types: K-mer: ntHash of k-mer ( -k ) K-mer sketchs (all using ntHash): FracMinHash ( -k -D ), previously named Scaled MinHash Minimizer ( -k -W ), optionally scaling/down-sampling ( -D ) Closed Syncmer ( -k -S ), optionally scaling/down-sampling ( -D ) Taken GTDB for example: # compute FracMinHash (Scaled MinHash) with scale 1000 # sequence containing \"plasmid\" in name are ignored, # k = 31 kmcp compute -I gtdb/ -k 31 -D 1000 -B plasmid -O gtdb-r202-minhash # build database # number of index files: 8, for server with >= 8 CPU cores # bloom filter parameter: # number of hash function: 3 # false positive rate: 0.001 kmcp index -j 8 -I gtdb-r202-minhash -O gtdb.minhash.kmcp -n 3 -f 0.001 # cp name mapping file to database directory cp taxid.map name.map gtdb.minhash.kmcp/ Attention: For small genomes like viruses, sketching parameters should be adjusted. For examples, setting a smaller scale like 10. Step 2. Searching The searching process is simple and very fast (<1 second). kmcp search --query-whole-file -d gtdb.minhash.kmcp/ contigs.fasta -o result.tsv The output is in tab-delimited format, full search result: #query qLen qKmers FPR hits target fragIdx frags tLen kSize mKmers qCov tCov jacc queryIdx NODE_1_length_106749_cov_161.610981 4563649 9052 0.000000e+00 1 GCF_900460465.1 0 1 4777134 31 8942 0.9878 0.9933 0.9813 0 Reference IDs can be optionally mapped to their names, let's print the main columns only: kmcp search --query-whole-file -d gtdb.minhash.kmcp/ -N gtdb.minhash.kmcp/name.map \\ contigs.fasta --quiet \\ | csvtk rename -t -C $ -f 1 -n query \\ | csvtk cut -t -f query,jacc,target \\ > result.tsv query jacc target NODE_1_length_106749_cov_161.610981 0.9813 NZ_UAVH01000012.1 Yersinia pestis strain NCTC5923, whole genome shotgun sequence Using closed syncmer: kmcp search --query-whole-file -d gtdb.syncmer.kmcp/ -N gtdb.syncmer.kmcp/name.map \\ contigs.fasta --quiet \\ | csvtk rename -t -C $ -f 1 -n query \\ | csvtk cut -t -f query,jacc,target query jacc target NODE_1_length_106749_cov_161.610981 0.9383 NZ_UAVH01000012.1 Yersinia pestis strain NCTC5923, whole genome shotgun sequence","title":"Sequence and genome searching"},{"location":"tutorial/searching/#sequence-and-genome-searching","text":"","title":"Sequence and genome searching"},{"location":"tutorial/searching/#using-cases","text":"Searching sequences against raws reads. For checking existence: Building database with raws reads and searching with query sequences, optionally using k-mer sketches for long query sequences. For abundance estimation: For long sequences (similar to taxonomic profiling): Building database with query sequences, searching with raws reads, and profiling. For short (shorter than reads length) sequences: Not capable. Searching sequences against assemblies/genomes. For checking existence: For short sequences (short reads, e.g., detecting host contamination): Building database with assemblies/genomes and searching with raws reads. For long sequences: Building database with assemblies/genomes using k-mer sketches. For genome similarity estimation: Building database with assemblies/genomes using k-mer sketches. For taxonomic profiling: For short reads: Building database with assemblies/genomes, searching with raws reads, and profiling. For long reads: Split long reads into short reads before searching.","title":"Using cases"},{"location":"tutorial/searching/#sequence-search","text":"KMCP can be used for fast sequence search against large scales of genomic datasets as BIGSI and COBS do. KMCP reimplemented and modified the Compact Bit-Sliced Signature index (COBS) algorithm, bringing a small database size and much faster searching speed (check the benchmark ).","title":"Sequence search"},{"location":"tutorial/searching/#step-1-building-databases","text":"The database building process is similar to that of metagenomic profiling, with one difference: Reference genomes are not splitted into fragments which slow down searching speed. Taken GTDB for example: # mask low-complexity region mkdir -p gtdb.masked find gtdb/ -name \"*.fna.gz\" \\ | rush 'dustmasker -in <(zcat {}) -outfmt fasta \\ | sed -e \"/^>/!s/[a-z]/n/g\" \\ | gzip -c > gtdb.masked/{%}' # compute k-mers # sequence containing \"plasmid\" in name are ignored, # k = 21 kmcp compute -I gtdb.masked/ -k 21 -B plasmid -O gtdb-r202-k21 --force # build database # number of index files: 32, for server with >= 32 CPU cores # bloom filter parameter: # number of hash function: 1 # false positive rate: 0.3 kmcp index -j 32 -I gtdb-r202-k21 -O gtdb-r202-k21-n 1 -f 0.3 # cp name mapping file to database directory cp name.map gtdb-r202-k21.kmcp/ The size of database is 56GB. By default, kmcp search loads the whole database into main memory (RAM) for fast searching. Optionally, the flag --low-mem can be set to avoid loading the whole database, while it's much slower, >10X slower on SSD and should be much slower on HDD disks.","title":"Step 1. Building databases"},{"location":"tutorial/searching/#step-2-searching","text":"kmcp search supports FASTA/Q format from STDIN or files ( usage ). kmcp search -d gtdb-r202-k21.kmcp/ test.fq.gz -o result.tsv.gz 13:36:14.522 [INFO] kmcp v0.7.0 13:36:14.522 [INFO] https://github.com/shenwei356/kmcp 13:36:14.522 [INFO] 13:36:14.522 [INFO] checking input files ... 13:36:14.522 [INFO] 1 input file(s) given 13:36:14.522 [INFO] loading database with mmap enabled ... 13:36:14.523 [INFO] number of extra workers for every index file: 3 13:36:14.571 [INFO] database loaded: gtdb-r202-k21.kmcp/ 13:36:14.571 [INFO] 13:36:14.571 [INFO] -------------------- [main parameters] -------------------- 13:36:14.571 [INFO] minimum query length: 70 13:36:14.571 [INFO] minimum matched k-mers: 30 13:36:14.571 [INFO] minimum query coverage: 0.550000 13:36:14.571 [INFO] minimum target coverage: 0.000000 13:36:14.571 [INFO] minimum target coverage: 0.000000 13:36:14.571 [INFO] -------------------- [main parameters] -------------------- 13:36:14.571 [INFO] 13:36:14.571 [INFO] searching ... 13:36:14.575 [INFO] reading sequence file: test.fq.gz processed queries: 999424, speed: 2.47 million queries per minute 13:36:38.843 [INFO] 13:36:38.843 [INFO] processed queries: 1000000, speed: 2.47 million queries per minute 13:36:38.843 [INFO] 68.2500% (682500/1000000) queries matched 13:36:38.843 [INFO] done searching 13:36:42.852 [INFO] 13:36:42.853 [INFO] elapsed time: 28.331134572s 13:36:42.853 [INFO] The result is tab-delimited. #query qLen qKmers FPR hits target fragIdx frags tLen kSize mKmers qCov tCov jacc queryIdx S0R0/1 150 130 3.0168e-03 2 GCF_002872255.1 0 1 2582291 21 88 0.6769 0.0000 0.0000 0 S0R0/1 150 130 3.0168e-03 2 GCF_001434585.1 0 1 2219511 21 74 0.5692 0.0000 0.0000 0 S0R0/2 150 130 3.0168e-03 5 GCF_002872255.1 0 1 2582291 21 81 0.6231 0.0000 0.0000 1 S0R0/2 150 130 3.0168e-03 5 GCF_001434585.1 0 1 2219511 21 80 0.6154 0.0000 0.0000 1 S0R0/2 150 130 3.0168e-03 5 GCF_001437405.1 0 1 2260906 21 77 0.5923 0.0000 0.0000 1 Reference IDs (column target ) can be optionally mapped to their names when searching: kmcp search -d gtdb-r202-k21.kmcp/ -N name.map test.fq.gz -o result.tsv.gz Or after searching using csvtk : csvtk replace -t -C $ -f target -k name.map -p '(.+)' -r '{kv}' result.tsv.gz Print the main columns only: csvtk head -t -C $ -n 5 result.tsv.gz \\ | csvtk rename -t -C $ -f 1 -n query \\ | csvtk cut -t -f query,FPR,qCov,target \\ | csvtk csv2md -t query FPR qCov target S0R0/1 3.0168e-03 0.6769 GCF_002872255.1 S0R0/1 3.0168e-03 0.5692 GCF_001434585.1 S0R0/2 3.0168e-03 0.6231 GCF_002872255.1 S0R0/2 3.0168e-03 0.6154 GCF_001434585.1 S0R0/2 3.0168e-03 0.5923 GCF_001437405.1","title":"Step 2. Searching"},{"location":"tutorial/searching/#genome-similarity-estimation","text":"KMCP can be used for fast similarity estimation of newly assembled genome against known reference genomes . BLAST is an option while it focuses on local similarity. Besides, the database is big and the searching speed is relative slow. Genome sketching is a method of utilizing small and approximate summaries of genomic data for fast searching and comparison. Mash and Sourmash provide fast genome distance estimation using MinHash (Mash) or FracMinHash (Scaled MinHash) (Sourmash). Here KMCP utilizes multiple sketches ( Minimizer , FracMinHash (previously named Scaled MinHash ) and Syncmers ) for genome similarity estimation. Prebuilt databases are available and users can also build custom databases following steps below.","title":"Genome similarity estimation"},{"location":"tutorial/searching/#step-1-building-databases_1","text":"The database building process is similar to that of metagenomic profiling, with few differences: K-mer sketches instead of all k-mers are computed. Reference genomes are not splitted into fragments. Smaller false positive rate ( -f ) and more than one hash functions ( -n ) are used to improve accuracy. Using bigger k-mer size: 31. Supported k-mer (sketches) types: K-mer: ntHash of k-mer ( -k ) K-mer sketchs (all using ntHash): FracMinHash ( -k -D ), previously named Scaled MinHash Minimizer ( -k -W ), optionally scaling/down-sampling ( -D ) Closed Syncmer ( -k -S ), optionally scaling/down-sampling ( -D ) Taken GTDB for example: # compute FracMinHash (Scaled MinHash) with scale 1000 # sequence containing \"plasmid\" in name are ignored, # k = 31 kmcp compute -I gtdb/ -k 31 -D 1000 -B plasmid -O gtdb-r202-minhash # build database # number of index files: 8, for server with >= 8 CPU cores # bloom filter parameter: # number of hash function: 3 # false positive rate: 0.001 kmcp index -j 8 -I gtdb-r202-minhash -O gtdb.minhash.kmcp -n 3 -f 0.001 # cp name mapping file to database directory cp taxid.map name.map gtdb.minhash.kmcp/ Attention: For small genomes like viruses, sketching parameters should be adjusted. For examples, setting a smaller scale like 10.","title":"Step 1. Building databases"},{"location":"tutorial/searching/#step-2-searching_1","text":"The searching process is simple and very fast (<1 second). kmcp search --query-whole-file -d gtdb.minhash.kmcp/ contigs.fasta -o result.tsv The output is in tab-delimited format, full search result: #query qLen qKmers FPR hits target fragIdx frags tLen kSize mKmers qCov tCov jacc queryIdx NODE_1_length_106749_cov_161.610981 4563649 9052 0.000000e+00 1 GCF_900460465.1 0 1 4777134 31 8942 0.9878 0.9933 0.9813 0 Reference IDs can be optionally mapped to their names, let's print the main columns only: kmcp search --query-whole-file -d gtdb.minhash.kmcp/ -N gtdb.minhash.kmcp/name.map \\ contigs.fasta --quiet \\ | csvtk rename -t -C $ -f 1 -n query \\ | csvtk cut -t -f query,jacc,target \\ > result.tsv query jacc target NODE_1_length_106749_cov_161.610981 0.9813 NZ_UAVH01000012.1 Yersinia pestis strain NCTC5923, whole genome shotgun sequence Using closed syncmer: kmcp search --query-whole-file -d gtdb.syncmer.kmcp/ -N gtdb.syncmer.kmcp/name.map \\ contigs.fasta --quiet \\ | csvtk rename -t -C $ -f 1 -n query \\ | csvtk cut -t -f query,jacc,target query jacc target NODE_1_length_106749_cov_161.610981 0.9383 NZ_UAVH01000012.1 Yersinia pestis strain NCTC5923, whole genome shotgun sequence","title":"Step 2. Searching"}]}